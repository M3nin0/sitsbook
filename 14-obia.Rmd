# Object-based time series image analysis {.unnumbered}

```{r, include = FALSE}
source("common.R")
```

Object-Based Image Analysis (OBIA) is an approach to remote sensing image analysis that partitions an image into meaningful segments or objects, which are then classified and analyzed. In contrast to traditional pixel-based approaches, which analyze each individual pixel in isolation, OBIA operates on groups of pixels, or "segments", which have similar spectral and spatial characteristics.

The general sequence of the processes involved in OBIA include:

1.  Segmentation: The first step in OBIA is to group together pixels that are similar based on certain criteria such as color, intensity or texture. These groupings are called "segments". The aim here is to create objects that represent meaningful features in the real world, like buildings, roads, fields, forests, and water bodies.

2.  Attribute Calculation: After the image has been segmented into distinct objects, the next step is to extract attributes from each object. In general, these attributes can be spectral (e.g., mean reflectance), spatial (e.g., size, shape, orientation), or textural (e.g., smoothness, roughness).

3.  Classification: Once the attributes have been extracted from the segments, they can be used to classify each segment.

One of the advantages of OBIA is that it more closely mimics the way humans visually perceive their environment, not by individual pixels, but by groups of pixels as meaningful objects. This often results in more accurate and contextually rich analysis of imagery data. It's widely used in various fields such as environmental monitoring, agriculture, urban planning, defense, and more.

Version 1.4.1. of `sits` includes an extension of OBIA for working with image time series. The initial step of the process is to segment one image of a reference date. Then, for each segment, we use an aggregation function to obtain a set of spectral attributes for each segment. The default option is to take the mean value for each temporal instance of each band. The result are a set of time series, one for each segment. Each time series is then classified independently. The result can be joined together with the original image to obtain a classification. We call this process "OBIA-TS" (object-based image time series analysis)

## Generic Image segmentation in SITS{-}

The first step of the OBIA-TS procedure is to select a data cube to be segmented and function that performs the segmentation. For this purpose, `sits` provides a generic `sits_segment()` function, which allows users to select different segmentation algorithms. The `sits_segment()` function has the following parameters:

-   `cube`: a regular data cube.
-   `tiles`: tiles to be segmented.
-   `bands`: bands to include in the segmentation
-   `dates`: dates to include in the segmentation
-   `seg_fn`: function to apply the segmentation
-   `...`: other params to be passed to segmentation function

In `sits` version 1.4.2, there is only one segmentation function available that implements the Simple Linear Iterative Clustering (SLIC) algorithm, which is described below. In future versions of `sits`, we expect to include additional functions that support spatio-temporal segmentation.

## Simple Linear Iterative Clustering (SLIC) algorithm{-}

In `sits` 1.4.2, we provide an implementation of The Simple Linear Iterative Clustering (SLIC) algorithm [@Achanta2012a]. SLIC uses spectral similarity and proximity in the image space to segment the image into "superpixels". Superpixels are clusters of pixels with similar spectral responses that are close together, which correspond to coherent object parts in the image. Here's a high-level view of the SLIC algorithm:

1.  The algorithm starts by dividing the image into a grid, where each cell of the grid will become a superpixel.

2.  For each cell, the pixel in the center becomes the initial "cluster center" for that superpixel.

3.  For each pixel, the algorithm calculates a distance to each of the nearby cluster centers. This distance includes both a spatial component (how far the pixel is from the center of the superpixel in terms of x and y coordinates) and a spectral component (how different the pixel's spectral values are from the average values of the superpixel).

4.  Each pixel is assigned to the closest cluster. After all pixels have been assigned to clusters, the algorithm recalculates the cluster centers by averaging the spatial coordinates and spectral values of all pixels within each cluster.

5.  Steps 3-4 are repeated for a set number of iterations, or until the cluster assignments stop changing.

The outcome of the SLIC algorithm is a set of superpixels which try to capture the to boundaries of objects within the image. The SLIC implementation in `sits` 1.4.1 uses the `supercells` R package [@Nowosad2022]. The parameters for the `sits_supercells()` function are:

-   `dist_fn`: metric used to calculate the distance between values. By default, the "euclidean" metric is used. Alternatives include "jsd" (Jensen-Shannon distance), and "dtw" (dynamic time warping) or one of 46 distance and similarity measures implemented in the R package `philentropy` [@Drost2018].
-   `avg_fn`: function to calculate a value of each superpixel. There are two internal functions implemented in C++ - "mean" and "median". It is also possible to provide a user-defined R function that returns one value based on an R vector.
-   `step`: distance, measured in the number of cells, between initial superpixels' centers.
-   `compactness`: A value that controls superpixels' density. Larger values cause clusters to be more compact.
-   `minarea`: minimal size of the output superpixels (measured in number of cells).

## Example of SLIC-based segmentation and classification{-}

To show an example of SLIC-based segmentation, we first build a data cube, using images available in the `sitsdata` package.

```{r, tidy = "styler", out.width="100%", fig.align="center", fig.cap= "Sentinel-2 image in an area of Rondonia in Brazil"}
# directory where files are located
data_dir <- system.file("extdata/Rondonia-20LKP", package = "sitsdata")
# Builds a cube based on existing files
s2_cube <- sits_cube(
    source = "AWS",
    collection = "SENTINEL-2-L2A",
    data_dir = data_dir,
    parse_info = c("X1", "tile", "band", "date")
)
plot(s2_cube, red = "B11", green = "B8A", blue = "B02", date = "2020-09-24")
```

Given that the SLIC algorithm uses a single date and that the date of "2020-09-04" is cloud-free and is close to the end of the dry season in Amazonia, it is selected as a suitable date for the segmentation.

The following example produces a segmented image.

```{r}
# segment a cube using 
segments_20LKP <- sits_segment(
    cube = s2_cube,
    tiles = "20LKP",
    bands = c("B02", "B11", "B8A"),
    dates = "2020-09-24",
    seg_fn = sits_supercells(
        step = 60,
        compactness = 1,
        dist_fun = "euclidean",
        iter = 10,
        minarea = 50,
        multicores = 1
    )
)
```

It is useful to visualize the segments together with the RGB image using `sits_view()`.

```{r, tidy = "styler", echo = TRUE, eval = FALSE}
sits_view(s2_cube, red = "B11", green = "B8A", blue = "B02", 
          date = "2020-09-24", segments = segments_20LKP)
```

```{r, echo = FALSE, out.width="90%", fig.caption = "Detail of segementation of image in Amazonia", fig.align="center"}
knitr::include_graphics("images/view_segments_RGB_detail.png")
```

After obtaining the segments, the next step is to obtain one time series per segment. Each time series will represent one entire object and will be classified independently. To do this, use `sits_get_data()` passing the segments as the samples. See Chapter "Working with time series" for a detailed description of `sits_get_data()`.

```{r, eval = TRUE, tidy = "styler"}
time_series_segments <- sits_get_data(
    cube = s2_cube,
    samples = segments_20LKP,
    multicores = 4
)
# show the output 
time_series_segments[1:4, ]
```

The `time_series_segments` object is a standard `sits` time series. For each segment, it contains the latitude/longitude of its geometrical centroid, the start and end dates of the cube. Its time series values will be computed as the average of all pixels inside the segment.

After obtaining the segments, the next step is building the machine learning model. This model will use training samples selected by INPE's researchers that describe the various land classes in the state of Rondonia; these samples are available in package `sitsdata`.

```{r, tidy = "styler"}
samples_file <- system.file("extdata/Rondonia-model/samples.rds", package = "sitsdata")
samples <- readRDS(samples_file)
# select the bands to match those of the data cube
samples_3bands <- sits_select(samples, bands = c("B02", "B11", "B8A"))
```

Using the samples, we can now obtain a machine learning model and apply it to classify the time series associated to the segments.

```{r, tidy = "styler"}
# Obtain a random forest model
rf_model <- sits_train(samples_3bands, sits_rfor())
# classify the time series segments
time_series_class <- sits_classify(
    data = time_series_segments,
    ml_model = rf_model,
    multicores = 4
)
### show the first time series segments classified
time_series_class$predicted[[1]]
```

The result of the classification is time series tibble, with an additional column called "predicted" that contains the most likely class for each pixel (in this case "Forest"), with the probabilities associated to each class. After obtaining the classes for the centroids of each object, it is useful to join the resulting time series tibble with the original segments using `sits_join_segments()`. The result of this function is a set of labelled segments, which can be used by other R applications such as `sf` and can also be viewed in `sits`.

```{r, tidy = "styler"}
labelled_segments <- sits_join_segments(
    data = time_series_class,
    segments = segments_20LKP
)
```

To view the classified segments together with the original image, use `plot()` or `sits_view()`, as in the following example.

```{r, tidy = "styler", eval = FALSE}
sits_view(
    s2_cube, 
    red = "B11", 
    green = "B8A", 
    blue = "B02", 
    dates = "2020-09-24",
    segments = labelled_segments
)
```
```{r, echo = FALSE, out.width="90%", fig.caption = "Detail of labelled segements for image in Rondonia, Brazil", fig.align="center"}
knitr::include_graphics("images/view_segments_class.png")
```
