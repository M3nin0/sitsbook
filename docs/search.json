[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Satellite images provide key information Earth’s environment impacts caused human actions. Petabytes Earth observation data now open free, making full extent image archives available. Using image time series, analysts make best use big Earth observation data collections, capturing subtle changes ecosystem health condition improving distinction different land classes.book introduces sits, open-source R package land use land cover classification big Earth observation data using satellite image time series. Users build regular data cubes cloud services Amazon Web Services, Microsoft Planetary Computer, NASA Harmonized Landsat-Sentinel, Brazil Data Cube, Swiss Data Cube Digital Earth Africa. sits API includes assessment training sample quality, machine learning deep learning classification algorithms, Bayesian post-processing methods smoothing uncertainty assessment. evaluate results, sits supports best practice accuracy assessments.","code":""},{"path":"index.html","id":"who-this-book-is-for","chapter":"Preface","heading":"Who this book is for","text":"target audience sits community remote sensing experts Earth Sciences background want use state---art data analysis methods minimal investment programming skills. package provides clear direct set functions, easy learn master. Users minimal background R programming can start using sits right away. yet familiar R need learn introductory concepts.R user like quickly master needed run sits, please read Parts 1 2 Garrett Golemund’s book, Hands-Programming R. already R user like update skills latest trends, please read book Hadley Wickham Gareth Golemund, R Data Science (2nd edition). Important concepts spatial analysis presented Edzer Pebesma Roger Bivand book Spatial Data Science.","code":""},{"path":"index.html","id":"software-version-described-in-this-book","chapter":"Preface","heading":"Software version described in this book","text":"version sits package described book 1.4.2.","code":""},{"path":"index.html","id":"main-reference-for-sits","chapter":"Preface","heading":"Main reference for sits","text":"use sits work, please cite following paper:Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira. Satellite Image Time Series Analysis Big Earth Observation Data. Remote Sensing, 13, p. 2428, 2021.","code":""},{"path":"index.html","id":"intellectual-property-rights","chapter":"Preface","heading":"Intellectual property rights","text":"book licensed Attribution-NonCommercial-ShareAlike 4.0 International (CC -NC-SA 4.0) Creative Commons. sits package licensed GNU General Public License, version 3.0.","code":""},{"path":"setup.html","id":"setup","chapter":"Setup","heading":"Setup","text":"","code":""},{"path":"setup.html","id":"how-to-use-this-on-line-book","chapter":"Setup","heading":"How to use this on-line book","text":"book contains reproducible code can run R environment. three options setup working environment:Install R RStudio (standard users).Use Docker image provided Brazil Data Cube.Install source (advanced users, usually contributors).","code":""},{"path":"setup.html","id":"install-sits-using-r-and-rstudio","chapter":"Setup","heading":"Install sits using R and RStudio","text":"standard installation sits Comprehensive R Archive Network (CRAN), network servers (also known mirrors) around world store --date, versions basic code packages R. suggest staged installation, follows:Get install base R CRAN.Install RStudio Posit website.Run RStudio install packages sf terra, order, using command line:Install sits:run examples book, please also install sitsdata package, available GitHub. install sitsdata, necessary use package devtools.","code":"\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"setup.html","id":"using-docker-images","chapter":"Setup","heading":"Using Docker images","text":"familiar Docker, images sits available RStudio Jupyter notebook. images provided Brazil Data Cube team:Version R RStudio.Version Jupyter Notebooks.Windows Mac platform, install Docker obtain one two images listed Brazil Data Cube. images contain full sits running environment.","code":""},{"path":"setup.html","id":"installation-from-source","chapter":"Setup","heading":"Installation from source","text":"sits package relies sf terra R packages, require GDAL PROJ libraries. Please follow instructions installing sf terra together GDAL, provided Edzer Pebesma.Windows MacOS users strongly encouraged install sf terra binary packages CRAN. install sits source, please install Rtools Windows access compiling environment. Mac, please follow instructions available .Ubuntu, recommend using latest version GDAL, GEOS, PROJ4 libraries binaries. , use repository ubuntugis-unstable, done follows:Getting error adding PPA repository due absence package software-properties-common. GDAL running docker containers, please add security flag --security-opt seccomp=unconfined start.Debian, use rocker geospatial dockerfiles.case Fedora, following command installs required dependencies:installing GDAL, GEOS, PROJ4, please install packages sf terra, order.configuring GDAL, GEOS, PROJ4, please proceed install sits, can installed regular R package.source code repository sits GitHub. two versions available GitHub: master dev. first contains current stable version, either code available CRAN minor update bug fixes. install master version, install development version, contains latest updates might unstable, users install devtools (already available) follows:install development version, contains latest updates might unstable, users install devtools (already available), install sits follows:run examples book, please also install sitsdata package.","code":"sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install libudunits2-dev libgdal-dev libgeos-dev libproj-dev \nsudo apt-get install gdal-bin\nsudo apt-get install proj-binsudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits@dev\", dependencies = TRUE)\noptions(download.file.method = \"wget\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"setup.html","id":"using-gpus-with-sits","chapter":"Setup","heading":"Using GPUs with sits","text":"torch package automatically recognizes GPU available machine uses training classification. significant performance gain GPUs used instead CPUs deep learning models. need specific adjustments torch scripts. use GPUs, torch requires version 11.6 CUDA library, available Ubuntu 18.04 20.04. Please follow detailed instructions setting torch available .","code":"\ninstall.packages(\"torch\")"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"","code":""},{"path":"acknowledgements.html","id":"funding-sources","chapter":"Acknowledgements","heading":"Funding Sources","text":"authors acknowledge funders supported development sits:Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.","code":""},{"path":"acknowledgements.html","id":"community-contributions","chapter":"Acknowledgements","heading":"Community Contributions","text":"authors thank R-spatial community foundational work, including Marius Appel, Tim Appelhans, Robert Hijmans, Jakub Nowosad, Edzer Pebesma, Martijn Tennekes R packages gdalcubes, leafem, terra, supercells, sf/stars, tmap. grateful work Dirk Eddelbuettel Rcpp RcppArmadillo Ron Wehrens package kohonen. much indebted Hadley Wickham tidyverse, Daniel Falbel torch luz packages, RStudio team package leaflet. multiple authors machine learning packages randomForest, e1071, xgboost provided robust algorithms. like thank Python developers shared deep learning algorithms image time series classification: Vivien Sainte Fare Garnot, Zhiguang Wang, Maja Schneider, Marc Rußwurm. first author also thanks Roger Bivand benign influence things related R.","code":""},{"path":"acknowledgements.html","id":"reproducible-papers-and-books-used-in-building-sits","chapter":"Acknowledgements","heading":"Reproducible papers and books used in building sits","text":"thank authors following papers making code papers open reusable. contribution essential build sits.Edzer Pebesma, Simple Features R: Standardized Support Spatial Vector Data. R Journal, 10(1), 2018.Edzer Pebesma, Simple Features R: Standardized Support Spatial Vector Data. R Journal, 10(1), 2018.Martin Tennekes, tmap: Thematic Maps R. Journal Statistical Software, 84(6), 1–39, 2018.Martin Tennekes, tmap: Thematic Maps R. Journal Statistical Software, 84(6), 1–39, 2018.Ron Wehrens Johannes Kruisselbrink, Flexible Self-Organising Maps kohonen 3.0. Journal Statistical Software, 87, 7, 2018.Ron Wehrens Johannes Kruisselbrink, Flexible Self-Organising Maps kohonen 3.0. Journal Statistical Software, 87, 7, 2018.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, Deep learning time series classification: review. Data Mining Knowledge Discovery, 33(4): 917–963, 2019.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, Deep learning time series classification: review. Data Mining Knowledge Discovery, 33(4): 917–963, 2019.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. Temporal Convolutional Neural Network Classification Satellite Image Time Series. Remote Sensing 11 (5), 2019.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. Temporal Convolutional Neural Network Classification Satellite Image Time Series. Remote Sensing 11 (5), 2019.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, Breizhcrops: Time Series Dataset Crop Type Mapping. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, Breizhcrops: Time Series Dataset Crop Type Mapping. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marius Appel Edzer Pebesma, -Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library. Data 4 (3): 1–16, 2020.Marius Appel Edzer Pebesma, -Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library. Data 4 (3): 1–16, 2020.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention, Conference Computer Vision Pattern Recognition, 2020.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention, Conference Computer Vision Pattern Recognition, 2020.Vivien Garnot Loic Landrieu, Lightweight Temporal Self-Attention Classifying Satellite Images Time Series, 2020.Vivien Garnot Loic Landrieu, Lightweight Temporal Self-Attention Classifying Satellite Images Time Series, 2020.Maja Schneider, Marco Körner, [Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention. ReScience C 7 (2), 2021.Maja Schneider, Marco Körner, [Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention. ReScience C 7 (2), 2021.Rolf Simoes, Felipe Souza, Mateus Zaglia, Gilberto Queiroz, Rafael dos Santos Karine Ferreira, Rstac: R Package Access Spatiotemporal Asset Catalog Satellite Imagery. IGARSS, 2021, pp. 7674-7677.Rolf Simoes, Felipe Souza, Mateus Zaglia, Gilberto Queiroz, Rafael dos Santos Karine Ferreira, Rstac: R Package Access Spatiotemporal Asset Catalog Satellite Imagery. IGARSS, 2021, pp. 7674-7677.Jakub Nowosad, Tomasz Stepinksi, Extended SLIC superpixels algorithm applications non-imagery geospatial rasters. International Journal Applied Earth Observations Geoinformation, 2022.Jakub Nowosad, Tomasz Stepinksi, Extended SLIC superpixels algorithm applications non-imagery geospatial rasters. International Journal Applied Earth Observations Geoinformation, 2022.Sigrid Keydana, Deep Learning Scientific Computing R torch, Chapman Hall/CRC, London, 2023.Sigrid Keydana, Deep Learning Scientific Computing R torch, Chapman Hall/CRC, London, 2023.Robin Lovelace, Jakub Nowosad, Jannes Münchow, Geocomputation R. Chapman Hall/CRC, London, 2023.Robin Lovelace, Jakub Nowosad, Jannes Münchow, Geocomputation R. Chapman Hall/CRC, London, 2023.Edzer Pebesma, Roger Bivand, Spatial Data Science: applications R. Chapman Hall/CRC, London, 2023.Edzer Pebesma, Roger Bivand, Spatial Data Science: applications R. Chapman Hall/CRC, London, 2023.","code":""},{"path":"acknowledgements.html","id":"publications-using-sits","chapter":"Acknowledgements","heading":"Publications using sits","text":"section gathers publications used sits generate results.2023Bruno Adorno, Thales Körting, Silvana Amaral, Contribution time-series data cubes classify urban vegetation types remote sensing. Urban Forest & Urban Greening, 79, 127817, 2023.2021Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, Quality control class noise reduction satellite image time series. ISPRS Journal Photogrammetry Remote Sensing, 177, 75–88, 2021.Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, Quality control class noise reduction satellite image time series. ISPRS Journal Photogrammetry Remote Sensing, 177, 75–88, 2021.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series. Remote Sensing, 13(5), 974, 2021.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series. Remote Sensing, 13(5), 974, 2021.2020Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira, Alexandre Carvalho, Land use cover maps Mato Grosso State Brazil 2001 2017. Nature Scientific Data, 7, article 34, 2020.Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira, Alexandre Carvalho, Land use cover maps Mato Grosso State Brazil 2001 2017. Nature Scientific Data, 7, article 34, 2020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017. Land, 9(1), 2020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017. Land, 9(1), 2020.Karine Ferreira, Gilberto Queiroz et al., Earth Observation Data Cubes Brazil: Requirements, Methodology Products. Remote Sensing, 12, 4033, 2020.Karine Ferreira, Gilberto Queiroz et al., Earth Observation Data Cubes Brazil: Requirements, Methodology Products. Remote Sensing, 12, 4033, 2020.Adeline Maciel, Lubia Vinhas, Michelle Picoli, Gilberto Camara, Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier. Land, 9, 506, 2020.Adeline Maciel, Lubia Vinhas, Michelle Picoli, Gilberto Camara, Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier. Land, 9, 506, 2020.2018Michelle Picoli, Gilberto Camara, et al., Big Earth Observation Time Series Analysis Monitoring Brazilian Agriculture. ISPRS Journal Photogrammetry Remote Sensing, 145, 328–339, 2018.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction.html","id":"why-work-with-satellite-image-time-series","chapter":"Introduction","heading":"Why work with satellite image time series?","text":"Satellite images comprehensive source data environment. Covering large area Earth’s surface, images allow researchers study regional global changes. Sensors capture data multiple spectral bands measure physical, chemical, biological properties Earth’s surface. observing location multiple times, satellites provide data changes environment survey areas difficult observe ground. Given unique features, images offer essential information many applications, including deforestation, crop production, food security, urban footprints, water scarcity, land degradation.time series set data points collected regular intervals time. Time series data used analyze trends, patterns, changes. Satellite image time series refer time series obtained collection images captured satellite period time, typically months years. Using time series, experts improve understanding ecological patterns processes. Instead selecting individual images specific dates comparing , researchers track change continuously [1].","code":""},{"path":"introduction.html","id":"time-first-space-later","chapter":"Introduction","heading":"Time-first, space-later","text":"“Time-first, space-later” concept satellite image classification takes time series analysis first step analyzing remote sensing data, spatial information considered time series classified. time-first part brings better understanding changes landscapes. Detecting tracking seasonal long-term trends becomes feasible, well identifying anomalous events patterns data, wildfires, floods, droughts. pixel data cube treated time series, using information available temporal instances case. Time series classification pixel-based, producing set labelled pixels. result used input space-later part method. phase, Bayesian smoothing algorithm considers spatial neighbourhood pixel improves results pixel-based classification.","code":""},{"path":"introduction.html","id":"how-sits-works","chapter":"Introduction","heading":"How sits works","text":"sits package uses satellite image time series land classification, using time-first, space-later approach. data preparation part, collections big Earth observation images organized data cubes. spatial location data cube associated time series. Locations known labels train machine learning algorithm, classifies time series data cube, shown Figure 1.\nFigure 1: Using time series land classification (Source: Authors).\npackage provides tools analysis, visualization, classification satellite image time series. Users follow typical workflow pixel-based classification:Select analysis-ready data image collection cloud providers AWS, Microsoft Planetary Computer, Digital Earth Africa, Brazil Data Cube.Build regular data cube using chosen image collection.Obtain new bands indices operations data cubes.Extract time series samples data cube used training data.Perform quality control filtering time series samples.Train machine learning model using time series samples.Classify data cube using model get class probabilities pixel.Post-process probability cube remove outliers.Produce labeled map post-processed probability cube.Evaluate accuracy classification using best practices.workflow step corresponds function sits API, shown Table Figure 2. functions convenient default parameters behaviors. single function builds machine learning (ML) models. classification function processes big data cubes efficient parallel processing. Since sits API simple learn, users can achieve good results without -depth knowledge machine learning parallel processing.\nTable 1: sits API workflow land classification\n\nFigure 2: Main functions sits API (Source: Authors).\nAdditionally, experts can perform object-based image analysis (OBIA) sits. case, classifying time series, one can use function sits_segments() create set closed polygons. polygons classified using subset time series contained inside segment. details, see Chapter Object-based time series image analysis.","code":""},{"path":"introduction.html","id":"land-use-and-land-cover","chapter":"Introduction","heading":"Land use and land cover","text":"Since main aim sits support land use land cover classification, section presents short discussion use terms. UN Food Agriculture Organization defines land cover “observed biophysical cover Earth’s surface” [2]. Land cover can observed mapped directly remote sensing images. FAO’s guidelines reports, land use described “human activities purposes land managed exploited”. FAO’s land use classifications include classes cropland pasture. Although land cover land use denote different approaches describing Earth’s landscape, practice considerable overlap concepts [3]. classifying remote sensing images, natural areas classified using land cover types (e.g, forest), human-modified areas described land use classes (e.g., pasture).One advantages using image time series land classification capacity measuring changes landscape related agricultural practices. example, time series vegetation index area used crop production show pattern minima (planting sowing stages) maxima (flowering stage). Thus, classification schemas based image time series data can richer detailed associated land cover. follows, use term “land classification” refer image classification represents land cover land use classes.","code":""},{"path":"introduction.html","id":"classes-and-labels","chapter":"Introduction","heading":"Classes and labels","text":"book, distinguish concepts “class” “label”. class denotes group spatial objects share similar land cover land use types, urban areas, forests, water bodies, agricultural fields. Classes defined based specific application study conducted, help analyse vast amount data obtained remote sensing imagery. label assignment identification given specific feature object within image. Labels markers indicate class particular pixel, segment, object belongs. Labels essential supervised classification methods, training dataset known labels used train machine learning algorithm recognize classify new, unlabelled data. Thus, “class” represents overall category group features, “label” refers specific assignment class particular feature object within image.","code":""},{"path":"introduction.html","id":"creating-a-data-cube","chapter":"Introduction","heading":"Creating a data cube","text":"two kinds data cubes sits: () irregular data cubes generated selecting image collections cloud providers AWS Planetary Computer; (b) regular data cubes images fully covering chosen area, image spectral bands spatial resolution, images follow set adjacent regular time intervals. Machine learning applications need regular data cubes. Please refer Chapter Earth observation data cubes details.first steps using sits : () select analysis-ready data image collection available cloud provider stored locally using sits_cube(); (b) collection regular, use sits_regularize() build regular data cube.section shows build data cube local images already organized regular data cube. data cube composed MODIS MOD13Q1 images Sinop region Mato Grosso, Brazil. images indexes NDVI EVI covering one-year period 2013-09-14 2014-08-29 (use “year-month-day” dates). 23 time instances, covering 16-day period. data available R package sitsdata.build data cube local files, users must provide information original source data obtained. case, sits_cube() needs parameters:source, cloud provider data obtained (case, Brazil Data Cube “BDC”);collection, collection cloud provider images extracted. case, data comes MOD13Q1 collection 6;data_dir, local directory image files stored;parse_info, vector strings stating file names store information “tile”, “band”, “date”. case, local images stored files whose names similar TERRA_MODIS_012010_EVI_2014-07-28.tif. file represents image obtained MODIS sensor onboard TERRA satellite, covering part tile 012010 EVI band date 2014-07-28.\nFigure 3: Color composite image MODIS cube NDVI band 2013-09-14 (Source: Authors).\naim parse_info parameter extract tile, band date information file name. Given large variation image file names generated different produces, includes designators X1 X2; place holders parts file name relevant sits_cube().R object returned sits_cube() contains metadata describing contents data cube. includes data source collection, satellite, sensor, tile collection, bounding box, projection, list files. file refers one band image one temporal instances cube.","code":"\n# Create a data cube object based on the information about the files\nsinop <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"satellite\", \"sensor\", \"tile\", \"band\", \"date\")\n)\n# select bands NDVI and EVI\nsinop_2bands <- sits_select(sinop, bands = c(\"NDVI\", \"EVI\"))\n# Plot the NDVI for the first date (2013-09-14)\nplot(sinop_2bands,\n  band = \"NDVI\",\n  dates = \"2013-09-14\",\n  palette = \"RdYlGn\"\n)\n# Show the R object that describes the data cube\nsinop_2bands#> # A tibble: 1 × 11\n#>   source collection satellite sensor tile       xmin    xmax    ymin    ymax crs  \n#>   <chr>  <chr>      <chr>     <chr>  <chr>     <dbl>   <dbl>   <dbl>   <dbl> <chr>\n#> 1 BDC    MOD13Q1-6  TERRA     MODIS  012010  -6.18e6 -5.96e6 -1.35e6 -1.23e6 \"PRO…\n#> # ℹ 1 more variable: file_info <list>"},{"path":"introduction.html","id":"the-time-series-tibble","chapter":"Introduction","heading":"The time series tibble","text":"handle time series information, sits uses tibble. Tibbles extensions data.frame tabular data structures provided tidyverse set packages. example shows time series tibble 1,218 time series obtained MODIS MOD13Q1 images. series four attributes: two bands (NIR MIR) two indexes (NDVI EVI). data set available package sitsdata.time series tibble contains data metadata. first six columns contain metadata: spatial temporal information, label assigned sample, data cube data extracted. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band. details handling time series data, please see Chapter Working time series.helpful plot dispersion time series. follows, brevity, filter one label (Forest) select one index (NDVI). Note filtering label use function dplyr package, selecting index use sits_select(). resulting plot shows time series associated label Forest index NDVI, highlighting median first third quartiles.\nFigure 4: Joint plot samples band NDVI label Forest (Source: Authors).\n","code":"\n# Load the MODIS samples for Mato Grosso from the \"sitsdata\" package\nlibrary(tibble)\nlibrary(sitsdata)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\nsamples_matogrosso_mod13q1[1:2, ]#> # A tibble: 2 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\nsamples_forest <- dplyr::filter(\n  samples_matogrosso_mod13q1,\n  label == \"Forest\"\n)\nsamples_forest_ndvi <- sits_select(\n  samples_forest,\n  band = \"NDVI\"\n)\nplot(samples_forest_ndvi)"},{"path":"introduction.html","id":"training-a-machine-learning-model","chapter":"Introduction","heading":"Training a machine learning model","text":"next step train machine learning (ML) model using sits_train(). takes two inputs, samples (time series table) ml_method (function implements machine learning algorithm). result model used classification. ML algorithm requires specific parameters user-controllable. novice users, sits provides default parameters produce good results. Please see Chapter Machine learning data cubes details.Since time series data four attributes (EVI, NDVI, NIR, MIR) data cube images two, select NDVI EVI values use resulting data training. build classification model, use random forest model called sits_rfor().\nFigure 5: relevant variables trained random forest model (Source: Authors).\n","code":"\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# Train a random forest model\nrf_model <- sits_train(\n  samples = samples_2bands,\n  ml_method = sits_rfor()\n)\n# Plot the most important variables of the model\nplot(rf_model)"},{"path":"introduction.html","id":"data-cube-classification","chapter":"Introduction","heading":"Data cube classification","text":"training machine learning model, next step classify data cube using sits_classify(). function produces set raster probability maps, one class. maps, value pixel proportional probability belongs class. function two mandatory parameters: data, data cube time series tibble classified; ml_model, trained ML model. Optional parameters include: () multicores, number cores used; (b) memsize, RAM used classification; (c) output_dir, directory classified raster files written. Details classification process available “Image classification data cubes”.\nFigure 6: Probability map class Forest (Source: Authors).\ncompleting classification, plot probability maps class Forest. Probability maps helpful visualize degree confidence classifier assigns labels pixel. can used produce uncertainty information support active learning, described Chapter Image classification data cubes.","code":"\n# Classify the raster image\nsinop_probs <- sits_classify(\n  data = sinop_2bands,\n  ml_model = rf_model,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\n# Plot the probability cube for class Forest\nplot(sinop_probs, labels = \"Forest\", palette = \"YlGnBu\")"},{"path":"introduction.html","id":"spatial-smoothing","chapter":"Introduction","heading":"Spatial smoothing","text":"working big Earth observation data, much variability class. result, pixels misclassified. errors likely occur transition areas classes. address problems, sits_smooth() takes probability cube input uses class probabilities pixel’s neighborhood reduce labeling uncertainty. Plotting smoothed probability map class Forest shows outliers removed.\nFigure 7: Smoothed probability map class Forest (Source: Authors).\n","code":"\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_bayes, labels = \"Forest\", palette = \"YlGnBu\")"},{"path":"introduction.html","id":"labeling-a-probability-data-cube","chapter":"Introduction","heading":"Labeling a probability data cube","text":"removing outliers using local smoothing, final classification map can obtained using sits_label_classification(). function assigns pixel class highest probability.\nFigure 8: Classification map Sinop (Source: Authors).\nplotting classified map, users can control map display setting various options associated tmap_options. options include: () scale (default = 0.5); (b) graticules_labels_size (default: 0.7); (c) legend_title_size (default: 1.0); (d) legend_text_size (default: 1.0); (e) legend_width (default: 0.5); (f) legend_height (default: 0.7); (g) legend_position (default: c(“left”, “bottom”). scale parameter affect others. Users first try adjust fine-tuning options.resulting classification files can read QGIS. Links associated files available sinop_map object nested table file_info.simplify process importing data QGIS, color palette used display classified maps sits can exported QGIS style using sits_colors_qgis. function takes two parameters: () cube, classified data cube; (b) file, file QGIS style XML written . case study, suffices following command.","code":"\n# Label the probability file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_map,\n  title = \"Sinop Classification Map\",\n  tmap_options = list(\"scale\" = 0.7)\n)\n# Show the location of the classification file\nsinop_map$file_info[[1]]#> # A tibble: 1 × 12\n#>   band  start_date end_date   ncols nrows  xres  yres      xmin      xmax     ymin\n#>   <chr> <date>     <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>     <dbl>    <dbl>\n#> 1 class 2013-09-14 2014-08-29   944   551  232.  232. -6181982. -5963298.  -1.35e6\n#> # ℹ 2 more variables: ymax <dbl>, path <chr>\n# Show the location of the classification file\nsits_colors_qgis(sinop_map, file = \"./tempdir/chp3/qgis_style.xml\")"},{"path":"introduction.html","id":"visualization-of-data-cubes-in-interactive-maps","chapter":"Introduction","heading":"Visualization of data cubes in interactive maps","text":"chapter, used plot() produce graphical display data cubes, time series, models. Data cubes samples can also shown interactive maps using sits_view(). function creates tiled overlays different kinds data cubes, allowing comparison original, intermediate final results. also includes background maps. following example creates interactive map combining original data cube classified map.","code":"\nsits_view(sinop, band = \"NDVI\", class_cube = sinop_map)"},{"path":"earth-observation-data-cubes.html","id":"earth-observation-data-cubes","chapter":"Earth observation data cubes","heading":"Earth observation data cubes","text":"","code":""},{"path":"earth-observation-data-cubes.html","id":"analysis-ready-data-image-collections","chapter":"Earth observation data cubes","heading":"Analysis-ready data image collections","text":"Analysis-ready data (ARD) images ready analysis without need preprocessing transformation. simplify accelerate analysis Earth observation data providing consistent high-quality data standardized across different sensors platforms. ARD data typically provided collection files, pixel contains single value spectral band given date.ARD collections available cloud services Amazon Web Service, Brazil Data Cube, Digital Earth Africa, Swiss Data Cube, Microsoft’s Planetary Computer. collections processed improve multidate comparability. Radiance measures top atmosphere converted ground reflectance measures. general, timelines images ARD collection different. Images still contain cloudy missing pixels; bands images collection may different resolutions. Figure 9 shows example Landsat ARD image collection.\nFigure 9: ARD image collection (Source: USGS. Reproduction based fair use doctrine).\nARD image collections organized spatial partitions. Sentinel-2/2A images follow Military Grid Reference System (MGRS) tiling system, divides world 60 UTM zones 8 degrees longitude. zone blocks 6 degrees latitude. Blocks split tiles 110 \\(\\times\\) 110 km\\(^2\\) 10 km overlap. Figure 10 shows MGRS tiling system part Northeastern coast Brazil, contained UTM zone 24, block M.\nFigure 10: MGRS tiling system used Sentinel-2 images (Source: GISSurfer 2.0. Reproduction based fair use doctrine).\nLandsat-4/5/7/8/9 satellites use Worldwide Reference System (WRS-2), breaks coverage Landsat satellites images identified path row (see Figure 11). path descending orbit satellite; WRS-2 system 233 paths per orbit, path 119 rows, row refers latitudinal center line frame imagery. Images WRS-2 geometrically corrected UTM projection.\nFigure 11: WRS-2 tiling system used Landsat-5/7/8/9 images (Source: INPE ESRI. Reproduction based fair use doctrine).\n","code":""},{"path":"earth-observation-data-cubes.html","id":"ard-image-collections-handled-by-sits","chapter":"Earth observation data cubes","heading":"ARD image collections handled by sits","text":"Package sits supports access following ARD image collections:Amazon Web Services (AWS): Open data Sentinel-2/2A level 2A collections Earth’s land surface.Brazil Data Cube (BDC): Open data collections Sentinel-2/2A, Landsat-8, CBERS-4/4A, MODIS images Brazil. collections organized regular data cubes.Digital Earth Africa (DEAFRICA): Open data collections Sentinel-2/2A Landsat-8 Africa.Microsoft Planetary Computer (MPC): Open data collections Sentinel-2/2A Landsat-4/5/7/8/9 Earth’s land areas.USGS: Landsat-4/5/7/8/9 collections available AWS, require access payment.Swiss Data Cube (SDC): Open data collection Sentinel-2/2A Landsat-8 images Switzerland.Harmonized Landsat-Sentinel (HLS): HLS, provided NASA, collection processes Landsat 8 Sentinel-2 imagery common standard.","code":""},{"path":"earth-observation-data-cubes.html","id":"regular-image-data-cubes","chapter":"Earth observation data cubes","heading":"Regular image data cubes","text":"Machine learning deep learning (ML/DL) classification algorithms require input data consistent. dimensionality data used training model data classified. gaps missing values. Thus, use ML/DL algorithms remote sensing data, ARD image collections converted regular data cubes. Adapting previous definition Appel Pebesma [4], consider regular data cube following definition properties:regular data cube four-dimensional structure dimensions x (longitude easting), y (latitude northing), time, bands. spatial, temporal, attribute dimensions independent interchangeable.spatial dimensions refer coordinate system, grids defined UTM (Universal Transverse Mercator) MGRS (Military Grid Reference System). grid (tile) grid corresponds unique zone coordinate system.temporal dimension set continuous equally-spaced intervals.every combination dimensions, cell single value.cells data cube spatiotemporal extent. spatial resolution cell X Y dimensions. temporal intervals . cell contains valid set measures. pixel associated unique coordinate zone coordinate system. position space, data cube provide set valid time series. time interval, regular data cube provide valid 2D image (see Figure 12.\nFigure 12: Conceptual view data cubes (Source: Authors).\nCurrently, cloud service provides regular data cubes default Brazil Data Cube (BDC). ARD collections available AWS, MPC, USGS, DEAFRICA regular space time. Bands may different resolutions, images may cover entire time, time intervals may irregular. reason, subsets collections need converted regular data cubes processing. produce data cubes machine-learning data analysis, users first create irregular data cube ARD collection use sits_regularize(), described .","code":""},{"path":"earth-observation-data-cubes.html","id":"creating-data-cubes","chapter":"Earth observation data cubes","heading":"Creating data cubes","text":"obtain information ARD image collection cloud providers, sits uses SpatioTemporal Asset Catalogue (STAC) protocol, specification geospatial information many large image collection providers adopted. ‘spatiotemporal asset’ file represents information Earth captured specific space time. access STAC endpoints, sits uses rstac R package.function sits_cube() supports access image collections cloud services; following parameters:source: Name provider.collection: collection available provider supported sits. find collections supported sits, see sits_list_collections().platform: Optional parameter specifying platform collections multiple satellites.tiles: Set tiles image collection reference system. Either tiles roi specified.roi: region interest. Either: () named vector (lon_min, lon_max, lat_min, lat_max) WGS 84 coordinates; (b) sf object. images intersecting convex hull roi selected.bands: Optional parameter bands used. missing, bands collection used.start_date: initial date temporal interval containing time series images.end_date: final date temporal interval containing time series images.result sits_cube() tibble description selected images required processing. contain actual data, pointers images. attributes individual image files can assessed listing file_info column tibble.","code":""},{"path":"earth-observation-data-cubes.html","id":"assessing-amazon-web-services","chapter":"Earth observation data cubes","heading":"Assessing Amazon Web Services","text":"Amazon Web Services (AWS) holds two kinds collections: open-data requester-pays. Open data collections can accessed without cost. Requester-pays collections require payment AWS account. Currently, sits supports collection SENTINEL-2-L2A open data. bands 10 m resolution B02, B03, B04, B08. 20 m bands B05, B06, B07, B8A, B11, B12. Bands B01 B09 available 60 m resolution. CLOUD band also available. example shows access one tile open data SENTINEL-2-L2A collection. tiles parameter allows selecting desired area according MGRS reference system.\nFigure 13: Sentinel-2 image area Northeastern coast Brazil.\n","code":"\n# Create a data cube covering an area in Brazil\ns2_23MMU_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"23MMU\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2018-07-12\",\n  end_date = \"2019-07-28\"\n)\nplot(s2_23MMU_cube,\n  red = \"B11\",\n  blue = \"B02\",\n  green = \"B8A\",\n  date = \"2018-10-05\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-microsofts-planetary-computer","chapter":"Earth observation data cubes","heading":"Assessing Microsoft’s Planetary Computer","text":"Microsoft’s Planetary Computer (MPC) hosts two open data collections: SENTINEL-2-L2A LANDSAT-C2-L2. first collection contains SENTINEL-2/2A ARD images, bands resolutions available AWS (see ). example shows access SENTINEL-2-L2A collection.\nFigure 14: Sentinel-2 image area state Rondonia, Brazil (Source: Authors).\nLANDSAT-C2-L2 collection provides access data Landsat-4/5/7/8/9 satellites. Images satellites intercalibrated ensure data consistency. compatibility different Landsat sensors, band names BLUE, GREEN, RED, NIR08, SWIR16, SWIR22. images 30 m resolution. collection, tile search supported; roi parameter used. example shows retrieve data region interest covering city Brasilia Brazil.\nFigure 15: Landsat-8 image area Northeast Brazil (Source: Authors).\n","code":"\n# Create a data cube covering an area in the Brazilian Amazon\ns2_20LKP_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"20LKP\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2019-07-01\",\n  end_date = \"2019-07-28\"\n)\n# Plot a color composite of one date of the cube\nplot(s2_20LKP_cube_MPC,\n  red = \"B11\", blue = \"B02\", green = \"B8A\",\n  date = \"2019-07-18\"\n)\n# Read a ROI that covers part of the Northeastern coast of Brazil\nroi <- c(\n  lon_min = -43.5526, lat_min = -2.9644,\n  lon_max = -42.5124, lat_max = -2.1671\n)\n# Select the cube\ns2_L8_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"LANDSAT-C2-L2\",\n  bands = c(\"BLUE\", \"RED\", \"GREEN\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi = roi,\n  start_date = \"2019-06-01\",\n  end_date = \"2019-09-01\"\n)\n# Plot the tile that covers the Lencois Maranhenses\nplot(s2_L8_cube_MPC,\n  red = \"RED\", green = \"GREEN\", blue = \"BLUE\",\n  date = \"2019-06-30\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-digital-earth-africa","chapter":"Earth observation data cubes","heading":"Assessing Digital Earth Africa","text":"Digital Earth Africa (DEAFRICA) cloud service provides open-access Earth observation data African continent. ARD image collections sits S2_L2A (Sentinel-2 level 2A) LS8_SR (Landsat-8). Since STAC interface DEAFRICA implement concept tiles, users need specify area interest using roi parameter. requested roi produces cube contains three MGRS tiles (“35HLD”, “35HKD”, “35HLC”) covering part South Africa.\nFigure 16: Sentinel-2 image area South Africa.\n","code":"\ndea_cube <- sits_cube(\n  source = \"DEAFRICA\",\n  collection = \"S2_L2A\",\n  roi = c(\n    lon_min = 24.97, lat_min = -34.30,\n    lon_max = 25.87, lat_max = -32.63\n  ),\n  bands = c(\"B05\", \"B8A\", \"B11\"),\n  start_date = \"2019-09-01\",\n  end_date = \"2019-10-01\"\n)\nplot(dea_cube, red = \"B11\", blue = \"B05\", green = \"B8A\")"},{"path":"earth-observation-data-cubes.html","id":"assessing-the-brazil-data-cube","chapter":"Earth observation data cubes","heading":"Assessing the Brazil Data Cube","text":"Brazil Data Cube (BDC) built Brazil’s National Institute Space Research (INPE), provide regular EO data cubes CBERS, LANDSAT, SENTINEL-2, TERRA/MODIS satellites environmental applications. collections available BDC : LANDSAT-OLI-16D (Landsat-8 OLI, 30 m resolution, 16-day intervals), SENTINEL-2-16D (Sentinel-2A 2B MSI images 10 m resolution, 16-day intervals), CBERS-WFI-16D (CBERS 4 WFI, 64 m resolution, 16-day intervals), CBERS-WFI-8D(CBERS 4 4A WFI images, 64m resolution, 8-day intervals) CBERS-MUX-2M (CBERS 4/4A MUX, 20 m resolution, two-month intervals), MOD13Q1-6 (MODIS MOD13SQ1 product, collection 6, 250 m resolution, 16-day intervals). details, use sits_list_collections(source = \"BDC\").BDC uses three hierarchical grids based Albers Equal Area projection SIRGAS 2000 datum. large grid tiles 4224.4 \\(\\times4\\) 224.4 km2 used CBERS-4 AWFI collections 64 m resolution; CBERS-4 AWFI tile contains images 6600 \\(\\times\\) 6600 pixels. medium grid used Landsat-8 OLI collections 30 m resolution; tiles extension 211.2 \\(\\times\\) 211.2 km2, image 7040 \\(\\times\\) 7040 pixels. small grid covers 105.6 \\(\\times\\) 105.6 km2 used Sentinel-2 MSI collections 10 m resolutions; image 10560 \\(\\times\\) 10560 pixels. data cubes BDC regularly spaced time cloud-corrected [5].\nFigure 17: Hierarchical BDC tiling system showing () large BDC grid overlayed Brazilian biomes, (b) one large tile, (c) four medium tiles, (d) sixteen small tiles (Source: Ferreira et al. (2020). Reproduction fair use doctrine).\naccess BDC, users must provide credentials using environment variables, shown . Obtaining BDC access key free. Users must register BDC site obtain key.example , data cube defined one tile (“005004”) CBERS-WFI-16D collection, holds CBERS AWFI images 16 days resolution.\nFigure 18: CBERS-4 WFI image Cerrado area Brazil.\n","code":"\n# Define a tile from the CBERS-4/4A AWFI collection\ncbers_tile <- sits_cube(\n  source = \"BDC\",\n  collection = \"CBERS-WFI-16D\",\n  tiles = \"005004\",\n  bands = c(\"B13\", \"B14\", \"B15\", \"B16\", \"CLOUD\"),\n  start_date = \"2021-05-01\",\n  end_date = \"2021-09-01\"\n)\n# Plot one time instance\nplot(cbers_tile,\n  red = \"B15\",\n  green = \"B16\",\n  blue = \"B13\",\n  date = \"2021-05-09\"\n)"},{"path":"earth-observation-data-cubes.html","id":"accessing-harmonized-landsat-sentinel-collections","chapter":"Earth observation data cubes","heading":"Accessing Harmonized Landsat-Sentinel collections","text":"Harmonized Landsat Sentinel (HLS) NASA initiative processes harmonizes Landsat 8 Sentinel-2 imagery common standard, including atmospheric correction, alignment, resampling, corrections BRDF (bidirectional reflectance distribution function). purpose HLS project create unified consistent dataset integrates advantages systems, making easier users work data.NASA Harmonized Landsat Sentinel (HLS) service provides two image collections:Landsat 8 OLI Surface Reflectance HLS (HLSL30) – HLSL30 product includes atmospherically corrected surface reflectance Landsat 8 OLI sensors 30 m resolution. dataset includes 11 spectral bands.Landsat 8 OLI Surface Reflectance HLS (HLSL30) – HLSL30 product includes atmospherically corrected surface reflectance Landsat 8 OLI sensors 30 m resolution. dataset includes 11 spectral bands.Sentinel-2 MultiSpectral Instrument Surface Reflectance HLS (HLSS30) – HLSS30 product includes atmospherically corrected surface reflectance Sentinel-2 MSI sensors 30 m resolution. dataset includes 12 spectral bands.Sentinel-2 MultiSpectral Instrument Surface Reflectance HLS (HLSS30) – HLSS30 product includes atmospherically corrected surface reflectance Sentinel-2 MSI sensors 30 m resolution. dataset includes 12 spectral bands.HLS tiling system identical one used Sentinel-2 (MGRS). tiles dimension 109.8 km overlap 4,900 m side.access NASA HLS, users need registed NASA EarthData, save login password ~/.netrc plain text file Unix (%HOME%_netrc Windows). file must contain following fields:Access images NASA HLS done region interest. following example shows HLS Sentinel-2 image Brazilian coast.\nFigure 19: Plot Sentinel-2 image obtained NASA HLS collection single tile showing island Ilhabela Brazilian coast.\nImages HLS Landsat Sentinel-2 collections accessed separately can combined sits_merge(). script creates HLS Landsat cube area Sentinel-2 cube bands. two cubes merged.Comparing timelines original cubes merged one, one can see benefits merged collection time series data analysis.\nFigure 20: Plot Landsat-8 image obtained NASA HLS collection single tile showing island Ilhabela Brazilian coast.\n","code":"machine urs.earthdata.nasa.gov\nlogin <username>\npassword <password>\n# define a region of interest\nroi <- c(\n  lon_min = -45.6422, lat_min = -24.0335,\n  lon_max = -45.0840, lat_max = -23.6178\n)\n\n# create a cube from the HLSS30 collection\nhls_cube_s2 <- sits_cube(\n  source = \"HLS\",\n  collection = \"HLSS30\",\n  roi = roi,\n  bands = c(\"BLUE\", \"GREEN\", \"RED\", \"CLOUD\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2020-09-01\"),\n  progress = FALSE\n)\n# plot the cube\nplot(hls_cube_s2, red = \"RED\", green = \"GREEN\", blue = \"BLUE\", date = \"2020-06-20\")\n# define a region of interest\nroi <- c(\n  lon_min = -45.6422, lat_min = -24.0335,\n  lon_max = -45.0840, lat_max = -23.6178\n)\n\n# create a cube from the HLSS30 collection\nhls_cube_l8 <- sits_cube(\n  source = \"HLS\",\n  collection = \"HLSL30\",\n  roi = roi,\n  bands = c(\"BLUE\", \"GREEN\", \"RED\", \"CLOUD\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2020-09-01\"),\n  progress = FALSE\n)\n# merge the Sentinel-2 and Landsat-8 cubes\nhls_cube_merged <- sits_merge(hls_cube_s2, hls_cube_l8)\n# Timeline of the Sentinel-2 cube\nsits_timeline(hls_cube_s2)#>  [1] \"2020-06-15\" \"2020-06-20\" \"2020-06-25\" \"2020-06-30\" \"2020-07-05\" \"2020-07-10\"\n#>  [7] \"2020-07-20\" \"2020-07-25\" \"2020-08-04\" \"2020-08-09\" \"2020-08-14\" \"2020-08-19\"\n#> [13] \"2020-08-24\" \"2020-08-29\"\n# Timeline of the Landsat-8 cube\nsits_timeline(hls_cube_l8)#> [1] \"2020-06-09\" \"2020-06-25\" \"2020-07-11\" \"2020-07-27\" \"2020-08-12\" \"2020-08-28\"\n# Timeline of the Landsat-8 cube\nsits_timeline(hls_cube_merged)#>  [1] \"2020-06-09\" \"2020-06-15\" \"2020-06-20\" \"2020-06-25\" \"2020-06-30\" \"2020-07-05\"\n#>  [7] \"2020-07-10\" \"2020-07-11\" \"2020-07-20\" \"2020-07-25\" \"2020-07-27\" \"2020-08-04\"\n#> [13] \"2020-08-09\" \"2020-08-12\" \"2020-08-14\" \"2020-08-19\" \"2020-08-24\" \"2020-08-28\"\n#> [19] \"2020-08-29\"\n# plotting a harmonized Landsat image from the merged data set\n# plot the cube\nplot(hls_cube_merged,\n  red = \"RED\",\n  green = \"GREEN\",\n  blue = \"BLUE\",\n  date = \"2020-07-11\"\n)"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-ard-local-files","chapter":"Earth observation data cubes","heading":"Defining a data cube using ARD local files","text":"ARD images downloaded cloud collections local computer associated STAC endpoint describes . must organized named allow sits create data cube . local files directory spatial resolution projection. file must contain single image band single date. file name needs include tile, date, band information. Users must provide information original data source allow sits retrieve information image attributes band names, missing values, etc. working local cubes, sits_cube() needs following parameters:source: Name original data provider; list providers collections, use sits_list_collections().collection: Collection data extracted.data_dir: Local directory images.bands: Optional parameter describe bands retrieved.parse_info: Information parse file names. File names need contain information tile, date, band, separated delimiter (usually \"_\").delim: Separator character descriptors file name (default \"_\").example shows define data cube using files sitsdata package. data set contains part tile “20LMR” Sentinel-2 images period 2022-01-05 2021-08-26, bands B02, B8A, B11. Data extracted collection “SENTINEL-2-L2A” Microsoft Planetary Computer (“MPC”).general, sits users need match local file names values provided parse_info parameter. Since file names data set use format SENTINEL-2_MSI_20LMR_B8A_2022-12-23.tif, fits default value parse_info c(\"X1\", \"X2\", \"tile\", \"band\", \"date\") delim “_“, necessary set values creating data cube local files.\nFigure 21: Sentinel-2 image area Rondonia, Brazil (Source: Authors).\n","code":"\nlibrary(sits)\n# Create a cube based on a stack of CBERS data\ndata_dir <- system.file(\"extdata/Rondonia-20LKP\", package = \"sitsdata\")\n# List the first file\nlist.files(data_dir)[1]#> [1] \"SENTINEL-2_MSI_20LKP_B02_2020-06-04.tif\"\n# Create a data cube from local files\ns2_cube_20LKP <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n\n# Plot the band B8A in the first time instance\nplot(s2_cube_20LKP,\n  red = \"B11\", green = \"B8A\", blue = \"B02\",\n  date = \"2020-07-22\"\n)"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-classified-images","chapter":"Earth observation data cubes","heading":"Defining a data cube using classified images","text":"also possible create local cubes based results produced classification post-classification algorithms. case, parameters required, parameter parse_info specified differently, follows:source: Name original data provider.collection: Name collection data extracted.data_dir: Local directory classified images.band: Band name associated type result. Use: () probs probability cubes produced sits_classify(); (b) bayes, cubes produced sits_smooth(); (c) entropy, least, ratio margin, according method selected using sits_uncertainty(); (d) class classified cubes.labels: Labels associated names classes (required cubes produced sits_uncertainty()).version: Version result (default = v1).parse_info: File name parsing information allow sits deduce values tile, start_date, end_date, band, version file name. Unlike non-classified image files, cubes produced classification post-classification start_date end_date.following code creates results cube based classification deforestation Brazil. classified cube obtained large data cube Sentinel-2 images, covering state Rondonia, Brazil comprising 40 tiles, 10 spectral bands, covering period 2020-06-01 2021-09-11. Samples four classes trained random forest classifier. Internally, classified images use integers represent classes. Thus, labels associated integers represent class name.\nFigure 22: Classified data cube year 2020/2021 Rondonia, Brazil (Source: Authors).\n","code":"\n# Create a cube based on a classified image\ndata_dir <- system.file(\"extdata/Rondonia-20LLP\",\n  package = \"sitsdata\"\n)\n# File name  \"SENTINEL-2_MSI_20LLP_2020-06-04_2021-08-26_class_v1.tif\"\nRondonia_class_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  bands = \"class\",\n  labels = c(\n    \"1\" = \"Burned_Area\", \"2\" = \"Cleared_Area\",\n    \"3\" = \"Highly_Degraded\", \"4\" = \"Forest\"\n  ),\n  data_dir = data_dir,\n  parse_info = c(\n    \"satellite\", \"sensor\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  )\n)\n# Plot the classified cube\nplot(Rondonia_class_cube,\n  tmap_options = list(\n    \"tmap_legend_title_size\" = 1.0,\n    \"tmap_legend_text_size\" = 0.7\n  )\n)"},{"path":"earth-observation-data-cubes.html","id":"regularizing-data-cubes","chapter":"Earth observation data cubes","heading":"Regularizing data cubes","text":"ARD collections available AWS, MPC, USGS, DEAFRICA regular space time. Bands may different resolutions, images may cover entire tile, time intervals irregular. reason, data collections need converted regular data cubes calling sits_regularize(), uses gdalcubes package [4].following example, user created irregular data cube Sentinel-2 collection available Microsoft’s Planetary Computer (MPC) tiles 20LKP 20LLP state Rondonia, Brazil. first build irregular data cube using sits_cube().\nFigure 23: Sentinel-2 tile 20LLP date 2018-07-03 (Source: Authors).\ndifferent acquisition orbits Sentinel-2 Sentinel-2A satellites, two tiles also different timelines. Tile 20LKP 12 instances, tile 20LLP 24 instances chosen period. function sits_regularize() builds data cube regular timeline best estimate valid pixel interval. period parameter sets time interval two images. Values period use ISO8601 time period specification, defines time intervals P[n]Y[n]M[n]D, “Y” stands years, “M” months, “D” days. Thus, P1M stands one-month period, P15D fifteen-day period. joining different images get best image period, sits_regularize() uses aggregation method organizes images chosen interval order increasing cloud cover selects first cloud-free pixel.\nFigure 24: Regularized image tile Sentinel-2 tile 20LLP (Source: Authors).\nobtaining regular data cube, users can perform data analysis classification operations, shown following chapters.","code":"\n# Creating an irregular data cube from MPC\ns2_cube <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = c(\"20LKP\", \"20LLP\"),\n  bands = c(\"B05\", \"B8A\", \"B12\", \"CLOUD\"),\n  start_date = as.Date(\"2018-07-01\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# Show the different timelines of the cube tiles\nsits_timeline(s2_cube)#> $`20LKP`\n#>  [1] \"2018-07-03\" \"2018-07-08\" \"2018-07-13\" \"2018-07-18\" \"2018-07-23\" \"2018-07-28\"\n#>  [7] \"2018-08-02\" \"2018-08-07\" \"2018-08-12\" \"2018-08-17\" \"2018-08-22\" \"2018-08-27\"\n#> \n#> $`20LLP`\n#>  [1] \"2018-07-03\" \"2018-07-05\" \"2018-07-08\" \"2018-07-10\" \"2018-07-13\" \"2018-07-15\"\n#>  [7] \"2018-07-18\" \"2018-07-20\" \"2018-07-23\" \"2018-07-25\" \"2018-07-28\" \"2018-07-30\"\n#> [13] \"2018-08-02\" \"2018-08-04\" \"2018-08-07\" \"2018-08-09\" \"2018-08-12\" \"2018-08-14\"\n#> [19] \"2018-08-17\" \"2018-08-19\" \"2018-08-22\" \"2018-08-24\" \"2018-08-27\" \"2018-08-29\"\n# plot the first image of the irregular cube\ns2_cube %>%\n  dplyr::filter(tile == \"20LLP\") %>%\n  plot(red = \"B12\", green = \"B8A\", blue = \"B05\", date = \"2018-07-03\")\n# Regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n  cube       = s2_cube,\n  output_dir = \"./tempdir/chp4\",\n  res        = 120,\n  period     = \"P15D\",\n  multicores = 4\n)\n# Plot the first image of the tile 20LLP of the regularized cube\n# The pixels of the regular data cube cover the full MGRS tile\nreg_cube %>%\n  dplyr::filter(tile == \"20LLP\") %>%\n  plot(red = \"B12\", green = \"B8A\", blue = \"B05\")"},{"path":"operations-on-data-cubes.html","id":"operations-on-data-cubes","chapter":"Operations on data cubes","heading":"Operations on data cubes","text":"","code":""},{"path":"operations-on-data-cubes.html","id":"pixel-based-and-neighborhood-based-operations","chapter":"Operations on data cubes","heading":"Pixel-based and neighborhood-based operations","text":"Pixel-based operations remote sensing images refer image processing techniques operate individual pixels cells image without considering spatial relationships neighboring pixels. operations typically applied pixel image independently can used extract information spectral, radiometric, spatial properties. Pixel-based operations produce spectral indexes combine data multiple bands.Neighborhood-based operations applied groups pixels image. neighborhood typically defined rectangular circular region centered given pixel. operations can used removing noise, detecting edges, sharpening, among uses.sits_apply() function computes new indices desired mathematical operation function bands available cube using valid R expression. applies operation tiles temporal intervals. two types operations sits_apply():Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).following examples show use sits_apply().","code":""},{"path":"operations-on-data-cubes.html","id":"computing-vegetation-indexes","chapter":"Operations on data cubes","heading":"Computing vegetation indexes","text":"Using vegetation indexes established practice remote sensing. indexes aim improve discrimination vegetation structure combining two wavebands, one leaf pigments reflect incoming light another leaves absorb incoming radiation. Green leaves natural vegetation forests strong emissivity rate near-infrared bands low emissivity rates red bands electromagnetic spectrum. spectral properties used calculate Normalized Difference Vegetation Index (NDVI), widely used index computed normalized difference values infra-red red bands. Including red-edge bands Sentinel-2 images broadened scope bands used calculate indices [6], [7]. follows, show examples vegetation index calculation using Sentinel-2 data cube.First, define data cube tile state Rondonia, Brazil, including bands used compute different vegetation indexes. regularize cube using target resolution 60 m reduce processing time.many options calculating vegetation indexes using Sentinel-2 bands. widely used method combines band B08 (785-899 nm) band B04 (650-680 nm). Recent works literature propose using red-edge bands B05 (698-713 nm), B06 (733-748 nm), B07 (773-793 nm) capturing subtle variations chlorophyll absorption producing indexes, called Normalized Difference Vegetation Red-edge indexes (NDRE) [6]. recent review, Chaves et al. argue red-edge bands important distinguishing leaf structure chlorophyll content different vegetation species [8]. example , show include indexes regular data cube Sentinel-2 spectral bands.first calculate NDVI usual way, using bands B08 B04.\nFigure 25: NDVI using bands B08 B04 Sentinel-2 (Source: Authors).\nnow compare traditional NDVI vegetation index computed using red-edge bands. example NDRE1 index, obtained using bands B06 B05. Sun et al. argue vegetation index built using bands B06 B07 provides better approximation leaf area index estimates NDVI [7]. Notice contrast forests deforested areas robust NDRE1 index NDVI.\nFigure 26: NDRE1 using bands B06 B05 Sentinel-2 (Source: Authors).\n","code":"\n# Create a directory to store files\nif (!file.exists(\"./tempdir/chp5\")) {\n  dir.create(\"./tempdir/chp5\")\n}\n# Create an irregular data cube from MSPC\ns2_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LKP\",\n  bands = c(\n    \"B02\", \"B03\", \"B04\",\n    \"B05\", \"B06\", \"B07\",\n    \"B08\", \"B8A\", \"B11\",\n    \"B12\", \"CLOUD\"\n  ),\n  start_date = as.Date(\"2018-07-01\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# Regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n  cube       = s2_cube,\n  output_dir = \"./tempdir/chp5\",\n  res        = 60,\n  period     = \"P15D\",\n  multicores = 4\n)\n# Calculate NDVI index using bands B08 and B04\nreg_cube <- sits_apply(reg_cube,\n  NDVI = (B08 - B04) / (B08 + B04),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)#> Warning: The provided band 'NDVI' already exists in cube.\nplot(reg_cube, band = \"NDVI\", palette = \"RdYlGn\")\n# Calculate NDRE1 index using bands B06 and B05\nreg_cube <- sits_apply(reg_cube,\n  NDRE1 = (B06 - B05) / (B06 + B05),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)#> Warning: The provided band 'NDRE1' already exists in cube.\n# Plot NDRE1 index\nplot(reg_cube, band = \"NDRE1\", palette = \"RdYlGn\")"},{"path":"operations-on-data-cubes.html","id":"spectral-indexes-for-identifying-burned-areas","chapter":"Operations on data cubes","heading":"Spectral indexes for identifying burned areas","text":"Band combination can also generate spectral indices detecting degradation fires, important element environmental degradation. Forest fires significantly impact emissions impoverish natural ecosystems [9]. Fires open canopy, making microclimate drier increasing amount dry fuel [10]. One well-established technique detecting burned areas remote sensing images normalized burn ratio (NBR), difference near-infrared short wave infrared band, calculated using bands B8A B12.\nFigure 27: NBR ratio regular data cube built using Sentinel-2 tiles 20LKP 20LLP (Source: Authors).\n","code":"\n# Calculate the NBR index\nreg_cube <- sits_apply(reg_cube,\n  NBR = (B12 - B8A) / (B12 + B8A),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)#> Warning: The provided band 'NBR' already exists in cube.\n# Plot the NBR for the first date\nplot(reg_cube, band = \"NBR\", palette = \"Reds\")"},{"path":"operations-on-data-cubes.html","id":"spectral-mixture-analysis","chapter":"Operations on data cubes","heading":"Spectral mixture analysis","text":"Many pixels images medium-resolution satellites Landsat Sentinel-2 contain mixture spectral responses different land cover types inside resolution element [11]. many applications, desirable obtain proportion given class inside mixed pixel. purpose, literature proposes mixture models; models represent pixel values combination multiple pure land cover types [12]. Assuming spectral response pure land cover classes (called endmembers) known, spectral mixture analysis derives new bands containing proportion endmember inside pixel.used method spectral mixture analysis linear model [12]. main idea behind linear mixture model observed pixel spectrum can expressed linear combination spectra pure endmembers, weighted respective proportions (abundances) within pixel. Mathematically, model can represented :\n\\[\nR_i = \\sum_{j=1}^N a_{,j}*x_j + \\epsilon_i, \\{1,...M}, M > N,\n\\]\n\\(=1,..M\\) set spectral bands \\(j=1,..N\\) set land classes. pixel, \\(R_i\\) reflectance -th spectral band, \\(x_j\\) reflectance value due j-th endmember, \\(a_{,j}\\) proportion j-th endmember -th spectral band. solve system equations obtain proportion endmember, sits uses non-negative least squares (NNLS) regression algorithm, available R package RStoolbox developed Jakob Schwalb-Willmann, based sequential coordinate-wise algorithm (SCA) proposed Franc et al. [13].run mixture model sits, necessary inform values pixels represent spectral responses unique class. -called “pure” pixels. quality resulting endmember images depends quality pure pixels, chosen carefully based expert knowledge area. Since sits supports multiple endmember spectral mixture analysis [14], users can specify one pure pixel per endmember account natural variability.sits, spectral mixture analysis done sits_mixture_model(), two mandatory parameters: cube (data cube) endmembers, named table (equivalent) defines pure pixels. endmembers table must following named columns: () type, defines class associated endmember; (b) names, names bands. line table must contain value endmember bands (see example). improve readability, suggest endmembers parameters defined tribble. tribble tibble easier read row--row layout. example , define three endmembers classes Forest, Soil, Water. Note values band expressed integers ranging 0 10,000.\nFigure 28: Percentage forest per pixel estimated mixture model (Source: Authors).\n\nFigure 29: Percentage water per pixel estimated mixture model (Source: Authors).\n\nFigure 30: Percentage soil per pixel estimated mixture model (Source: Authors).\nLinear mixture models (LMM) improve interpretation remote sensing images accounting mixed pixels providing accurate representation Earth’s surface. key benefits include:Improved classification accuracy: LMMs provide accurate representation mixed pixels considering contributions multiple land classes within single pixel. can lead improved land cover classification accuracy compared conventional per-pixel classification methods, may struggle accurately classify mixed pixels.Improved classification accuracy: LMMs provide accurate representation mixed pixels considering contributions multiple land classes within single pixel. can lead improved land cover classification accuracy compared conventional per-pixel classification methods, may struggle accurately classify mixed pixels.Sub-pixel information: LMMs allow estimation abundances land class within pixel, providing valuable sub-pixel information. can especially useful applications spatial resolution sensor fine enough resolve individual land cover types, monitoring urban growth studying vegetation dynamics.Sub-pixel information: LMMs allow estimation abundances land class within pixel, providing valuable sub-pixel information. can especially useful applications spatial resolution sensor fine enough resolve individual land cover types, monitoring urban growth studying vegetation dynamics.Enhanced change detection: considering sub-pixel composition land classes, LMMs can provide sensitive measure changes land cover time. can lead accurate precise change detection, particularly areas complex land cover patterns subtle changes land cover may occur.Enhanced change detection: considering sub-pixel composition land classes, LMMs can provide sensitive measure changes land cover time. can lead accurate precise change detection, particularly areas complex land cover patterns subtle changes land cover may occur.Biophysical parameter estimation: LMMs can used estimate biophysical parameters, vegetation fraction, leaf area index (LAI), soil moisture content, relating endmember abundances parameters. can provide valuable information monitoring managing natural resources, agriculture, ecosystems.Biophysical parameter estimation: LMMs can used estimate biophysical parameters, vegetation fraction, leaf area index (LAI), soil moisture content, relating endmember abundances parameters. can provide valuable information monitoring managing natural resources, agriculture, ecosystems.Applications spectral mixture analysis remote sensing include forest degradation [18], wetland surface dynamics [19], urban area characterization [20]. models providing valuable information wide range applications, land mapping change detection resource management environmental monitoring.","code":"\n# Define the endmembers for three classes and six bands\nem <- tibble::tribble(\n  ~class,   ~B02, ~B03, ~B04, ~B8A, ~B11, ~B12,\n  \"forest\",  200,  352,  189, 2800, 1340,  546,\n  \"soil\",    400,  650,  700, 3600, 3500, 1800,\n  \"water\",   700, 1100, 1400,  850,   40,   26\n)\n# Generate the mixture model\nreg_cube <- sits_mixture_model(\n  data = reg_cube,\n  endmembers = em,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp5\"\n)\n# Plot the FOREST for the first date using the Greens palette\nplot(reg_cube, band = \"FOREST\", palette = \"Greens\")\n# Plot the water endmember for the first date using the Blues palette\nplot(reg_cube, band = \"WATER\", palette = \"Blues\")\n# Plot the SOIL endmember for the first date using the orange red (OrRd) palette\nplot(reg_cube, band = \"SOIL\", palette = \"OrRd\")"},{"path":"working-with-time-series.html","id":"working-with-time-series","chapter":"Working with time series","heading":"Working with time series","text":"","code":""},{"path":"working-with-time-series.html","id":"data-structures-for-satellite-time-series","chapter":"Working with time series","heading":"Data structures for satellite time series","text":"sits package uses sets time series data describing properties spatiotemporal locations interest. land classification, sets consist samples labeled experts. package can also used type classification, provided timeline bands time series used training match data cubes.sits, time series stored tibble data structure. following code shows first three lines time series tibble containing 1,882 labeled samples land classes Mato Grosso state Brazil. samples time series extracted MODIS MOD13Q1 product 2000 2016, provided every 16 days 250 m resolution Sinusoidal projection. Based ground surveys high-resolution imagery, includes samples seven classes: Forest, Cerrado, Pasture, Soy_Fallow, Soy_Cotton, Soy_Corn, Soy_Millet.time series tibble contains data metadata. first six columns contain spatial temporal information, label assigned sample, data cube data extracted. first sample labeled Pasture location (\\(-58.5631\\), \\(-13.8844\\)), valid period (2006-09-14, 2007-08-29). Informing dates label valid crucial correct classification. case, researchers labeling samples used agricultural calendar Brazil. relevant dates applications countries likely differ used example. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band.","code":"\n# Samples\ndata(\"samples_matogrosso_mod13q1\")\nsamples_matogrosso_mod13q1[1:4, ]#> # A tibble: 4 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 3     -59.4    -9.31 2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 4     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>"},{"path":"working-with-time-series.html","id":"utilities-for-handling-time-series","chapter":"Working with time series","heading":"Utilities for handling time series","text":"package provides functions data manipulation displaying information time series tibbles. example, summary() shows labels sample set frequencies.many cases, helpful relabel data set. example, may situations using smaller set labels desirable samples one label original set may distinguishable samples labels. use sits_labels()<- assign new labels. example shows relabeling time series set shown ; samples associated crops grouped single Croplands label.Since metadata embedded time series use tibble data format, functions dplyr, tidyr, purrr packages tidyverse [21] can used process data. example, following code uses sits_select() get subset sample data set two bands (NDVI EVI) uses dplyr::filter() select samples labeled Cerrado.","code":"\nsummary(samples_matogrosso_mod13q1)#> # A tibble: 7 × 3\n#>   label      count   prop\n#>   <chr>      <int>  <dbl>\n#> 1 Cerrado      379 0.206 \n#> 2 Forest       131 0.0713\n#> 3 Pasture      344 0.187 \n#> 4 Soy_Corn     364 0.198 \n#> 5 Soy_Cotton   352 0.192 \n#> 6 Soy_Fallow    87 0.0474\n#> 7 Soy_Millet   180 0.0980\n# Copy the sample set for Mato Grosso\nsamples_new_labels <- samples_matogrosso_mod13q1\n# Show the current labels\nsits_labels(samples_new_labels)#> [1] \"Cerrado\"    \"Forest\"     \"Pasture\"    \"Soy_Corn\"   \"Soy_Cotton\" \"Soy_Fallow\"\n#> [7] \"Soy_Millet\"\n# Update the labels\nsits_labels(samples_new_labels) <- c(\n  \"Cerrado\", \"Forest\",\n  \"Pasture\", \"Croplands\",\n  \"Croplands\", \"Croplands\",\n  \"Croplands\"\n)\nsummary(samples_new_labels)#> # A tibble: 4 × 3\n#>   label     count   prop\n#>   <chr>     <int>  <dbl>\n#> 1 Cerrado     379 0.206 \n#> 2 Croplands   983 0.535 \n#> 3 Forest      131 0.0713\n#> 4 Pasture     344 0.187\n# Select NDVI band\nsamples_ndvi <- sits_select(samples_matogrosso_mod13q1,\n  bands = \"NDVI\"\n)\n# Select only samples with Cerrado label\nsamples_cerrado <- dplyr::filter(\n  samples_ndvi,\n  label == \"Cerrado\"\n)"},{"path":"working-with-time-series.html","id":"time-series-visualisation","chapter":"Working with time series","heading":"Time series visualisation","text":"Given samples display, plot() tries group many spatial locations together. following example, first 12 samples labelled Cerrado refer spatial location consecutive time periods. reason, samples plotted together.\nFigure 31: Plot first ‘Cerrado’ samples (Source: Authors).\nmany samples, default visualization combines samples together single temporal interval, even belong different years. plot shows spread values time series band. strong red line plot indicates median values, two orange lines first third interquartile ranges. See ?sits::plot details data visualization sits.\nFigure 32: Plot Cerrado samples (Source: Authors).\nsee spatial distribution samples, use sits_view() create interactive plot. spatial visulisation useful show data collected.","code":"\n# Plot the first 12 samples\nplot(samples_cerrado[1:12, ])\n# Plot all cerrado samples together\nplot(samples_cerrado)\nsits_view(samples_matogrosso_mod13q1)"},{"path":"working-with-time-series.html","id":"visualizing-sample-patterns","chapter":"Working with time series","heading":"Visualizing sample patterns","text":"dealing large time series, useful obtain single plot captures essential temporal variability class. Following work dtwSat R package [22], use generalized additive model (GAM) obtain single time series based statistical approximation. GAM, predictor depends linearly smooth function predictor variables.\\[\ny = \\beta_{} + f(x) + \\epsilon, \\epsilon \\sim N(0, \\sigma^2).\n\\]function sits_patterns() uses GAM predict idealized approximation time series associated class bands. resulting patterns can viewed using plot().\nFigure 33: Patterns samples Mato Grosso.\nresulting patterns provide insights time series behaviour class. response Forest class quite distinctive. also show possible separate single double cropping classes. similarities double-cropping classes (Soy_Corn Soy_Millet) Cerrado Pasture classes. subtle differences class signatures provide hints possible ways machine learning algorithms might distinguish classes. One example difference middle-infrared response dry season (May September) differentiate Cerrado Pasture.","code":"\n# Estimate the patterns for each class and plot them\nsamples_matogrosso_mod13q1 %>%\n  sits_patterns() %>%\n  plot()"},{"path":"working-with-time-series.html","id":"geographical-variability-of-training-samples","chapter":"Working with time series","heading":"Geographical variability of training samples","text":"working machine learning classification Earth observation data, important evaluate training samples well distributed study area. Training data often comes ground surveys made chosen locations. large areas, ideally representative samples need capture spatial variability. practice, however, ground surveys means data collection limited selected areas. many cases, geographical distribution training data cover study area equally. mismatch can problem achieving good quality classification. stated Meyer Pebesma [23]: “large gaps geographic space always imply large gaps feature space”.Meyer Pebesma propose using spatial distance distribution plot, displays two distributions nearest-neighbor distances: sample--sample prediction-location--sample [23]. difference two distributions reflects degree spatial clustering reference data. Ideally, two distributions similar. Cases sample--sample distance distribution match prediction-location--sample distribution indicate possible problems training data collection.sits implements spatial distance distribution plots sits_geo_dist() function. function gets training data samples parameter, study area roi parameter expressed sf object. Additional parameters n (maximum number samples distribution) crs (coordinate reference system samples). default, n 1000, crs “EPSG:4326”. example shows use sits_geo_dist().\nFigure 34: Distribution sample--sample sample--prediction distances (Source: Authors).\nplot shows mismatch sample--sample sample--prediction distributions. samples closer close location values need predicted. case, many areas samples collected prediction uncertainty higher. similar cases, improving distribution training samples always welcome. possible, areas insufficient samples lower accuracy. information must reported potential users classification results.","code":"\n# Read a shapefile for the state of Mato Grosso, Brazil\nmt_shp <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# Convert to an sf object\nmt_sf <- sf::read_sf(mt_shp)\n\n# Calculate sample-to-sample and sample-to-prediction distances\ndistances <- sits_geo_dist(\n  samples = samples_modis_ndvi,\n  roi = mt_sf\n)\n# Plot sample-to-sample and sample-to-prediction distances\nplot(distances)"},{"path":"working-with-time-series.html","id":"obtaining-time-series-data-from-data-cubes","chapter":"Working with time series","heading":"Obtaining time series data from data cubes","text":"get set time series sits, first create regular data cube request one time series cube using sits_get_data(). function uses two mandatory parameters: cube samples. cube indicates data cube time series extracted. samples parameter accepts following data types:data.frame information latitude longitude (mandatory), start_date, end_date, label sample point.csv file columns latitude, longitude, start_date, end_date, label.shapefile containing either POINTor POLYGON geometries. See details .sf object (sf package) POINT POLYGON geometry information. See details .example , given data cube, user provides latitude longitude desired location. Since bands, start date, end date time series missing, sits obtains data cube. result tibble one time series can visualized using plot().\nFigure 35: NDVI EVI time series fetched local raster cube (Source: Authors).\nuseful case set labeled samples can used training data set. case, trusted observations usually labeled commonly stored plain text files comma-separated values (csv) using shapefiles (shp).retrieve training samples time series analysis, users must provide temporal information (start_date end_date). simplest case, samples share dates. strict requirement. possible specify different dates long compatible duration. example, data set samples_matogrosso_mod13q1 provided sitsdata package contains samples different years covering duration. samples MOD13Q1 product, contains number images per year. Thus, time series data set samples_matogrosso_mod13q1 number dates.Given suitably built csv sample file, sits_get_data() requires two parameters: () cube, name R object describes data cube; (b) samples, name CSV file.Users can also specify samples providing shapefiles sf objects containing POINT POLYGON geometries. geographical location inferred geometries associated shapefile sf object. files containing points, geographical location obtained directly. polygon geometries, parameter n_sam_pol (defaults 20) determines number samples extracted polygon. temporal information can provided explicitly user; absent, inferred data cube. label information available shapefile sf object, parameter label_attr compulsory indicate column contains label associated time series.","code":"\n# Obtain a raster cube based on local files\ndata_dir <- system.file(\"extdata/sinop\", package = \"sitsdata\")\nraster_cube <- sits_cube(\n  source     = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir   = data_dir,\n  parse_info = c(\"satellite\", \"sensor\", \"tile\", \"band\", \"date\")\n)\n# Obtain a time series from the raster cube from a point\nsample_latlong <- tibble::tibble(\n  longitude = -55.57320,\n  latitude  = -11.50566\n)\nseries <- sits_get_data(\n  cube = raster_cube,\n  samples = sample_latlong\n)\nplot(series)\n# Retrieve a list of samples described by a csv file\nsamples_csv_file <- system.file(\"extdata/samples/samples_sinop_crop.csv\",\n  package = \"sits\"\n)\n# Read the csv file into an R object\nsamples_csv <- read.csv(samples_csv_file)\n# Print the first three samples\nsamples_csv[1:3, ]#> # A tibble: 3 × 6\n#>      id longitude latitude start_date end_date   label  \n#>   <int>     <dbl>    <dbl> <chr>      <chr>      <chr>  \n#> 1     1     -55.7    -11.8 2013-09-14 2014-08-29 Pasture\n#> 2     2     -55.6    -11.8 2013-09-14 2014-08-29 Pasture\n#> 3     3     -55.7    -11.8 2013-09-14 2014-08-29 Forest\n# Get the points from a data cube in raster brick format\npoints <- sits_get_data(\n  cube = raster_cube,\n  samples = samples_csv_file\n)\n# Show the tibble with the first three points\npoints[1:3, ]#> # A tibble: 3 × 7\n#>   longitude latitude start_date end_date   label    cube      time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>    <chr>     <list>           \n#> 1     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 2     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 3     -55.7    -11.7 2013-09-14 2014-08-29 Soy_Corn MOD13Q1-6 <tibble [23 × 3]>\n# Obtain a set of points inside the state of Mato Grosso, Brazil\nshp_file <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# Read the shapefile into an \"sf\" object\nsf_shape <- sf::st_read(shp_file)#> Reading layer `mt' from data source \n#>   `/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/sits/extdata/shapefiles/mato_grosso/mt.shp' \n#>   using driver `ESRI Shapefile'\n#> Simple feature collection with 1 feature and 3 fields\n#> Geometry type: MULTIPOLYGON\n#> Dimension:     XY\n#> Bounding box:  xmin: -61.63284 ymin: -18.03993 xmax: -50.22481 ymax: -7.349034\n#> Geodetic CRS:  SIRGAS 2000\n# Create a data cube based on MOD13Q1 collection from BDC\nmodis_cube <- sits_cube(\n  source      = \"BDC\",\n  collection  = \"MOD13Q1-6\",\n  bands       = c(\"NDVI\", \"EVI\"),\n  roi         = sf_shape,\n  start_date  = \"2020-06-01\",\n  end_date    = \"2021-08-29\"\n)\n\n# Read the points from the cube and produce a tibble with time series\nsamples_mt <- sits_get_data(\n  cube         = modis_cube,\n  samples      = shp_file,\n  start_date   = \"2020-06-01\",\n  end_date     = \"2021-08-29\",\n  n_sam_pol    = 20,\n  multicores   = 4\n)"},{"path":"working-with-time-series.html","id":"filtering-time-series","chapter":"Working with time series","heading":"Filtering time series","text":"Satellite image time series generally contaminated atmospheric influence, geolocation error, directional effects [24]. Atmospheric noise, sun angle, interferences observations different equipment specifications, nature climate-land dynamics can sources variability [25]. Inter-annual climate variability also changes phenological cycles vegetation, resulting time series whose periods intensities match year--year basis. make best use available satellite data archives, methods satellite image time series analysis need deal noisy non-homogeneous data sets.literature satellite image time series several applications filtering correct smooth vegetation index data. package supports well-known Savitzky–Golay (sits_sgolay()) Whittaker (sits_whittaker()) filters. evaluation NDVI time series filtering estimating phenological parameters India, Atkinson et al. found Whittaker filter provides good results [25]. Zhou et al. found Savitzky-Golay filter suitable reconstructing tropical evergreen broadleaf forests [26].","code":""},{"path":"working-with-time-series.html","id":"savitzkygolay-filter","chapter":"Working with time series","heading":"Savitzky–Golay filter","text":"Savitzky-Golay filter fits successive array \\(2n+1\\) adjacent data points \\(d\\)-degree polynomial linear least squares. main parameters filter polynomial degree (\\(d\\)) length window data points (\\(n\\)). generally produces smoother results larger value \\(n\\) /smaller value \\(d\\) [27]. optimal value two parameters can vary case case. sits, parameter order sets order polynomial (default = 3), parameter length sets size temporal window (default = 5), parameter scaling sets temporal expansion (default = 1). following example shows effect Savitsky-Golay filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01.\nFigure 36: Savitzky-Golay filter applied multi-year NDVI time series (Source: Authors).\nresulting smoothed curve desirable unwanted properties. 2000 2008, Savitsky-Golay filter removes noise clouds. However, 2010, region converted agriculture, filter removes important part natural variability crop cycle. Therefore, length parameter arguably big, resulting oversmoothing.","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Savitzky Golay filter\npoint_sg <- sits_sgolay(point_ndvi, length = 11)\n# Merge the point and plot the series\nsits_merge(point_sg, point_ndvi) %>% plot()"},{"path":"working-with-time-series.html","id":"whittaker-filter","chapter":"Working with time series","heading":"Whittaker filter","text":"Whittaker smoother attempts fit curve representing raw data, penalized subsequent points vary much [28]. Whittaker filter balances residual original data smoothness fitted curve. filter one parameter: \\(\\lambda{}\\) works smoothing weight parameter. following example shows effect Whittaker filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01. lambda parameter controls smoothing filter. default, set 0.5, small value. example shows effect larger smoothing parameter.\nFigure 37: Whittaker filter applied one-year NDVI time series (Source: Authors).\nSimilar observed Savitsky-Golay filter, high values smoothing parameter lambda produce -smoothed time series reduces capacity time series represent natural variations crop growth. reason, low smoothing values recommended using sits_whittaker().","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Whitakker filter\npoint_whit <- sits_whittaker(point_ndvi, lambda = 8)\n# Merge the point and plot the series\nsits_merge(point_whit, point_ndvi) %>% plot()"},{"path":"improving-the-quality-of-training-samples.html","id":"improving-the-quality-of-training-samples","chapter":"Improving the quality of training samples","heading":"Improving the quality of training samples","text":"Selecting good training samples machine learning classification satellite images critical achieving accurate results. Experience machine learning methods demonstrated number quality training samples crucial factors obtaining accurate results [29]. Large accurate datasets preferable, regardless algorithm used, noisy training samples can negatively impact classification performance [30]. Thus, beneficial use pre-processing methods improve quality samples eliminate may incorrectly labeled possess low discriminatory power.necessary distinguish wrongly labelled samples differences resulting natural variability class signatures. training data belongs large geographic region, variability vegetation phenology leads different patterns assigned label. related issue limitation crisp boundaries describe natural world. Class definitions use idealized descriptions (e.g., “savanna woodland tree cover 50% 90% ranging 8 15 m height”). practice, boundaries classes fuzzy sometimes overlap, making hard distinguish . improve sample quality, sits provides methods evaluating training data.Given set training samples, experts first perform cross-validation training set, able assess inherent prediction error. results indicate whether data internally consistent. Since cross-validation predictor actual model performance, chapter provides additional tools improving quality training sets. detailed information available Chapter “Validation Accuracy Assessment”.","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"data-sets-used-in-this-chapter","chapter":"Improving the quality of training samples","heading":"Data sets used in this chapter","text":"examples chapter use two data sets:cerrado_2classes: set time series Cerrado region Brazil, second largest biome South America area 2 million km^2. data contains 746 samples divided 2 classes (Cerrado Pasture). time series covers 12 months (23 data points) MOD13Q1 product, 2 bands (EVI, NDVI).cerrado_2classes: set time series Cerrado region Brazil, second largest biome South America area 2 million km^2. data contains 746 samples divided 2 classes (Cerrado Pasture). time series covers 12 months (23 data points) MOD13Q1 product, 2 bands (EVI, NDVI).samples_cerrado_mod13q1: set time series Cerrado region Brazil. data ranges 2000 2017 includes 50,160 samples divided 12 classes (Dense_Woodland, Dunes, Fallow_Cotton, Millet_Cotton, Pasture, Rocky_Savanna, Savanna, Savanna_Parkland, Silviculture, Soy_Corn, Soy_Cotton, Soy_Fallow). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (EVI, NDVI, MIR, NIR). use bands NDVI EVI faster processing.samples_cerrado_mod13q1: set time series Cerrado region Brazil. data ranges 2000 2017 includes 50,160 samples divided 12 classes (Dense_Woodland, Dunes, Fallow_Cotton, Millet_Cotton, Pasture, Rocky_Savanna, Savanna, Savanna_Parkland, Silviculture, Soy_Corn, Soy_Cotton, Soy_Fallow). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (EVI, NDVI, MIR, NIR). use bands NDVI EVI faster processing.","code":"\nlibrary(sits)\nlibrary(sitsdata)\n# Take only the NDVI and EVI bands\nsamples_cerrado_mod13q1_2bands <- sits_select(\n  data = samples_cerrado_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n\n# Show the summary of the samples\nsummary(samples_cerrado_mod13q1_2bands)#> # A tibble: 12 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    9966 0.199  \n#>  2 Dunes              550 0.0110 \n#>  3 Fallow_Cotton      630 0.0126 \n#>  4 Millet_Cotton      316 0.00630\n#>  5 Pasture           7206 0.144  \n#>  6 Rocky_Savanna     8005 0.160  \n#>  7 Savanna           9172 0.183  \n#>  8 Savanna_Parkland  2699 0.0538 \n#>  9 Silviculture       423 0.00843\n#> 10 Soy_Corn          4971 0.0991 \n#> 11 Soy_Cotton        4124 0.0822 \n#> 12 Soy_Fallow        2098 0.0418"},{"path":"improving-the-quality-of-training-samples.html","id":"cross-validation-of-training-sets","chapter":"Improving the quality of training samples","heading":"Cross-validation of training sets","text":"Cross-validation technique estimate inherent prediction error model [31]. Since cross-validation uses training samples, results accuracy measures unless samples carefully collected represent diversity possible occurrences classes study area [32]. practice, working large areas, hard obtain random stratified samples cover different variations land classes associated ecosystems study area. Thus, cross-validation taken measure model performance training data estimate overall map accuracy.Cross-validation uses part available samples fit classification model different part test . k-fold validation method splits data \\(k\\) partitions approximately size proceeds fitting model testing \\(k\\) times. step, take one distinct partition test remaining \\({k-1}\\) training model calculate prediction error classifying test partition. simple average gives us estimation expected prediction error. recommended choices \\(k\\) \\(5\\) \\(10\\) [31].sits_kfold_validate() supports k-fold validation sits. result confusion matrix accuracy statistics (overall class). examples , use multiprocessing speed results. parameters sits_kfold_validate :samples: training samples organized time series tibble;folds: number folds, many times split data (default = 5);ml_method: ML/DL method used validation (default = random forest);multicores: number cores used parallel processing (default = 2).show example cross-validation samples_cerrado_mod13q1 data set.results show good validation, reaching 94% accuracy. However, accuracy guarantee good classification result. shows training data internally consistent. follows, present additional methods improving sample quality.","code":"\nrfor_validate <- sits_kfold_validate(\n  samples = samples_cerrado_mod13q1_2bands,\n  folds = 5,\n  ml_method = sits_rfor(),\n  multicores = 5\n)\nrfor_validate#> Confusion Matrix and Statistics\n#> \n#>                   Reference\n#> Prediction         Pasture Dense_Woodland Savanna_Parkland Rocky_Savanna Savanna\n#>   Pasture             6610             22                6             8     106\n#>   Dense_Woodland       499           9681                0           622     131\n#>   Savanna_Parkland       2              0             2639            44      13\n#>   Rocky_Savanna          8             59               25          7298       7\n#>   Savanna               55            199               29            33    8915\n#>   Dunes                  0              0                0             0       0\n#>   Soy_Corn              10              0                0             0       0\n#>   Soy_Cotton             3              0                0             0       0\n#>   Soy_Fallow            14              0                0             0       0\n#>   Fallow_Cotton          4              0                0             0       0\n#>   Silviculture           1              5                0             0       0\n#>   Millet_Cotton          0              0                0             0       0\n#>                   Reference\n#> Prediction         Dunes Soy_Corn Soy_Cotton Soy_Fallow Fallow_Cotton\n#>   Pasture              0       38          9         30            36\n#>   Dense_Woodland       0        2          2          1             0\n#>   Savanna_Parkland     0        1          0          1             0\n#>   Rocky_Savanna        0        0          0          0             0\n#>   Savanna              0        7          0          1             0\n#>   Dunes              550        0          0          0             0\n#>   Soy_Corn             0     4852         59        342             6\n#>   Soy_Cotton           0       45       4045          0            22\n#>   Soy_Fallow           0       24          0       1714             1\n#>   Fallow_Cotton        0        2          3          9           560\n#>   Silviculture         0        0          0          0             0\n#>   Millet_Cotton        0        0          6          0             5\n#>                   Reference\n#> Prediction         Silviculture Millet_Cotton\n#>   Pasture                     1             0\n#>   Dense_Woodland             95             0\n#>   Savanna_Parkland            0             0\n#>   Rocky_Savanna               0             0\n#>   Savanna                    11             0\n#>   Dunes                       0             0\n#>   Soy_Corn                    0             2\n#>   Soy_Cotton                  0            21\n#>   Soy_Fallow                  0             0\n#>   Fallow_Cotton               0            23\n#>   Silviculture              316             0\n#>   Millet_Cotton               0           270\n#> \n#> Overall Statistics\n#>                            \n#>  Accuracy : 0.946          \n#>    95% CI : (0.944, 0.9479)\n#>                            \n#>     Kappa : 0.937          \n#> \n#> Statistics by Class:\n#> \n#>                           Class: Pasture Class: Dense_Woodland\n#> Prod Acc (Sensitivity)            0.9173                0.9714\n#> Specificity                       0.9940                0.9664\n#> User Acc (Pos Pred Value)         0.9627                0.8775\n#> Neg Pred Value                    0.9862                0.9927\n#> F1 score                          0.9395                0.9220\n#>                           Class: Savanna_Parkland Class: Rocky_Savanna\n#> Prod Acc (Sensitivity)                     0.9778               0.9117\n#> Specificity                                0.9987               0.9977\n#> User Acc (Pos Pred Value)                  0.9774               0.9866\n#> Neg Pred Value                             0.9987               0.9835\n#> F1 score                                   0.9776               0.9477\n#>                           Class: Savanna Class: Dunes Class: Soy_Corn\n#> Prod Acc (Sensitivity)            0.9720            1          0.9761\n#> Specificity                       0.9918            1          0.9907\n#> User Acc (Pos Pred Value)         0.9638            1          0.9205\n#> Neg Pred Value                    0.9937            1          0.9973\n#> F1 score                          0.9679            1          0.9475\n#>                           Class: Soy_Cotton Class: Soy_Fallow\n#> Prod Acc (Sensitivity)               0.9808            0.8170\n#> Specificity                          0.9980            0.9992\n#> User Acc (Pos Pred Value)            0.9780            0.9778\n#> Neg Pred Value                       0.9983            0.9921\n#> F1 score                             0.9794            0.8902\n#>                           Class: Fallow_Cotton Class: Silviculture\n#> Prod Acc (Sensitivity)                  0.8889              0.7470\n#> Specificity                             0.9992              0.9999\n#> User Acc (Pos Pred Value)               0.9318              0.9814\n#> Neg Pred Value                          0.9986              0.9979\n#> F1 score                                0.9098              0.8483\n#>                           Class: Millet_Cotton\n#> Prod Acc (Sensitivity)                  0.8544\n#> Specificity                             0.9998\n#> User Acc (Pos Pred Value)               0.9609\n#> Neg Pred Value                          0.9991\n#> F1 score                                0.9045"},{"path":"improving-the-quality-of-training-samples.html","id":"hierarchical-clustering-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Hierarchical clustering for sample quality control","text":"package provides two clustering methods assess sample quality: Agglomerative Hierarchical Clustering (AHC) Self-organizing Maps (SOM). methods different computational complexities. AHC computational complexity \\(\\mathcal{O}(n^2)\\), given number time series \\(n\\), whereas SOM complexity linear. large data, AHC requires substantial memory running time; cases, SOM recommended. section describes run AHC sits. SOM-based technique presented next section.AHC computes dissimilarity two elements data set. Depending distance functions linkage criteria, algorithm decides two clusters merged iteration. approach helpful exploring samples due visualization power ease use [33]. sits, AHC implemented using sits_cluster_dendro().\nFigure 38: Example hierarchical clustering two class set time series (Source: Authors).\nsits_cluster_dendro() function one mandatory parameter (samples), samples evaluated. Optional parameters include bands, dist_method, linkage. dist_method parameter specifies calculate distance two time series. recommend metric uses dynamic time warping (DTW) [34], DTW reliable method measuring differences satellite image time series [35]. options available sits based provided package dtwclust, include dtw_basic, dtw_lb, dtw2. Please check ?dtwclust::tsclust information DTW distances.linkage parameter defines distance metric clusters. recommended linkage criteria : complete ward.D2. Complete linkage prioritizes within-cluster dissimilarities, producing clusters shorter distance samples, results sensitive outliers. alternative, Ward proposes use sum--squares error minimize data variance [36]; method available ward.D2 option linkage parameter. cut dendrogram, sits_cluster_dendro() function computes adjusted rand index (ARI) [37], returning height cut dendrogram maximizes index. example, ARI index indicates six clusters. result sits_cluster_dendro() time series tibble one additional column called “cluster”. function sits_cluster_frequency() provides information composition cluster.cluster frequency table shows cluster predominance either Cerrado Pasture labels, except cluster 3, mix samples labels. confusion may resulted incorrect labelling, inadequacy selected bands spatial resolution, even natural confusion due variability land classes. remove cluster 3, use dplyr::filter(). resulting clusters still contain mixed labels, possibly resulting outliers. case, sits_cluster_clean() removes outliers, leaving frequent label. cleaning samples, resulting set samples likely improve classification results.","code":"\n# Take a set of patterns for 2 classes\n# Create a dendrogram, plot, and get the optimal cluster based on ARI index\nclusters <- sits_cluster_dendro(\n  samples = cerrado_2classes,\n  bands = c(\"NDVI\", \"EVI\"),\n  dist_method = \"dtw_basic\",\n  linkage = \"ward.D2\"\n)\n# Show clusters samples frequency\nsits_cluster_frequency(clusters)#>          \n#>             1   2   3   4   5   6 Total\n#>   Cerrado 203  13  23  80   1  80   400\n#>   Pasture   2 176  28   0 140   0   346\n#>   Total   205 189  51  80 141  80   746\n# Remove cluster 3 from the samples\nclusters_new <- dplyr::filter(clusters, cluster != 3)\n# Clear clusters, leaving only the majority label\nclean <- sits_cluster_clean(clusters_new)\n# Show clusters samples frequency\nsits_cluster_frequency(clean)#>          \n#>             1   2   4   5   6 Total\n#>   Cerrado 203   0  80   0  80   363\n#>   Pasture   0 176   0 140   0   316\n#>   Total   203 176  80 140  80   679"},{"path":"improving-the-quality-of-training-samples.html","id":"using-som-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Using SOM for sample quality control","text":"sits provides clustering technique based self-organizing maps (SOM) alternative hierarchical clustering quality control training samples. SOM dimensionality reduction technique [38], high-dimensional data mapped two-dimensional map, keeping topological relations data patterns. shown Figure 39, SOM 2D map composed units called neurons. neuron weight vector, dimension training samples. start, neurons assigned small random value trained competitive learning. algorithm computes distances member training set neurons finds neuron closest input, called best matching unit.\nFigure 39: SOM 2D map creation (Source: Santos et al. (2021). Reproduction fair use doctrine).\ninput data quality assessment set training samples, high-dimensional data; example, time series 25 instances 4 spectral bands 100 dimensions. projecting high-dimensional data set 2D SOM map, units map (called neurons) compete sample. time series mapped one neurons. Since number neurons smaller number classes, neuron associated many time series. resulting 2D map set clusters. Given SOM preserves topological structure neighborhoods multiple dimensions, clusters contain training samples given label usually neighbours 2D space. neighbors neuron SOM map provide information intraclass interclass variability, used detect noisy samples. methodology using SOM sample quality assessment discussed detail reference paper [39].\nFigure 40: Using SOM class noise reduction (Source: Santos et al. (2021). Reproduction fair use doctrine).\n","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"creating-the-som-map","chapter":"Improving the quality of training samples","heading":"Creating the SOM map","text":"perform SOM-based quality assessment, first step run sits_som_map(), uses kohonen R package compute SOM grid [40], controlled five parameters. grid size given grid_xdim grid_ydim. starting learning rate alpha, decreases interactions. measure separation samples, use distance (either “sumofsquares” “euclidean”). number iterations set rlen. details, please consult ?kohonen::supersom.\nFigure 41: SOM map Cerrado samples (Source: Authors).\noutput sits_som_map() list three elements: () data, original set time series two additional columns time series: id_sample (original id sample) id_neuron (id neuron belongs); (b) labelled_neurons, tibble information neurons. neuron, gives prior posterior probabilities labels occur samples assigned ; (c) SOM grid. plot SOM grid, use plot(). neurons labelled using majority voting.SOM grid shows classes associated neurons close , although exceptions. Pasture neurons far main cluster transition open savanna pasture areas always well defined depends climate latitude. Also, neurons associated Soy_Fallow dispersed map, indicating possible problems distinguishing class agricultural classes. SOM map can used remove outliers, shown .","code":"\n# Clustering time series using SOM\nsom_cluster <- sits_som_map(samples_cerrado_mod13q1_2bands,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"euclidean\",\n  rlen = 20\n)\n# Plot the SOM map\nplot(som_cluster)"},{"path":"improving-the-quality-of-training-samples.html","id":"measuring-confusion-between-labels-using-som","chapter":"Improving the quality of training samples","heading":"Measuring confusion between labels using SOM","text":"second step SOM-based quality assessment understanding confusion labels. function sits_som_evaluate_cluster() groups neurons majority label produces tibble. Neurons grouped clusters, many clusters labels. results shows percentage samples label cluster. Ideally, samples cluster label. practice, cluster contain samples different label. information helps measuring confusion samples.Many labels associated clusters samples different label. confusion labels arises sample labeling subjective can biased. many cases, interpreters use high-resolution data identify samples. However, actual images classified captured satellites lower resolution. case study, MOD13Q1 image pixels 250 m resolution. , correspondence labelled locations high-resolution images mid low-resolution images direct. confusion sample label can visualized bar plot using plot(), shown . bar plot shows confusion labels associated natural vegetation typical Brazilian Cerrado (Savanna, Savanna_Parkland, Rocky_Savanna). mixture due large variability natural vegetation Cerrado biome, makes difficult draw sharp boundaries classes. confusion also visible agricultural classes. Millet_Cotton class particularly difficult one since many samples assigned class confused Soy_Cotton Fallow_Cotton.\nFigure 42: Confusion classes measured SOM (Source: Authors).\n","code":"\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster)\n# Show the result\nsom_eval#> # A tibble: 73 × 4\n#>    id_cluster cluster        class          mixture_percentage\n#>         <int> <chr>          <chr>                       <dbl>\n#>  1          1 Dense_Woodland Dense_Woodland           82.9    \n#>  2          1 Dense_Woodland Pasture                   5.84   \n#>  3          1 Dense_Woodland Rocky_Savanna             5.66   \n#>  4          1 Dense_Woodland Savanna                   2.84   \n#>  5          1 Dense_Woodland Silviculture              2.76   \n#>  6          1 Dense_Woodland Soy_Corn                  0.0185 \n#>  7          1 Dense_Woodland Soy_Fallow                0.00925\n#>  8          2 Dunes          Dunes                   100      \n#>  9          3 Fallow_Cotton  Fallow_Cotton            52.9    \n#> 10          3 Fallow_Cotton  Millet_Cotton            13.2    \n#> # ℹ 63 more rows\n# Plot the confusion between clusters\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"detecting-noisy-samples-using-som","chapter":"Improving the quality of training samples","heading":"Detecting noisy samples using SOM","text":"third step quality assessment uses discrete probability distribution associated neuron, included labeled_neurons tibble produced sits_som_map(). approch associates probabilities frequency occurrence. homogeneous neurons (one label high frequency) assumed composed good quality samples. Heterogeneous neurons (two classes significant frequencies) likely contain noisy samples. algorithm computes two values sample:prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled Pasture 5 Forest, samples labelled Forest assigned prior probability 25%. indicates Forest samples neuron may good quality.prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled Pasture 5 Forest, samples labelled Forest assigned prior probability 25%. indicates Forest samples neuron may good quality.posterior probability: probability label assigned sample correct, considering neighbouring neurons. Take case -mentioned neuron whose samples labeled Pasture prior probability 75%. happens neighbouring neurons Forest majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [41].posterior probability: probability label assigned sample correct, considering neighbouring neurons. Take case -mentioned neuron whose samples labeled Pasture prior probability 75%. happens neighbouring neurons Forest majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [41].identify noisy samples, take result sits_som_map() function first argument function sits_som_clean_samples(). function finds samples noisy, clean, need examined user. requires prior_threshold posterior_threshold parameters according following rules:prior probability sample less prior_threshold, sample assumed noisy tagged “remove”;prior probability greater equal prior_threshold posterior probability calculated Bayesian inference greater equal posterior_threshold, sample assumed noisy thus tagged “clean”;prior probability greater equal prior_threshold posterior probability less posterior_threshold, situation sample part majority level assigned neuron, label consistent neighbors. anomalous condition tagged “analyze”. Users encouraged inspect samples find whether fact noisy .default value prior_threshold posterior_threshold 60%. sits_som_clean_samples() additional parameter (keep), indicates samples kept set based prior posterior probabilities. default keep c(\"clean\", \"analyze\"). result cleaning, 900 samples considered noisy thus removed.samples class highest confusion others(Millet_Cotton) removed. samples class Silviculture (planted forests) also removed since confused natural forests woodlands SOM map. analysis includes calculating SOM map confusion matrix new set, shown following example.\nFigure 43: Cluster confusion plot samples cleaned SOM (Source: Authors).\nexpected, new confusion map shows significant improvement previous one. result interpreted carefully since may due different effects. direct interpretation Millet_Cotton Silviculture easily separated classes, given current attributes (time series NDVI EVI indices MODIS images). situations, users consider improving number samples less represented classes, including MODIS bands, working higher resolution satellites. results SOM method interpreted based users’ understanding ecosystems agricultural practices study region.comparison original clean samples run 5-fold validation original cleaned sample sets using sits_kfold_validate() random forest model. SOM procedure improves validation results 95% original data set 99% cleaned one. improvement interpreted providing better fit final map accuracy. 5-fold validation procedure measures well machine learning model fits samples; accuracy assessment classification results. result indicates training set SOM sample removal procedure internally consistent original one. details accuracy measures, please see Chapter Validation accuracy measures.SOM-based analysis discards samples can confused samples classes. removing noisy samples uncertain classes, data set obtains better validation score since less confusion classes. Users analyse results care. discarded samples low-quality ones. Confusion samples different classes can result inconsistent labelling lack capacity satellite data distinguish chosen classes. many samples discarded, current example, revising whole classification schema advisable. aim selecting training data always match reality ground power remote sensing data identify differences. analysis procedure can replace actual user experience knowledge study region.","code":"\nnew_samples <- sits_som_clean_samples(\n  som_map = som_cluster,\n  prior_threshold = 0.6,\n  posterior_threshold = 0.6,\n  keep = c(\"clean\", \"analyze\")\n)\n# Print the new sample distribution\nsummary(new_samples)#> # A tibble: 11 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    8411 0.204  \n#>  2 Dunes              550 0.0133 \n#>  3 Fallow_Cotton      103 0.00250\n#>  4 Millet_Cotton      159 0.00386\n#>  5 Pasture           5751 0.140  \n#>  6 Rocky_Savanna     6520 0.158  \n#>  7 Savanna           8109 0.197  \n#>  8 Savanna_Parkland  2242 0.0544 \n#>  9 Soy_Corn          4308 0.105  \n#> 10 Soy_Cotton        3647 0.0885 \n#> 11 Soy_Fallow        1419 0.0344\n# Evaluate the mixture in the SOM clusters of new samples\nnew_cluster <- sits_som_map(\n  data = new_samples,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"euclidean\"\n)\nnew_cluster_mixture <- sits_som_evaluate_cluster(new_cluster)\n# Plot the mixture information.\nplot(new_cluster_mixture)\n# Run a k-fold validation\nassess_orig <- sits_kfold_validate(\n  samples = samples_cerrado_mod13q1_2bands,\n  folds = 5,\n  ml_method = sits_rfor()\n)\n# Print summary\nsummary(assess_orig)#> Overall Statistics                            \n#>  Accuracy : 0.9454          \n#>    95% CI : (0.9434, 0.9474)\n#>     Kappa : 0.9363\nassess_new <- sits_kfold_validate(\n  samples = new_samples,\n  folds = 5,\n  ml_method = sits_rfor()\n)\n# Print summary\nsummary(assess_new)#> Overall Statistics                            \n#>  Accuracy : 0.9893          \n#>    95% CI : (0.9882, 0.9902)\n#>     Kappa : 0.9874"},{"path":"improving-the-quality-of-training-samples.html","id":"reducing-sample-imbalance","chapter":"Improving the quality of training samples","heading":"Reducing sample imbalance","text":"Many training samples Earth observation data analysis imbalanced. situation arises distribution samples associated label uneven. One example Cerrado data set used Chapter. three frequent labels (Dense Woodland, Savanna Pasture) include 53% samples, three least frequent labels (Millet-Cotton, Silviculture, Dunes) comprise 2.5% data set. Sample imbalance undesirable property training set since machine learning algorithms tend accurate classes many samples. instances belonging minority group misclassified often belonging majority group. Thus, reducing sample imbalance can positively affect classification accuracy [42].function sits_reduce_imbalance() deals training set imbalance; increases number samples least frequent labels, reduces number samples frequent labels. Oversampling requires generating synthetic samples. package uses SMOTE method estimates new samples considering cluster formed nearest neighbours minority label. SMOTE takes two samples cluster produces new one randomly interpolating [43].perform undersampling, sits_reduce_imbalance() builds SOM map majority label based required number samples selected. dimension SOM set ceiling(sqrt(new_number_samples/4)) allow reasonable number neurons group similar samples. calculating SOM map, algorithm extracts four samples per neuron generate reduced set samples approximates variation original one.sits_reduce_imbalance() algorithm two parameters: n_samples_over n_samples_under. first parameter indicates minimum number samples per class. classes samples less value oversampled. second parameter controls maximum number samples per class; classes samples value undersampled. following example uses sits_reduce_imbalance() Cerrado samples. generate balanced data set classes minumim 1000 maximum 1500 samples. use sits_som_evaluate_cluster() estimate confusion classes balanced data set.\nFigure 44: Confusion cluster balanced data set (Source: Authors).\nshown Figure 44, balanced data set shows less confusion per label unbalanced one. case, many classes confused others original confusion map now better represented. Reducing sample imbalance tried alternative reducing number samples classes using SOM. general, users balance training data better performance.","code":"\n# Reducing imbalances in the Cerrado data set\nbalanced_samples <- sits_reduce_imbalance(\n  samples = samples_cerrado_mod13q1_2bands,\n  n_samples_over = 1000,\n  n_samples_under = 1500,\n  multicores = 4\n)\n# Print the balanced samples\n# Some classes have more than 1500 samples due to the SOM map\n# Each label has between 10% and 6% of the full set\nsummary(balanced_samples)#> # A tibble: 12 × 3\n#>    label            count   prop\n#>    <chr>            <int>  <dbl>\n#>  1 Dense_Woodland    1600 0.0967\n#>  2 Dunes             1000 0.0604\n#>  3 Fallow_Cotton     1000 0.0604\n#>  4 Millet_Cotton     1000 0.0604\n#>  5 Pasture           1596 0.0964\n#>  6 Rocky_Savanna     1508 0.0911\n#>  7 Savanna           1600 0.0967\n#>  8 Savanna_Parkland  1588 0.0960\n#>  9 Silviculture      1000 0.0604\n#> 10 Soy_Corn          1592 0.0962\n#> 11 Soy_Cotton        1560 0.0943\n#> 12 Soy_Fallow        1504 0.0909\n# Clustering time series using SOM\nsom_cluster_bal <- sits_som_map(\n  data = balanced_samples,\n  grid_xdim = 10,\n  grid_ydim = 10,\n  alpha = 1.0,\n  distance = \"euclidean\",\n  rlen = 20\n)\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster_bal)\n# Show the result\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"conclusion","chapter":"Improving the quality of training samples","heading":"Conclusion","text":"quality training data critical improving accuracy maps resulting machine learning classification methods. address challenge, sits package provides three methods improving training samples. large datasets, recommend using imbalance-reducing SOM-based algorithms. SOM-based method identifies potential mislabeled samples outliers require investigation. results demonstrate positive impact overall classification accuracy.complexity diversity planet defy simple label names hard boundaries. Due representational data handling issues, classification systems limited number categories, inevitably fail adequately describe nuances planet’s landscapes. representation systems thus limited application-dependent. stated Janowicz [44]: “geographical concepts situated context-dependent can described different, equally valid, points view; thus, ontological commitments arbitrary large extent”.availability big data satellite image time series challenge. principle, image time series can capture subtle changes land classification. Experts must conceive classification systems training data collections understanding time series information relates actual land change. Methods quality analysis, presented Chapter, replace user understanding informed choices.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-for-data-cubes","chapter":"Machine learning for data cubes","heading":"Machine learning for data cubes","text":"","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-classification","chapter":"Machine learning for data cubes","heading":"Machine learning classification","text":"Machine learning classification type supervised learning algorithm trained predict class input data point belongs . goal machine learning models approximate function \\(y = f(x)\\) maps input \\(x\\) class \\(y\\). model defines mapping \\(y = f(x;\\theta)\\) learns value parameters \\(\\theta\\) result best function approximation [45]. difference different algorithms approach building mapping classifies input data.\nsits, machine learning used classify individual time series using time-first approach. package includes two kinds methods time series classification:Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Deep learning methods temporal relations observed values time series taken account. models specifically designed time series. temporal order values time series relevant classification model. class models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()).Deep learning methods temporal relations observed values time series taken account. models specifically designed time series. temporal order values time series relevant classification model. class models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()).Based experience sits, random forest, extreme gradient boosting, temporal deep learning models outperform SVM multilayer perceptron models. reason dates provide information others temporal behavior land classes. instance, monitoring deforestation, dates corresponding forest removal actions informative earlier later dates. Similarly, dates may capture large portion variation crop mapping. Therefore, classification methods consider temporal order samples likely capture seasonal behavior image time series. Random forest extreme gradient boosting methods use individual measures nodes decision trees can also capture specific events deforestation.following examples show train machine learning methods apply classify single time series. use set samples_matogrosso_mod13q1, containing time series samples Brazilian Mato Grosso state obtained MODIS MOD13Q1 product. 1,892 samples nine classes (Cerrado, Forest, Pasture, Soy_Corn, Soy_Cotton, Soy_Fallow, Soy_Millet). time series covers 12 months (23 data points) six bands (NDVI, EVI, BLUE, RED, NIR, MIR). samples arranged along agricultural year, starting September ending August. data set used paper “Big Earth observation time series analysis monitoring Brazilian agriculture” [46], available R package sitsdata.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"common-interface-to-machine-learning-and-deep-learning-models","chapter":"Machine learning for data cubes","heading":"Common interface to machine learning and deep learning models","text":"sits_train() function provides standard interface machine learning models. function takes two mandatory parameters: training data (samples) ML algorithm (ml_method). model estimated, can classify individual time series data cubes sits_classify(). follows, show apply method classify single time series. , Chapter Image classification data cubes, discuss classify data cubes.Since sits aimed remote sensing users machine learning experts, provides set default values classification models. settings chosen based testing authors. Nevertheless, users can control parameters model. Novice users can rely default values, experienced ones can fine-tune model parameters meet needs. Model tuning discussed end Chapter.set time series organized tibble taken input classifier, result tibble one additional column (“predicted”), contains information labels assigned interval. results can shown text format using function sits_show_prediction() graphically using plot().","code":""},{"path":"machine-learning-for-data-cubes.html","id":"random-forest","chapter":"Machine learning for data cubes","heading":"Random forest","text":"Random forest machine learning algorithm uses ensemble learning method classification tasks. algorithm consists multiple decision trees, trained different subset training data different subset features. make prediction, decision tree forest independently classifies input data. final prediction made based majority vote decision trees. randomness algorithm comes random subsets data features used train decision tree, helps reduce overfitting improve accuracy model. classifier measures importance feature classification task, can helpful feature selection data visualization. Pelletier et al. discuss robustness random forest method satellite image time series classification [47].\nFigure 45: Random forest algorithm (Source: Venkata Jagannath Wikipedia - licenced CC--SA 4.0).\nsits provides sits_rfor(), uses R randomForest package [48]; main parameter num_trees, number trees grow default value 100. model can visualized using plot().\nFigure 46: important variables random forest model (Source: Authors).\nimportant explanatory variables NIR (near infrared) band date 17 (2007-05-25) MIR (middle infrared) band date 22 (2007-08-13). NIR value end May captures growth second crop double cropping classes. Values MIR band end period (late July late August) capture bare soil signatures distinguish agricultural natural classes. corresponds summertime ground drier harvesting crops.\nFigure 47: Classification time series using random forest (Source: Authors).\nresult shows area started forest 2000, deforested 2004 2005, used pasture 2006 2007, double-cropping agriculture 2009 onwards. behavior consistent expert evaluation land change process region Amazonia.Random forest robust outliers can deal irrelevant inputs [31]. method tends overemphasize variables performance tends stabilize part trees grown [31]. cases abrupt change occurs, deforestation mapping, random forest (properly trained) emphasize temporal instances bands capture quick change.","code":"\n# Train the Mato Grosso samples with random forest model\nrfor_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_rfor(num_trees = 100)\n)\n# Plot the most important variables of the model\nplot(rfor_model)\n# Classify using random forest model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = rfor_model\n)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"support-vector-machine","chapter":"Machine learning for data cubes","heading":"Support vector machine","text":"support vector machine (SVM) classifier generalization linear classifier finds optimal separation hyperplane minimizes misclassification [49]. Since set samples \\(n\\) features defines n-dimensional feature space, hyperplanes linear \\({(n-1)}\\)-dimensional boundaries define linear partitions space. classes linearly separable feature space, optimal solution defined maximal margin hyperplane, separating hyperplane farthest training observations [50]. maximal margin computed smallest distance observations hyperplane. solution hyperplane coefficients depends samples define maximum margin criteria, -called support vectors.\nFigure 48: Maximum-margin hyperplane margins SVM trained samples two classes. Samples margin called support vectors. (Source: Larhmam Wikipedia - licensed CC--SA-4.0).\ndata linearly separable, SVM includes kernel functions map original feature space higher dimensional space, providing nonlinear boundaries original feature space. Despite linear boundary enlarged feature space, new classification model generally translates hyperplane nonlinear boundary original attribute space. Kernels efficient computational strategy produce nonlinear boundaries input attribute space; thus, improve training-class separation. SVM one widely used algorithms machine learning applications applied classify remote sensing data [51].sits, SVM implemented wrapper e1071 R package uses LIBSVM implementation [52]. sits package adopts one--one method multiclass classification. \\(q\\) class problem, method creates \\({q(q-1)/2}\\) SVM binary models, one class pair combination, testing unknown input vectors throughout models. voting scheme computes overall result.example shows apply SVM classify time series using default values. main parameters kernel, controls whether use nonlinear transformation (default radial), cost, measures punishment wrongly-classified samples (default 10), cross, sets value k-fold cross validation (default 10).\nFigure 49: Classification time series using SVM (Source: Authors).\nSVM classifier less stable less robust outliers random forest method. example, tends misclassify data. 2008, likely correct land class still Pasture rather Soy_Millet produced algorithm, Soy_Cotton class 2012 also inconsistent previous latter classification Soy_Corn.","code":"\n# Train an SVM model\nsvm_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_svm()\n)\n# Classify using the SVM model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = svm_model\n)\n# Plot the result\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"extreme-gradient-boosting","chapter":"Machine learning for data cubes","heading":"Extreme gradient boosting","text":"boosting method starts weak predictor improves performance sequentially fitting better model iteration. fits simple classifier training data uses residuals fit build predictor. Typically, base classifier regression tree. Although random forest boosting use trees classification, significant differences. performance random forest generally increases number trees becomes stable. Boosting trees apply finer divisions previous results improve performance [31]. However, result generalizable since quality training data set controls actual performance.Gradient boosting variant boosting methods minimize cost function gradient descent. Extreme gradient boosting [53], called XGBoost, efficiently approximates gradient loss function. recent papers show outperforms random forest remote sensing image classification [54]. However, result generalizable since actual performance controlled quality training data set.sits, XGBoost method implemented sits_xbgoost() function, based XGBoost R package, five hyperparameters require tuning. sits_xbgoost() function takes user choices input cross-validation determine suitable values predictor.learning rate eta varies 0.0 1.0 kept small (default 0.3) avoid overfitting. minimum loss value gamma specifies minimum reduction required make split. default 0; increasing makes algorithm conservative. max_depth value controls maximum depth trees. Increasing value make model complex likely overfit (default 6). subsample parameter controls percentage samples supplied tree. default 1 (maximum). Setting lower values means xgboost randomly collects part data instances grow trees, thus preventing overfitting. nrounds parameter controls maximum number boosting interactions; default 100, proven enough cases. follow convergence algorithm, users can turn verbose parameter . general, results using extreme gradient boosting algorithm similar random forest method.\nFigure 50: Classification time series using XGBoost (Source: Authors).\n","code":"\n# Train using  XGBoost\nxgb_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_xgboost(verbose = 0)\n)\n# Classify using SVM model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = xgb_model\n)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-using-multilayer-perceptron","chapter":"Machine learning for data cubes","heading":"Deep learning using multilayer perceptron","text":"support deep learning methods, sits uses torch R package, takes Facebook torch C++ library back-end. Machine learning algorithms use R torch package similar developed using PyTorch. simplest deep learning method multilayer perceptron (MLP), feedforward artificial neural networks. MLP consists three kinds nodes: input layer, set hidden layers, output layer. input layer dimension number features data set. hidden layers attempt approximate best classification function. output layer decides class assigned input.sits, MLP models can built using sits_mlp(). Since established model generic classification satellite image time series, designing MLP models requires parameter customization. important decisions number layers model number neurons per layer. values set layers parameter, list integer values. size list number layers, element indicates number nodes per layer.choice number layers depends inherent separability data set classified. data sets classes different signatures, shallow model (three layers) may provide appropriate responses. complex situations require models deeper hierarchy. Models many hidden layers may take long time train may converge. suggest start three layers test different options number neurons per layer increasing number layers. experience, using three five layers reasonable compromise training data good quality. increase number layers improve model.MLP models also need include activation function. activation function node defines output node given input set inputs. Following standard practices [45], use relu activation function.optimization method (optimizer) represents gradient descent algorithm used. methods aim maximize objective function updating parameters opposite direction gradient objective function [55]. Based experience image time series, recommend start using default method provided sits, optimizer_adamw, package torchopt. Please refer torchopt package additional information.Another relevant parameter list dropout rates (dropout). Dropout technique randomly dropping units neural network training [56]. randomly discarding neurons, dropout reduces overfitting. Since cascade neural nets aims improve learning data acquired, discarding neurons may seem like waste resources. practice, dropout prevents early convergence local minimum [45]. suggest users experiment different dropout rates, starting small values (10-30%) increasing required.following example shows use sits_mlp(). default parameters chosen based modified version [57], proposes using multilayer perceptron baseline time series classification. parameters : () Three layers 512 neurons , specified parameter layers; (b) Using “relu” activation function; (c) dropout rates 40%, 30%, 20% layers; (d) “optimizer_adamw” optimizer (default value); (e) number training steps (epochs) 100; (f) batch_size 64, indicates many time series used input given step; (g) validation percentage 20%, means 20% samples randomly set aside validation.simplify output, verbose option turned . model generated, plot training history.\nFigure 51: Evolution training accuracy MLP model (Source: Authors).\n, classify 16-year time series using multilayer perceptron model.\nFigure 52: Classification time series using MLP (Source: Authors).\ntheory, multilayer perceptron model can capture subtle changes random forest XGBoost specific case, result similar . Although model mixes Soy_Corn Soy_Millet classes, distinction temporal signatures quite subtle. Also, case, suggests need improve number samples. example, MLP model shows increase sensitivity compared previous models. recommend compare different configurations since MLP model sensitive changes parameters.","code":"\n# Train using an MLP model\n# This is an example of how to set parameters\n# First-time users should test default options first\nmlp_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_mlp(\n    layers           = c(512, 512, 512),\n    dropout_rates    = c(0.40, 0.30, 0.20),\n    epochs           = 100,\n    batch_size       = 64,\n    verbose          = FALSE,\n    validation_split = 0.2\n  )\n)\n# Show training evolution\nplot(mlp_model)\n# Classify using MLP model and plot the result\npoint_mt_mod13q1 %>%\n  sits_classify(mlp_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"temporal-convolutional-neural-network-tempcnn","chapter":"Machine learning for data cubes","heading":"Temporal Convolutional Neural Network (TempCNN)","text":"Convolutional neural networks (CNN) deep learning methods apply convolution filters (sliding windows) input data sequentially. Temporal Convolutional Neural Network (TempCNN) neural network architecture specifically designed process sequential data time series. case time series, 1D CNN applies moving temporal window time series produce another time series result convolution.TempCNN applies one-dimensional convolutions input sequence capture temporal dependencies, allowing network learn long-term dependencies input sequence. layer model captures temporal dependencies different scale. Due multi-scale approach, TempCNN can capture complex temporal patterns data produce accurate predictions.TempCNN architecture satellite image time series classification proposed Pelletier et al. [58]. three 1D convolutional layers final softmax layer classification (see Figure 53). authors combine different methods avoid overfitting reduce vanishing gradient effect, including dropout, regularization, batch normalization. TempCNN reference paper [58], authors favourably compare model Recurrent Neural Network proposed Russwurm Körner [59]. Figure 53 shows architecture TempCNN model.\nFigure 53: Structure tempCNN architecture (Source: Pelletier et al. (2019). Reproduction fair use doctrine).\nfunction sits_tempcnn() implements model. parameter cnn_layers controls number 1D-CNN layers size filters applied layer; default values three CNNs 128 units. parameter cnn_kernels indicates size convolution kernels; default kernels size 7. Activation 1D-CNN layers uses “relu” function. dropout rates 1D-CNN layer controlled individually parameter cnn_dropout_rates. validation_split controls size test set relative full data set. recommend setting aside least 20% samples validation.\nFigure 54: Training evolution TempCNN model (Source: Authors).\n, classify 16-year time series using TempCNN model.\nFigure 55: Classification time series using TempCNN (Source: Authors).\nresult important differences previous ones. TempCNN model indicates Soy_Cotton class likely one 2004. result possibly wrong, shows time series 2004 different Forest Pasture classes. One possible explanation forest degradation 2004, leading signature mix forest bare soil. case, including forest degradation samples improve training data. experience, TempCNN models reliable way classifying image time series [60]. Recent work compares different models also provides evidence TempCNN models satisfactory behavior, especially case crop classes [61].","code":"\nlibrary(torchopt)\n# Train using tempCNN\ntempcnn_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tempcnn(\n    optimizer            = torchopt::optim_adamw,\n    cnn_layers           = c(128, 128, 128),\n    cnn_kernels          = c(7, 7, 7),\n    cnn_dropout_rates    = c(0.2, 0.2, 0.2),\n    epochs               = 100,\n    batch_size           = 64,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# Show training evolution\nplot(tempcnn_model)\n# Classify using TempCNN model and plot the result\nclass <- point_mt_mod13q1 %>%\n  sits_classify(tempcnn_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"residual-1d-cnn-networks-resnet","chapter":"Machine learning for data cubes","heading":"Residual 1D CNN networks (ResNet)","text":"residual 1D CNN network, also known ResNet, extension standard 1D CNN architecture, adding residual connections layers. Residual connections allow network learn residual mappings, difference input output layer. adding residual connections, network can learn bypass specific layers still capture essential features data.Residual Network (ResNet) time series classification proposed Wang et al. [57], based idea deep residual networks 2D image recognition [62]. ResNet architecture comprises 11 layers, three blocks three 1D CNN layers (see Figure 56). block corresponds 1D CNN architecture. output block combined shortcut links output input, called skip connection. purpose combining input layer block output layer (convolutions) avoid -called “vanishing gradient problem”. issue occurs deep networks neural network’s weights updated based partial derivative error function. gradient small, weights updated, stopping training [63]. Skip connections aim avoid vanishing gradients occurring, allowing deep networks trained.\nFigure 56: Structure ResNet architecture (Source: Wang et al. (2017). Reproduction fair use doctrine).\nsits, Residual Network implemented using sits_resnet(). default parameters proposed Wang et al. [57], implemented Fawaz et al. [64]. first parameter blocks, controls number blocks size filters block. default, model implements three blocks, first 64 filters others 128. parameter kernels controls size kernels three layers inside block. useful experiment bit kernel sizes case satellite image time series. default activation “relu”, recommended literature reduce problem vanishing gradients. default optimizer optim_adamw, available package torchopt.\nFigure 57: Training evolution ResNet model (Source: Authors).\n, classify 16-year time series using ResNet model. behavior ResNet model similar TempCNN, variability.\nFigure 58: Classification time series using ResNet (Source: Authors).\n","code":"\n# Train using ResNet\nresnet_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_resnet(\n    blocks               = c(64, 128, 128),\n    kernels              = c(7, 5, 3),\n    epochs               = 100,\n    batch_size           = 64,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# Show training evolution\nplot(resnet_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>%\n  sits_classify(tempcnn_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"attention-based-models","chapter":"Machine learning for data cubes","heading":"Attention-based models","text":"Attention-based deep learning models class models use mechanism inspired human attention focus specific parts input processing. models shown effective various tasks machine translation, image captioning, speech recognition.basic idea behind attention-based models allow model selectively focus different input parts different times. can done introducing mechanism assigns weights element input, indicating relative importance element current processing step. model can use compute weighted sum input. results capture model’s attention specific parts input.Attention-based models become one used deep learning architectures problems involve sequential data inputs, e.g., text recognition automatic translation. general idea inputs alike applications language translation. Consider English sentence “Look lonely people”. sound translation system needs relate words “look” “people” key parts sentence ensure link captured translation. specific type attention models, called transformers, enables recognition complex relationships input output sequences [65].basic structure transformers neural network algorithms. encoder transforms textual input values numerical vectors decoder processes vectors provide suitable answers. difference values handled internally. MLP, inputs treated equally first; based iterative matching training test data, backpropagation technique feeds information back initial layers identify suitable combination inputs produces best output.Convolutional nets (CNN) combine input values close time (1D) space (2D) produce higher-level information helps distinguish different components input data. text recognition, initial choice deep learning studies use recurrent neural networks (RNN) handle input sequences.However, neither MLPs, CNNs, RNNs able capture structure complex inputs natural language. success transformer-based solutions accounts substantial improvements natural language processing.two main differences transformer models algorithms positional encoding self-attention. Positional encoding assigns index input value, ensuring relative locations inputs maintained throughout learning processing phases. Self-attention compares every word sentence every word sentence, including . way, learns contextual information relation words. conception validated large language models BERT [66] GPT-3 [67].application attention-based models satellite image time series analysis proposed Garnot et al. [68] Russwurm Körner [61]. self-attention network can learn focus specific time steps image features relevant distinguishing different classes. algorithm tries identify combination individual temporal observations relevant identify class. example, crop identification use observations capture onset growing season, date maximum growth, end growing season. case deforestation, algorithm tries identify dates forest cut. Attention-based models means identify events characterize land class.first model proposed Garnot et al. full transformer-based model [68]. Considering image time series classification easier natural language processing, Garnot et al. also propose simplified version full transformer model Garnot2020?. simpler model uses reduced way compute attention matrix, reducing time training classification without loss quality result.sits, full transformer-based model proposed Garnot et al. [68] implemented using sits_tae(). default parameters proposed authors. default optimizer optim_adamw, available package torchopt.\nFigure 59: Training evolution Temporal Self-Attention model (Source: Authors).\n, classify 16-year time series using TAE model.\nFigure 60: Classification time series using TAE (Source: Authors).\nGarnot co-authors also proposed Lightweight Temporal Self-Attention Encoder (LTAE) Garnot2020?, authors claim can achieve high classification accuracy fewer parameters compared neural network models. good choice applications computational resources limited. sits_lighttae() function implements algorithm. default optimizer optim_adamw, available package torchopt. important parameter set learning rate lr. Values ranging 0.001 0.005 produce good results. See also section model tuning.\nFigure 61: Training evolution Lightweight Temporal Self-Attention model (Source: Authors).\n, classify 16-year time series using LightTAE model.\nFigure 62: Classification time series using LightTAE (Source: Authors).\nbehaviour sits_tae() sits_lighttae() similar sits_tempcnn(). points possible need classes training data better represent transition period 2004 2010. One possibility training data associated Pasture class consistent time series years 2005 2008. However, transition Forest Pasture 2004 Pasture Agriculture 2009-2010 subject uncertainty since classifiers agree resulting classes. general, deep learning temporal-aware models sensitive class variability random forest extreme gradient boosters.","code":"\n# Train a machine learning model using TAE\ntae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tae(\n    epochs               = 150,\n    batch_size           = 64,\n    optimizer            = torchopt::optim_adamw,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# Show training evolution\nplot(tae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>%\n  sits_classify(tae_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))\n# Train a machine learning model using TAE\nltae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_lighttae(\n    epochs = 150,\n    batch_size = 64,\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001),\n    validation_split = 0.2\n  )\n)\n# Show training evolution\nplot(ltae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>%\n  sits_classify(ltae_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-model-tuning","chapter":"Machine learning for data cubes","heading":"Deep learning model tuning","text":"Model tuning process selecting best set hyperparameters specific application. using deep learning models image classification, highly recommended step enable better fit algorithm training data. Hyperparameters parameters model learned training instead set prior training affect behavior model training. Examples include learning rate, batch size, number epochs, number hidden layers, number neurons layer, activation functions, regularization parameters, optimization algorithms.Deep learning model tuning involves selecting best combination hyperparameters results optimal performance model given task. done training evaluating model different sets hyperparameters select set gives best performance.Deep learning algorithms try find optimal point representing best value prediction function , given input \\(X\\) data points, predicts result \\(Y\\). case, \\(X\\) multidimensional time series, \\(Y\\) vector probabilities possible output classes. complex situations, best prediction function time-consuming estimate. reason, deep learning methods rely gradient descent methods speed predictions converge faster exhaustive search [69]. gradient descent methods use optimization algorithm adjusted hyperparameters learning regularization rates [70]. learning rate controls numerical step gradient descent function, regularization rate controls model overfitting. Adjusting values optimal setting requires using model tuning methods.reduce learning curve, sits provides default values machine learning deep learning methods, ensuring reasonable baseline performance. However, refininig model hyperparameters might necessary, especially complex models sits_lighttae() sits_tempcnn(). end, package provides sits_tuning() function.straightforward approach model tuning run grid search; involves defining range hyperparameter testing possible combinations. approach leads combinational explosion thus recommended. Instead, Bergstra Bengio propose randomly chosen trials [71]. paper shows randomized trials efficient grid search trials, selecting adequate hyperparameters fraction computational cost. sits_tuning() function follows Bergstra Bengio using random search chosen hyperparameters.Since gradient descent plays key role deep learning model fitting, developing optimizers important topic research [72]. Many optimizers proposed literature, recent results reviewed Schmidt et al. [70]. Adamw optimizer provides good baseline reliable performance general deep learning applications [73].Experiments image time series show optimizers may better performance specific problem land classification. reason, authors developed torchopt R package, includes several recently proposed optimizers, including Madgrad [74], Yogi [75]. Using sits_tuning() function allows testing optimizers available torch torch_opt packages.sits_tuning() function takes following parameters:samples: Training data set used model.samples_validation: Optional data set containing time series used validation. missing, next parameter used.validation_split: samples_validation used, parameter defines proportion time series training data set used validation (default 20%).ml_method(): Deep learning method (either sits_mlp(), sits_tempcnn(), sits_resnet(), sits_tae() sits_lighttae()).params: Defines optimizer hyperparameters calling sits_tuning_hparams(), shown example .trials: Number trials run random search.multicores: Number cores used procedure.progress: Show progress bar?sits_tuning_hparams() function inside sits_tuning() allows defining optimizers hyperparameters, including lr (learning rate), eps (controls numerical stability), weight_decay (controls overfitting). default values eps weight_decay sits deep learning functions 1e-08 1e-06, respectively. default lr sits_lighttae() sits_tempcnn() 0.005, sits_tae() sits_resnet() 0.001.Users different ways randomize hyperparameters, including:choice() (list options);uniform (uniform distribution);randint (random integers uniform distribution);normal(mean, sd) (normal distribution);beta(shape1, shape2) (beta distribution);loguniform(max, min) (loguniform distribution).suggest use log-uniform distribution search wide range values span several orders magnitude. common hyperparameters like learning rates, can vary small values (e.g., 0.0001) larger values (e.g., 1.0) logarithmic manner. default, sits_tuning() uses loguniform distribution 10^-2 10^-4 learning rate distribution 10^-2 10^-8 weight decay.result tibble different values accuracy, kappa, decision matrix, hyperparameters. best results obtain accuracy values 0.978 0.970, shown . best result obtained learning rate 0.0013 weight decay 3.73e-07. worst result accuracy 0.891, shows importance tuning procedure.large data sets, tuning process time-consuming. Despite cost, recommended achieve best performance. general, tuning hyperparameters models sits_tempcnn() sits_lighttae() result slight performance improvement default parameters overall accuracy. performance gain stronger less well represented classes, significant gains producer’s user’s accuracies possible. detecting change less frequent classes, tuning can make substantial difference results.","code":"\ntuned <- sits_tuning(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_lighttae(),\n  params = sits_tuning_hparams(\n    optimizer = torch::optim_adamw,\n    opt_hparams = list(\n      lr = loguniform(10^-2, 10^-4),\n      weight_decay = loguniform(10^-2, 10^-8)\n    )\n  ),\n  trials = 40,\n  multicores = 6,\n  progress = FALSE\n)\n# Obtain accuracy, kappa, lr, and weight decay for the 5 best results\n# Hyperparameters are organized as a list\nhparams_5 <- tuned[1:5, ]$opt_hparams\n# Extract learning rate and weight decay from the list\nlr_5 <- purrr::map_dbl(hparams_5, function(h) h$lr)\nwd_5 <- purrr::map_dbl(hparams_5, function(h) h$weight_decay)\n\n# Create a tibble to display the results\nbest_5 <- tibble::tibble(\n  accuracy = tuned[1:5, ]$accuracy,\n  kappa = tuned[1:5, ]$kappa,\n  lr = lr_5,\n  weight_decay = wd_5\n)\n# Print the best five combination of hyperparameters\nbest_5#> # A tibble: 5 × 4\n#>   accuracy kappa       lr weight_decay\n#>      <dbl> <dbl>    <dbl>        <dbl>\n#> 1    0.978 0.974 0.00136  0.000000373 \n#> 2    0.975 0.970 0.00269  0.0000000861\n#> 3    0.973 0.967 0.00162  0.00218     \n#> 4    0.970 0.964 0.000378 0.00000868  \n#> 5    0.970 0.964 0.00198  0.00000275"},{"path":"machine-learning-for-data-cubes.html","id":"considerations-on-model-choice","chapter":"Machine learning for data cubes","heading":"Considerations on model choice","text":"results taken indication method performs better. crucial factor achieving good result quality training data [29]. Experience shows classification quality depends training samples well model matches samples. examples ML classifying large areas, please see papers authors [5], [46], [76], [77].specific case satellite image time series, Russwurm et al. present comparative study seven deep neural networks classification agricultural crops, using random forest baseline [61]. data composed Sentinel-2 images Britanny, France. results indicate slight difference best model (attention-based transformer model) TempCNN, ResNet, random forest. Attention-based models obtain accuracy ranging 80-81%, TempCNN gets 78-80%, random forest obtains 78%. Based result also authors’ experience, make following recommendations:Random forest provides good baseline image time series classification included users’ assessments.Random forest provides good baseline image time series classification included users’ assessments.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.","code":""},{"path":"image-classification-in-data-cubes.html","id":"image-classification-in-data-cubes","chapter":"Image classification in data cubes","heading":"Image classification in data cubes","text":"Chapter discusses classify data cubes providing step--step example. study area state Rondonia, Brazil, underwent substantial deforestation last decades. objective case study detect deforested areas.","code":""},{"path":"image-classification-in-data-cubes.html","id":"data-cube-for-case-study","chapter":"Image classification in data cubes","heading":"Data cube for case study","text":"examples chapter use pre-built data cube Sentinel-2 images, available package sitsdata. images SENTINEL-2-L2A collection Microsoft Planetary Computer (MPC). data consists bands BO2, B8A, B11, indexes NDVI, EVI NBR small area \\(1200 \\times 1200\\) pixels state Rondonia. explained Chapter Earth observation data cubes, must inform sits parse file names obtain tile, date, band information. Image files named according convention “satellite_ sensor_tile_band_date” (e.g., SENTINEL-2_MSI_20LKP_BO2_2020_06_04.tif) default format sits.\nFigure 63: Color composite image cube date 2023-07-16 (Source: authors).\n","code":"\n# Files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LMR/\", package = \"sitsdata\")\n# Read data cube\ncube_20LMR <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n\n# Plot the cube\nplot(cube_20LMR, date = \"2022-07-16\", red = \"B11\", green = \"B8A\", blue = \"B02\")"},{"path":"image-classification-in-data-cubes.html","id":"training-data-for-the-case-study","chapter":"Image classification in data cubes","heading":"Training data for the case study","text":"case study uses training data set samples_deforestation, available package sitsdata. data set consists 6007 samples collected Sentinel-2 images covering state Rondonia. nine classes: “Clear_Cut_Bare_Soil”, “Clear_Cut_Burned_Area”, “Mountainside_Forest”, “Forest”, “Riparian_Forest”, “Clear_Cut_Vegetation”, “Water”, “Wetland”, “Seasonally_Flooded”. time series contains values Sentinel-2/2A bands B02, B8A, B11, indices NDVI, EVI NBR 2022-01-05 2022-12-23 16-day intervals. samples intended detect deforestation events collected remote sensing experts using visual interpretation.helpful plot basic patterns associated samples understand training set better. function sits_patterns() uses generalized additive model (GAM) predict smooth, idealized approximation time series associated class bands. Since data cube used classification three bands (B02, B8A, B11) three indexes (NDVI, EVI, NBR), filter samples bands indexes showing patterns.\nFigure 64: Patterns associated training samples (Source: Authors).\npatterns show different temporal responses selected classes. match typical behavior deforestation Amazon. cases, forest cut start dry season (May/June). end dry season, clear-cut areas burned clean remains; action reflected steep fall response NBR values burned area samples August. areas native trees cut vegatation remain (“Clear_Cut_Vegetation”) values NBR band increase period. sign mixed pixels, combine forest remains bare soil.","code":"\nlibrary(sitsdata)\n# Obtain the samples\ndata(\"samples_deforestation\")\n# Show the contents of the samples\nsummary(samples_deforestation)#> # A tibble: 9 × 3\n#>   label                 count   prop\n#>   <chr>                 <int>  <dbl>\n#> 1 Clear_Cut_Bare_Soil     944 0.157 \n#> 2 Clear_Cut_Burned_Area   983 0.164 \n#> 3 Clear_Cut_Vegetation    603 0.100 \n#> 4 Forest                  964 0.160 \n#> 5 Mountainside_Forest     211 0.0351\n#> 6 Riparian_Forest        1247 0.208 \n#> 7 Seasonally_Flooded      731 0.122 \n#> 8 Water                   109 0.0181\n#> 9 Wetland                 215 0.0358\nsamples_deforestation |>\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NBR\")) |>\n  sits_patterns() |>\n  plot()"},{"path":"image-classification-in-data-cubes.html","id":"training-machine-learning-models","chapter":"Image classification in data cubes","heading":"Training machine learning models","text":"next step train machine learning model illustrate CPU-based classification random forest model tempCNN model. build Random Forest model using sits_train() plot model find important variables model.\nFigure 65: relevant variables Random Forest model (Source: Authors).\nfigure shows “B11” band values date 15 (“2022-08-17”) informative RF model, followed “EVI” index values date 9 (“2022-05-13”). bands dates represent inflection points image time series.","code":"\n# Train model using Temporal CNN model\nrfor_model <- sits_train(\n  samples_deforestation,\n  ml_method = sits_rfor()\n)\nplot(rfor_model)"},{"path":"image-classification-in-data-cubes.html","id":"classification-of-machine-learning-models-in-cpus","chapter":"Image classification in data cubes","heading":"Classification of machine learning models in CPUs","text":"machine learning models available sits (sits_rfor(), sits_svm() sits_xgboost()) use CPU-based parallel processing, done internally package. algorithms adaptable; requirement users inform configuration machines. Details CPU-based parallel processing sits can found Technical Annex.classify data cubes sets time series, use sits_classify(), uses parallel processing speed performance, described end Chapter. relevant parameters : () data, either data cube set time series; (b) ml_model, trained model using one machine learning methods provided; (c) multicores, number CPU cores used processing; (d) memsize, memory available classification; (e) output_dir, directory results stored; (f) version, version control. follow processing steps, turn parameters verbose print information progress get progress bar. classification result data cube set probability layers, one output class. probability layer contains model’s assessment likely pixel belongs related class. probability cube can visualized plot().\nFigure 66: Probabilities class Forest\nprobability cube provides information output values algorithm class. probability maps contain outliers misclassified pixels. labeled map generated pixel-based time series classification method exhibits several misclassified pixels, small patches surrounded different class. occurrence outliers common issue arises due inherent nature classification approach. Regardless resolution, mixed pixels prevalent images, class exhibits considerable data variability. result, factors can lead outliers likely misclassified. overcome limitation, sits employs post-processing smoothing techniques leverage spatial context probability cubes refine results. techniques discussed Chapter Bayesian smoothing post-processing. follows, generate smoothed cube illustrate procedure.\nFigure 67: Smoothened probabilities class Forest\ngeneral, users perform post-processing smoothing obtaining probability maps raster format. post-processing operation, apply sits_label_classification() obtain map likely class pixel. pixel, sits_label_classification() function takes label highest probability assigns resulting map. output labelled map classes. addition, function remove outliers using modal filter clean parameter set TRUE (default value). pixel, modal filter scans neighborhood defined window_size (default = 3) assigns pixel frequent label inside window.\nFigure 68: Final map deforestation obtained random forest model(Source: Authors).\n","code":"\n# Classify data cube to obtain a probability cube\ncube_20LMR_probs <- sits_classify(\n  data = cube_20LMR,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\",\n  multicores = 4,\n  memsize = 16\n)\n\nplot(cube_20LMR_probs, labels = \"Forest\", palette = \"YlGn\")\n# Smoothen a  probability cube\ncube_20LMR_bayes <- sits_smooth(\n  cube = cube_20LMR_probs,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\",\n  multicores = 4,\n  memsize = 16\n)\nplot(cube_20LMR_bayes, labels = c(\"Forest\", \"Clear_Cut_Bare_Soil\"), palette = \"YlGn\")\n# Generate a thematic map\ncube_20LMR_class <- sits_label_classification(\n  cube = cube_20LMR_bayes,\n  clean = TRUE,\n  window_size = 3L,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\"\n)\n\n# Plot the thematic map\nplot(cube_20LMR_class,\n  tmap_options =\n    list(\"scale\" = 0.6)\n)"},{"path":"image-classification-in-data-cubes.html","id":"training-and-running-deep-learning-models","chapter":"Image classification in data cubes","heading":"Training and running deep learning models","text":"next examples shows run deep learning models sits. model show run deep learning methods GPUs available. case study uses Temporal CNN model [58], described ChapterMachine learning data cubes. first show need model tuning, applying model data cube classification.","code":""},{"path":"image-classification-in-data-cubes.html","id":"deep-learning-model-tuning-1","chapter":"Image classification in data cubes","heading":"Deep learning model tuning","text":"example, use sits_tuning() find good hyperparameters train sits_tempcnn() algorithm Rondonia training data set. hyperparameters sits_tempcnn() method include size layers, convolution kernels, dropout rates, learning rate weight decay. Please refer description Temporal CNN algorithm Chapter Machine learning data cubesThe result sits_tuning() tibble different values accuracy, kappa, decision matrix, hyperparameters. five best results obtain accuracy values 0.939 0.908, shown . best result obtained learning rate 3.76e-04 weight decay 1.5e-04, three CNN layers size 256, kernel size 5, dropout rates 0.2.","code":"\ntuned_tempcnn <- sits_tuning(\n  samples = samples_deforestation,\n  ml_method = sits_tempcnn(),\n  params = sits_tuning_hparams(\n    cnn_layers = choice(c(256, 256, 256), c(128, 128, 128), c(64, 64, 64)),\n    cnn_kernels = choice(c(3, 3, 3), c(5, 5, 5), c(7, 7, 7)),\n    cnn_dropout_rates = choice(\n      c(0.15, 0.15, 0.15), c(0.2, 0.2, 0.2),\n      c(0.3, 0.3, 0.3), c(0.4, 0.4, 0.4)\n    ),\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(\n      lr = loguniform(10^-2, 10^-4),\n      weight_decay = loguniform(10^-2, 10^-8)\n    )\n  ),\n  trials = 50,\n  multicores = 4\n)\n# Obtain accuracy, kappa, cnn_layers, cnn_kernels, and cnn_dropout_rates the best result\ncnn_params <- tuned_tempcnn[1, c(\"accuracy\", \"kappa\", \"cnn_layers\", \"cnn_kernels\", \"cnn_dropout_rates\"), ]\n# Learning rates and weight decay are organized as a list\nhparams_best <- tuned_tempcnn[1, ]$opt_hparams[[1]]\n# Extract learning rate and weight decay\nlr_wd <- tibble::tibble(\n  lr_best = hparams_best$lr,\n  wd_best = hparams_best$weight_decay\n)\n# Print the best parameters\ndplyr::bind_cols(cnn_params, lr_wd)#> # A tibble: 1 × 7\n#>   accuracy kappa cnn_layers       cnn_kernels cnn_dropout_rates  lr_best  wd_best\n#>      <dbl> <dbl> <chr>            <chr>       <chr>                <dbl>    <dbl>\n#> 1    0.939 0.929 c(256, 256, 256) c(5, 5, 5)  c(0.2, 0.2, 0.2)  0.000376 0.000153"},{"path":"image-classification-in-data-cubes.html","id":"classification-in-gpus-using-parallel-processing","chapter":"Image classification in data cubes","heading":"Classification in GPUs using parallel processing","text":"Deep learning time series classification methods sits, include sits_tempcnn(), sits_mlp(), sits_resnet(), sits_lightae() sits_tae(), written using torch package, adaptation pyTorch R environment. algorithms can use CUDA-compatible NVDIA GPU properly configured. Please refer torch installation guide details. GPU available, algorithms run regular CPUs, using paralellization methods traditional machine learning methods. Typically, 10-fold performance increase running torch based methods GPUs relative processing time GPU.illustrate use GPUs, take data cube training data used previous examples use Temporal CNN method. first step obtain deep learning model using hyperparameters produced tuning procedure shown earlier. runAfter training model, classify data cube. GPU available, users need provide additional parameter gpu_memory sits_classify() function. information used sits optimize access GPU speed processing.classification, can smooth probability cube label resulting smoothed probabilities obtain classified map.\nFigure 69: Final map deforestation obtained using TempCNN model (Source: Authors).\n","code":"\ntcnn_model <- sits_train(\n  samples_deforestation,\n  sits_tempcnn(\n    cnn_layers = c(256, 256, 256),\n    cnn_kernels = c(5, 5, 5),\n    cnn_dropout_rates = c(0.2, 0.2, 0.2),\n    opt_hparams = list(\n      lr = 0.000376,\n      weight_decay = 0.000153\n    )\n  )\n)\ncube_20LMR_probs_tcnn <- sits_classify(\n  cube_20LMR,\n  ml_model = tcnn_model,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  gpu_memory = 16,\n  multicores = 6,\n  memsize = 24\n)\n# Smoothen the probability map\ncube_20LMR_bayes_tcnn <- sits_smooth(\n  cube_20LMR_probs_tcnn,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  multicores = 6,\n  memsize = 24\n)\n# Obtain the final labelled map\ncube_20LMR_class_tcnn <- sits_label_classification(\n  cube_20LMR_bayes_tcnn,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  multicores = 6,\n  memsize = 24\n)\n# plot the final classification map\nplot(cube_20LMR_class_tcnn,\n  tmap_options = list(\"scale\" = 0.6)\n)"},{"path":"image-classification-in-data-cubes.html","id":"map-reclassification","chapter":"Image classification in data cubes","heading":"Map reclassification","text":"Reclassification remote sensing map refers changing classes assigned different pixels image. purpose reclassification modify information contained image better suit specific use case. sits, reclassification involves assigning new classes pixels based additional information reference map. Users define rules according desired outcome. rules applied classified map. result new map updated classes.illustrate reclassification sits, take classified data cube stored sitsdata package. discussed Chapter Earth observation data cubes, sits can create data cube classified image file. Users need provide original data source collection, directory data stored (data_dir), information retrieve data cube parameters file names (parse_info), labels used classification.\nFigure 70: Original classification map (Source: Authors).\nmap shows total extent deforestation clear cuts estimated sits random forest algorithm area Rondonia, Brazil, based time series Sentinel-2 images period 2020-06-04 2021-08-26. Suppose want estimate deforestation occurred June 2020 August 2021. need reference map containing information forest cuts 2020.example, use reference PRODES deforestation map Amazonia created Brazil’s National Institute Space Research (INPE). map produced visual interpretation. PRODES measures deforestation every year, starting August one year July following year. contains classes represent natural world (Forest, Water, NonForest, NonForest2) classes capture yearly deforestation increments. classes named “dYYYY” “rYYYY”; first refers deforestation given year (e.g., “d2008” deforestation August 2007 July 2008); second places satellite data sufficient determine land class (e.g., “r2010” 2010). map available package sitsdata, shown .Since labels deforestation map specialized part default sits color table, define legend better visualization different deforestation classes.Using new legend, can visualize PRODES deforestation map.\nFigure 71: Deforestation map produced PRODES.\nTaking PRODES map reference, can include new labels classified map produced sits using sits_reclassify(). new class name Defor_2020 applied pixels PRODES considers deforested July 2020. also include Non_Forest class include pixels PRODES takes covered native vegetation, wetlands rocky areas. PRODES classes used mask sits deforestation map.sits_reclassify() operation requires parameters: () cube, classified data cube whose pixels reclassified; (b) mask, reference data cube used mask; (c) rules, named list. names rules list new label. new label associated mask vector includes labels reference map joined. sits_reclassify() compares original reference map pixel pixel. pixel reference map whose labels one rules, algorithm relabels original map. result reclassified map original labels plus new labels masked using reference map.\nFigure 72: Deforestation map sits masked PRODES map (Source: Authors).\nreclassified map split deforestation mid-2020 (using PRODES map) areas classified sits taken deforested mid-2020 mid-2021. allows experts measure much deforestation occurred period according sits compare result PRODES map.sits_reclassify() function restricted comparing deforestation maps. can used case requires masking result based reference map.","code":"\n# Open classification map\ndata_dir <- system.file(\"extdata/Rondonia-Class\", package = \"sitsdata\")\nro_class <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"satellite\", \"sensor\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  labels = c(\n    \"1\" = \"Water\", \"2\" = \"Clear_Cut_Burned_Area\",\n    \"3\" = \"Clear_Cut_Bare_Soil\",\n    \"4\" = \"Clear_Cut_Vegetation\",\n    \"5\" = \"Forest\",\n    \"6\" = \"Bare_Soil\",\n    \"7\" = \"Wetland\"\n  )\n)\n\nplot(ro_class,\n  tmap_options = list(\"scale\" = 0.6)\n)\ndata_dir <- system.file(\"extdata/PRODES\", package = \"sitsdata\")\nprodes2021 <- sits_cube(\n  source = \"USGS\",\n  collection = \"LANDSAT-C2L2-SR\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"product\", \"sensor\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  version = \"v20220606\",\n  labels = c(\n    \"1\" = \"Forest\", \"2\" = \"Water\", \"3\" = \"NonForest\",\n    \"4\" = \"NonForest2\", \"6\" = \"d2007\", \"7\" = \"d2008\",\n    \"8\" = \"d2009\", \"9\" = \"d2010\", \"10\" = \"d2011\",\n    \"11\" = \"d2012\", \"12\" = \"d2013\", \"13\" = \"d2014\",\n    \"14\" = \"d2015\", \"15\" = \"d2016\", \"16\" = \"d2017\",\n    \"17\" = \"d2018\", \"18\" = \"r2010\", \"19\" = \"r2011\",\n    \"20\" = \"r2012\", \"21\" = \"r2013\", \"22\" = \"r2014\",\n    \"23\" = \"r2015\", \"24\" = \"r2016\", \"25\" = \"r2017\",\n    \"26\" = \"r2018\", \"27\" = \"d2019\", \"28\" = \"r2019\",\n    \"29\" = \"d2020\", \"31\" = \"r2020\", \"32\" = \"Clouds2021\",\n    \"33\" = \"d2021\", \"34\" = \"r2021\"\n  )\n)\n# Use the RColorBrewer palette \"YlOrBr\" for the deforestation years\ncolors <- grDevices::hcl.colors(n = 15, palette = \"YlOrBr\")\n# Define the legend for the deforestation map\ndef_legend <- c(\n  \"Forest\" = \"forestgreen\", \"Water\" = \"dodgerblue3\",\n  \"NonForest\" = \"bisque2\", \"NonForest2\" = \"bisque2\",\n  \"d2007\" = colors[1], \"d2008\" = colors[2],\n  \"d2009\" = colors[3], \"d2010\" = colors[4],\n  \"d2011\" = colors[5], \"d2012\" = colors[6],\n  \"d2013\" = colors[7], \"d2014\" = colors[8],\n  \"d2015\" = colors[9], \"d2016\" = colors[10],\n  \"d2017\" = colors[11], \"d2018\" = colors[12],\n  \"d2019\" = colors[13], \"d2020\" = colors[14],\n  \"d2021\" = colors[15], \"r2010\" = \"lightcyan\",\n  \"r2011\" = \"lightcyan\", \"r2012\" = \"lightcyan\",\n  \"r2013\" = \"lightcyan\", \"r2014\" = \"lightcyan\",\n  \"r2015\" = \"lightcyan\", \"r2016\" = \"lightcyan\",\n  \"r2017\" = \"lightcyan\", \"r2018\" = \"lightcyan\",\n  \"r2019\" = \"lightcyan\", \"r2020\" = \"lightcyan\",\n  \"r2021\" = \"lightcyan\", \"Clouds2021\" = \"lightblue2\"\n)\nsits_view(prodes2021, legend = def_legend)\n# Reclassify cube\nro_def_2021 <- sits_reclassify(\n  cube = ro_class,\n  mask = prodes2021,\n  rules = list(\n    \"Non_Forest\" = mask %in% c(\"NonForest\", \"NonForest2\"),\n    \"Deforestation_Mask\" = mask %in% c(\n      \"d2007\", \"d2008\", \"d2009\",\n      \"d2010\", \"d2011\", \"d2012\",\n      \"d2013\", \"d2014\", \"d2015\",\n      \"d2016\", \"d2017\", \"d2018\",\n      \"d2019\", \"d2020\",\n      \"r2010\", \"r2011\", \"r2012\",\n      \"r2013\", \"r2014\", \"r2015\",\n      \"r2016\", \"r2017\", \"r2018\",\n      \"r2019\", \"r2020\", \"r2021\"\n    ),\n    \"Water\" = mask == \"Water\"\n  ),\n  memsize = 8,\n  multicores = 2,\n  output_dir = \"./tempdir/chp9\",\n  version = \"reclass\"\n)\n\n# Plot the reclassified map\nplot(ro_def_2021,\n  tmap_options = list(\"scale\" = 0.6)\n)"},{"path":"bayesian-smoothing-for-post-processing.html","id":"bayesian-smoothing-for-post-processing","chapter":"Bayesian smoothing for post-processing","heading":"Bayesian smoothing for post-processing","text":"","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"introduction-1","chapter":"Bayesian smoothing for post-processing","heading":"Introduction","text":"Machine learning algorithms rely training samples derived “pure” pixels, hand-picked users represent desired output classes. Given presence mixed pixels images regardless resolution, considerable data variability within class, classifiers often produce results outliers misclassified pixels. Therefore, post-processing techniques become crucial refine labels classified image . Post-processing methods reduce salt--pepper border effects, single pixels small groups pixels classified differently larger surrounding areas; effects leads visual discontinuity inconsistency. mitigating errors minimizing noise, post-processing improves quality initial classification results, bringing significant gain overall accuracy interpretability final output .sits package uses time-first, space-later approach. Since machine learning classifiers sits mostly pixel-based, necessary complement spatial smoothing methods. methods improve accuracy land classification incorporating spatial contextual information classification process. smoothing method available sits uses Empirical Bayes approach, adjusted specific properties land classification. assumption class probabilities local level similar provide baseline comparison pixel values produced classifier. Based two elements, Bayesian smoothing adjusts probabilities pixels, considering spatial dependence.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"empirical-bayesian-estimation","chapter":"Bayesian smoothing for post-processing","heading":"Empirical Bayesian estimation","text":"Bayesian estimate based probabilities produced classifiers. Let \\(p_{,k} \\geq 0\\) prior probability \\(\\)-th pixel belonging class \\(k \\\\{1, \\ldots, m\\}\\). probabilities \\(p_{,k}\\) classifier’s output, subject noise, outliers, classification errors. estimation aims remove effects obtain values approximate actual class probability better.convert class probability values \\(p_{,k}\\) log-odds values using logit function, transform probability values ranging \\(0\\) \\(1\\) values negative infinity infinity. conversion probabilities logit values helpful support assumption normal distribution data.\\[\n    x_{,k} = \\ln \\left(\\frac{p_{,k}}{1 - p_{,k}}\\right)\n\\]standard Empirical Bayesian updating leads estimation values posterior distribution can expressed weighted mean\\[\n{E}[\\mu_{,k} | x_{,k}] =\n\\Biggl [ \\frac{s^2_{,k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times\nx_{,k} +\n\\Biggl [ \\frac{\\sigma^2_{k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times m_{,k},\n\\]\n:\\(x_{,k}\\) logit value pixel \\(\\) class \\(k\\).\\(m_{,k}\\) average logit values pixels class \\(k\\)\nneighborhood pixel \\(\\).\\(s^2_{,k}\\) variance logit values pixels class \\(k\\)\nneighborhood pixel \\(\\).\\(\\sigma^2_{k}\\) user-derived hyperparameter estimates variance class \\(k\\), expressed logits.equation weighted average value \\(x_{,k}\\) pixel mean \\(m_{,k}\\) neighboring pixels. variance \\(s^2_{,k}\\) neighbors high, algorithm gives weight pixel value \\(x_{,k}\\). class variance \\(\\sigma^2_k\\) increases, results gives weight neighborhood mean \\(m_{,k}\\).","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"using-non-isotropic-neighbourhoods","chapter":"Bayesian smoothing for post-processing","heading":"Using non-isotropic neighbourhoods","text":"fundamental idea behind Bayesian smoothing land classification individual pixels area related close . pixel usually class neighbours. closeness relations expressed similar values class probability. find pixel assigned “Water” surrounded pixels labelled “Forest”, pixel may wrongly labelled. check pixel mislabelled, look class probabilities pixels neighbors. possible situations:outlier class probability distribution different neighbors. example, probability belonging “Water” class 80% “Forest” 20%. also consider “Water” pixels smaller variance, since water areas strong signal multispectral images, post-processing method change pixel’s label.outlier class probability distribution different neighbors. example, probability belonging “Water” class 80% “Forest” 20%. also consider “Water” pixels smaller variance, since water areas strong signal multispectral images, post-processing method change pixel’s label.outlier class probability distribution similar neighbors. Consider case pixel 47% probability “Water” 43% probability “Forest”. small difference indicates need look neighbourhood improve information produced classifier. cases, post-processing estimate may change pixel’s label.outlier class probability distribution similar neighbors. Consider case pixel 47% probability “Water” 43% probability “Forest”. small difference indicates need look neighbourhood improve information produced classifier. cases, post-processing estimate may change pixel’s label.Pixels border two areas different classes pose challenge. neighbours belong class pixel. address issue, employ non-isotropic definition neighbourhood estimate prior class distribution. instance, consider boundary pixel neighborhood defined 7 x 7 window, located along border Forest Grassland classes. estimate prior probability pixel labelled Forest, take account neighbours one side border likely correctly classified Forest. Pixels opposite side border disregarded, since unlikely belong spatial process. practice, use half pixels 7 x 7 window, opting higher probability named Forest. prior probability Grassland class, reverse selection consider opposite side border.Although choice neighbourhood may seem unconventional, consistent assumption non-continuity spatial processes describing class. dense forest patch, example, pixels strong spatial autocorrelation values Forest class; however, spatial autocorrelation doesn’t extend across border land classes.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"effect-of-the-hyperparameter","chapter":"Bayesian smoothing for post-processing","heading":"Effect of the hyperparameter","text":"parameter \\(\\sigma^2_k\\) controls level smoothness. \\(\\sigma^2_k\\) zero, value \\({E}[\\mu_{,k} | x_{,k}]\\) equal pixel value \\(x_{,k}\\). parameter \\(\\sigma^2_k\\) expresses confidence inherent variability distribution values class \\(k\\). smaller parameter \\(\\sigma^2_k\\), trust estimated probability values produced classifier class \\(k\\). Conversely, higher values \\(\\sigma^2_k\\) indicate lower confidence classifier outputs improved confidence local averages.Consider following two-class example. Take pixel probability \\(0.4\\) (logit \\(x_{,1} = -0.4054\\)) class probability \\(0.6\\) (logit \\(x_{,2} = 0.4054\\)) class B. Without post-processing, pixel labeled class B. Consider local average \\(0.6\\) (logit \\(m_{,1} = 0.4054\\)) class \\(0.4\\) (logit \\(m_{,2} = -0.4054\\)) class B. case outlier classified originally class B midst set class pixels.Given situation, apply proposed method. Suppose local variance logits \\(s^2_{,1} = 5\\) class \\(s^2_{,2} = 10\\) class B. difference expected local variability class smaller class B. complete estimate, need set parameter \\(\\sigma^2_{k}\\), representing belief variability probability values class.Setting \\(\\sigma^2_{k}\\) based confidence local variability class around pixel \\({}\\). considered local variability high, can take \\(\\sigma^2_1\\) class \\(\\sigma^2_2\\) class B 10. case, Bayesian estimated probability class \\(0.52\\) class B \\(0.48\\) pixel relabelled class .contrast, consider local variability high set \\(\\sigma^2\\) 5 classes B, Bayesian probability estimate \\(0.48\\) class \\(0.52\\) class B. case, original class kept. Therefore, result sensitive subjective choice hyperparameter.make following recommendations setting \\(\\sigma^2_{k}\\) parameter:Set \\(\\sigma^2_{k}\\) parameter high values (\\(20\\) ) increase neighborhood influence compared probability values pixel. Classes whose probabilities strong spatial autocorrelation tend replace outliers different classes.Set \\(\\sigma^2_{k}\\) parameter high values (\\(20\\) ) increase neighborhood influence compared probability values pixel. Classes whose probabilities strong spatial autocorrelation tend replace outliers different classes.Set \\(\\sigma^2_{k}\\) parameter low values (\\(5\\) ) reduce neighborhood influence compared probabilities pixel class \\(k\\). way, classes low spatial autocorrelation likely relabeled.Set \\(\\sigma^2_{k}\\) parameter low values (\\(5\\) ) reduce neighborhood influence compared probabilities pixel class \\(k\\). way, classes low spatial autocorrelation likely relabeled.Consider case forest areas watersheds. expert wishes compact areas classified forests without many outliers inside , set \\(\\sigma^2\\) parameter class Forest high. comparison, avoid small watersheds similar neighbors relabeled, advisable avoid strong influence neighbors, setting \\(\\sigma^2\\) low possible.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"running-bayesian-smoothing","chapter":"Bayesian smoothing for post-processing","heading":"Running Bayesian smoothing","text":"example , create probability cube based existing local file.\nFigure 73: Probability map produced classes Forest Water (Source: Authors).\nprobability map class Forest shows high values associated compact patches linear stretches riparian areas. contrast, probability map class Water mostly low values, except places high chance occurrence class. understand behavior Bayesian estimator, helpful examine local variance associated logits probabilities.first reference classified map without smoothing, shows presence outliers classification errors. obtain , use sits_label_classification(), taking probability map input, follows.\nFigure 74: Classified map without smoothing (Source: Authors).\nremove outliers classification errors, run smoothing procedure sits_smooth() parameters: () cube, probability cube produced sits_classify(); (b) window_size, local window compute neighborhood probabilities; (d) neigh_fraction, fraction local neighbors used calculate local statistics; (e) smoothness, vector estimates prior variance class; (f) multicores, number CPU cores used processing; (g) memsize, memory available classification; (h) output_dir, directory results stored; () version, version control. resulting cube can visualized plot(). follows, compare smoothing effect varying window_size smoothness parameters.Together, parameters window_size neigh_fraction control many pixels neighborhood Bayesian estimator use calculate local statistics. example, setting window size \\(7\\) neigh_fraction \\(0.50\\) (defaults) ensures \\(25\\) samples used estimate local statistics.smoothness values classes aare set value \\(20\\), relatively high. case, situations, new value probability strongly influenced local average.\nFigure 75: Probability maps bayesian smoothing (Source: Authors).\nBayesian smoothing removed local variability associated misclassified pixels differ neighbors. side effect: water areas surrounded forests preserved forest probability map. smoothing impact best appreciated comparing labeled map produced without smoothing one follows procedure, shown .\nFigure 76: Final classification map Bayesian smoothing 7 x 7 window, using neigh_fraction = 0.5 smoothness = 20 (Source: Authors).\nsmoothed map, outliers removed expanding forest areas. Forests replaced small corridors water soil encircled trees. effect due high probability forest detection training data. keep water areas reduce expansion forest area, viable alternative reduce smoothness (\\(\\sigma^2\\)) Forest Water classes. way, local influence forest classes reduced. water areas, since narrow, neighborhoods many low probability values, reduce expected value Bayesian estimator.\nFigure 77: Probability maps Bayesian smoothing 7 x 7 window low smoothness classes Water Forest (Source: Authors).\nComparing two maps, narrow water streams inside forest area better preserved. Small corridors forest areas also maintained. better comparison two maps requires importing QGIS.conclusion, post-processing desirable step classification process. Bayesian smoothing improves borders objects created classification removes outliers result pixel-based classification. reliable method used situations.","code":"\n# define the classes of the probability cube\nlabels <- c(\n  \"1\" = \"Water\",\n  \"2\" = \"Clear_Cut_Burned_Area\",\n  \"3\" = \"Clear_Cut_Bare_Soil\",\n  \"4\" = \"Clear_Cut_Vegetation\",\n  \"5\" = \"Forest\",\n  \"6\" = \"Wetland\"\n)\n# directory where the data is stored\ndata_dir <- system.file(\"extdata/Rondonia-20LLQ/\", package = \"sitsdata\")\n# create a probability data cube from a file\nprobs_cube <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  bands = \"probs\",\n  labels = labels,\n  parse_info = c(\n    \"satellite\", \"sensor\", \"tile\",\n    \"start_date\", \"end_date\", \"band\", \"version\"\n  )\n)\n\n# plot the probabilities for water and forest\nplot(probs_cube, labels = c(\"Water\", \"Forest\"))\n# Generate the thematic map\nclass_map <- sits_label_classification(\n  cube = probs_cube,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp10\",\n  version = \"no_smooth\"\n)\n\n# Plot the result\nplot(class_map,\n  tmap_options = list(\"scale\" = 0.6)\n)\n# Compute Bayesian smoothing\ncube_smooth_w7_f05_s20 <- sits_smooth(\n  cube = probs_cube,\n  window_size = 7,\n  neigh_fraction = 0.50,\n  smoothness = 20,\n  multicores = 4,\n  memsize = 12,\n  version = \"w7-f05-s20\",\n  output_dir = \"./tempdir/chp10\"\n)\n\n# Plot the result\nplot(cube_smooth_w7_f05_s20, labels = c(\"Water\", \"Forest\"), palette = \"YlGn\")\n# Generate the thematic map\ndefor_map_w7_f05_20 <- sits_label_classification(\n  cube = cube_smooth_w7_f05_s20,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp8\",\n  version = \"w7-f05-s20\"\n)\n\nplot(defor_map_w7_f05_20,\n  tmap_options = list(\"scale\" = 0.6)\n)\n# Reduce smoothing for classes Water and Forest\n# Labels:  \"Water\", \"ClearCut_Burn\", \"ClearCut_Soil\",\n#          \"ClearCut_Veg\", \"Forest\", \"Wetland\"\nsmooth_water_forest <- c(5, 20, 20, 20, 5, 20)\n# Compute Bayesian smoothing\ncube_smooth_w7_f05_swf <- sits_smooth(\n  cube = probs_cube,\n  window_size = 7,\n  neigh_fraction = 0.5,\n  smoothness = smooth_water_forest,\n  multicores = 4,\n  memsize = 12,\n  version = \"w7-f05-swf\",\n  output_dir = \"./tempdir/chp10\"\n)\n\n# Computed labeled map\ndefor_map_w7_f05_swf <- sits_label_classification(\n  cube = cube_smooth_w7_f05_swf,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp10\",\n  version = \"w7-f05-swf\"\n)\n\nplot(defor_map_w7_f05_swf,\n  tmap_options = list(\"scale\" = 0.6)\n)"},{"path":"validation-and-accuracy-measurements.html","id":"validation-and-accuracy-measurements","chapter":"Validation and accuracy measurements","heading":"Validation and accuracy measurements","text":"","code":""},{"path":"validation-and-accuracy-measurements.html","id":"case-study","chapter":"Validation and accuracy measurements","heading":"Case study","text":"show validation accuracy assessment insits, show example land classification Cerrado biome, second largest biome Brazil 1.9 million km\\(^2\\). Brazilian Cerrado tropical savanna ecoregion rich ecosystem ranging grasslands woodlands. home 7000 species plants high levels endemism [78]. includes three major types natural vegetation: Open Cerrado, typically composed grasses small shrubs sporadic presence small tree vegetation; Cerrado, typical savanna formation presence low, irregularly branched, thin-trunked trees; Cerradão, areas medium-sized trees (10–12 m) [79]. natural areas converted agriculture fast pace, one world’s fast-moving agricultural frontiers [80]. main agricultural land uses include cattle ranching, crop farms, planted forests. classification follows work Simoes et al. [60].data comprises 67 Landsat-8 tiles Brazil Data Cube (BDC), 23 time steps covering 2017-08-29 2018-08-29. Since data available Brazil Data Cube, users first obtain access BDC obtaining access key. obtaining access key, include credentials using environment variables, shown . Obtaining BDC access key free. obtain key, users need register BDC site.obtaining BDC access key, can now create data cube Cerrado biome.classify Cerrado, use training data set produced Simoes et al. [60]. authors carried systematic sampling using \\(5 \\times 5\\) km grid throughout Cerrado biome, collecting 85,026 samples. training data labels extracted three sources: 2018 pastureland map Parente et al. [81], MapBiomas Collection 5 2018 [82], Brazil’s National Mapping Agency IBGE land maps 2016–2018. 85,026 samples, authors selected without disagreement labels assigned three sources. final training set consists 48,850 points authors extracted time series using Landsat-8 data cube available BDC. classes training set : Annual Crop, Cerradao, Cerrado, Open Cerrado, Nat_NonVeg (Dunes), Pasture, Perennial_Crop, Silviculture (Planted Forests), Sugarcane, Water.data set available package sitsdata samples_cerrado_lc8.","code":"\n# Files are available in the Brazil Data Cube\n#\n# Obtain the region of interest covering the Cerrado biome\nroi_cerrado_shp <- system.file(\n  \"extdata/shapefiles/cerrado_border/cerrado_border.shp\",\n  package = \"sitsdata\"\n)\n# Read the shapefile as an object of the \"sf\" package\nroi_cerrado <- sf::st_read(roi_cerrado_shp, quiet = TRUE)\n# Create a data cube for the entire Cerrado biome\ncerrado_cube <- sits_cube(\n  source = \"BDC\",\n  collection = \"LANDSAT-OLI-16D\",\n  roi = roi_cerrado,\n  start_date = \"2017-08-29\",\n  end_date = \"2018-08-29\",\n  multicores = 3\n)\nlibrary(sitsdata)\ndata(\"samples_cerrado_lc8\")\n# Show the class distribution in the new training set\nsummary(samples_cerrado_lc8)#> # A tibble: 10 × 3\n#>    label          count     prop\n#>    <chr>          <int>    <dbl>\n#>  1 Annual_Crop     6887 0.141   \n#>  2 Cerradao        4211 0.0862  \n#>  3 Cerrado        16251 0.333   \n#>  4 Nat_NonVeg        38 0.000778\n#>  5 Open_Cerrado    5658 0.116   \n#>  6 Pasture        12894 0.264   \n#>  7 Perennial_Crop    68 0.00139 \n#>  8 Silviculture     805 0.0165  \n#>  9 Sugarcane       1775 0.0363  \n#> 10 Water            263 0.00538"},{"path":"validation-and-accuracy-measurements.html","id":"cross-validation-of-training-set","chapter":"Validation and accuracy measurements","heading":"Cross-validation of training set","text":"first step analysing results perform cross-validation. Since data set big highly imbalanced, use sits_reduce_imbalance() reduce size produce smaller, balanced sample data set validation examples.following code five-fold validation using random forest algorithm.One useful function sits capacity compare different validation methods store XLS file analysis. following example shows using Cerrado data set. take models: random forest (sits_rfor()), extreme gradient boosting (sits_xgboost()), temporal CNN (sits_tempcnn()), lightweight temporal attention encoder (sits_lighttae()). computing confusion matrix statistics model, also store result list. calculation finished, function sits_to_xlsx() writes results Excel-compatible spreadsheet.resulting Excel file can opened R using spreadsheet programs. Figure 78 shows printout read Excel. sheet corresponds output one model. simplicity, show result TempCNN, overall accuracy 90%.\nFigure 78: Result 5-fold cross-validation Mato Grosso data using LightTAE (Source: Authors).\nscores overall accuracy similar models. However, models significant differences, shown comparing F1 scores .table shows F1-scores classes model, produced k-fold validation. F1-scores harmonic mean user’s accuracy precision accuracy class. results show , although deep learning models TempCNN LightTAE similar overall accuracies random forest XGBoost, F1-scores per class generally better.cross-validation results interpreted carefully. Cross-validation measures well model fits training data. Using results measure classification accuracy valid training data good sample entire data set. practice, training data subject various sources bias. cases land classification, classes much frequent others, , training data set imbalanced. large areas, regional differences soil climate condition lead classes different spectral responses. collecting samples large areas, field analysts may restricted areas access (e.g., along roads). additional problem mixed pixels. Expert interpreters tend select samples stand fieldwork reference images. Border pixels unlikely chosen part training data. reasons, cross-validation results considered indicative accuracy measurement entire data set.","code":"\n# Reduce imbalance in the data set\n# Maximum number of samples per class will be 1000\n# Minimum number of samples per class will be 500\nsamples_cerrado_bal <- sits_reduce_imbalance(\n  samples = samples_cerrado_lc8,\n  n_samples_over = 500,\n  n_samples_under = 1000,\n  multicores = 4\n)\n\n# Show new sample distribution\nsummary(samples_cerrado_bal)#> # A tibble: 10 × 3\n#>    label          count   prop\n#>    <chr>          <int>  <dbl>\n#>  1 Annual_Crop     1000 0.124 \n#>  2 Cerradao         884 0.110 \n#>  3 Cerrado          980 0.121 \n#>  4 Nat_NonVeg       500 0.0619\n#>  5 Open_Cerrado     960 0.119 \n#>  6 Pasture          972 0.120 \n#>  7 Perennial_Crop   500 0.0619\n#>  8 Silviculture     805 0.0997\n#>  9 Sugarcane        972 0.120 \n#> 10 Water            500 0.0619\n# Perform a five-fold validation for the Cerrado data set\n# Random forest machine learning method using default parameters\nval_rfor <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  folds = 5,\n  ml_method = sits_rfor(),\n  multicores = 5\n)\n\n# Print the validation statistics\nsummary(val_rfor)#> Overall Statistics                            \n#>  Accuracy : 0.8781          \n#>    95% CI : (0.8708, 0.8852)\n#>     Kappa : 0.8635\n# Compare different models for the Cerrado data set\n# Create a list to store the results\nresults <- list()\n# Give a name to the results of the random forest model (see above)\nval_rfor$name <- \"rfor\"\n# Store the rfor results in a list\nresults[[length(results) + 1]] <- val_rfor\n# Extreme Gradient Boosting\nval_xgb <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_xgboost(),\n  folds = 5,\n  multicores = 5\n)\n# Give a name to the SVM model\nval_xgb$name <- \"xgboost\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_xgb\n# Temporal CNN\nval_tcnn <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_tempcnn(\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001)\n  ),\n  folds = 5,\n  multicores = 5\n)\n# Give a name to the result\nval_tcnn$name <- \"TempCNN\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_tcnn\n# Light TAE\nval_ltae <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_lighttae(\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001)\n  ),\n  folds = 5,\n  multicores = 5\n)\n# Give a name to the result\nval_ltae$name <- \"LightTAE\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_ltae\n# Save to an XLS file\nxlsx_file <- \"./model_comparison.xlsx\"\n\nsits_to_xlsx(results, file = xlsx_file)\nmodel_acc <- tibble::tibble(\n  \"Random Forest\" = val_rfor$overall[[\"Accuracy\"]],\n  \"XGBoost\"       = val_xgb$overall[[\"Accuracy\"]],\n  \"TempCNN\"       = val_tcnn$overall[[\"Accuracy\"]],\n  \"LightTAE\"      = val_ltae$overall[[\"Accuracy\"]]\n)\n\noptions(digits = 3)\nmodel_acc#> # A tibble: 1 × 4\n#>   `Random Forest` XGBoost TempCNN LightTAE\n#>             <dbl>   <dbl>   <dbl>    <dbl>\n#> 1           0.879   0.889   0.897    0.894\nf1_score_rfor <- unname(val_rfor$byClass[, \"F1\"])\nf1_score_xgb <- unname(val_xgb$byClass[, \"F1\"])\nf1_score_tcnn <- unname(val_tcnn$byClass[, \"F1\"])\nf1_score_ltae <- unname(val_ltae$byClass[, \"F1\"])\n\nf1_scores <- tibble::tibble(\n  \"Classes\"  = sits_labels(samples_cerrado_bal),\n  \"RandFor\"  = f1_score_rfor,\n  \"XGBoost\"  = f1_score_xgb,\n  \"TempCNN\"  = f1_score_tcnn,\n  \"LightTAE\" = f1_score_ltae\n)\n\nf1_scores#> # A tibble: 10 × 5\n#>    Classes        RandFor XGBoost TempCNN LightTAE\n#>    <chr>            <dbl>   <dbl>   <dbl>    <dbl>\n#>  1 Annual_Crop      0.909   0.903   0.924    0.912\n#>  2 Cerradao         0.878   0.889   0.877    0.882\n#>  3 Cerrado          0.746   0.759   0.755    0.748\n#>  4 Nat_NonVeg       0.823   0.835   0.838    0.833\n#>  5 Open_Cerrado     0.824   0.847   0.854    0.859\n#>  6 Pasture          0.917   0.933   0.947    0.931\n#>  7 Perennial_Crop   0.999   0.999   0.998    1    \n#>  8 Silviculture     0.977   0.976   0.990    0.995\n#>  9 Sugarcane        0.998   0.998   1        0.998\n#> 10 Water            0.890   0.911   0.945    0.936"},{"path":"validation-and-accuracy-measurements.html","id":"accuracy-assessment-of-classified-images","chapter":"Validation and accuracy measurements","heading":"Accuracy assessment of classified images","text":"measure accuracy classified images, sits_accuracy() uses area-weighted technique, following best practices proposed Olofsson et al. [83]. need area-weighted estimates arises land classes evenly distributed space. applications (e.g., deforestation) interest lies assessing much image changed, area mapped deforested likely small fraction total area. users disregard relative importance small areas change taking place, overall accuracy estimate inflated unrealistic. reason, Olofsson et al. argue “mapped areas adjusted eliminate bias attributable map classification error, error-adjusted area estimates accompanied confidence intervals quantify sampling variability estimated area” [83].motivation, measuring accuracy classified images, sits_accuracy() follows procedure set Olofsson et al. [83]. Given classified image validation file, first step calculates confusion matrix traditional way, .e., identifying commission omission errors. calculates unbiased estimator proportion area cell \\(,j\\) error matrix\\[\n\\hat{p_{,j}} = W_i\\frac{n_{,j}}{n_i},\n\\]\ntotal area map \\(A_{tot}\\), mapping area class \\(\\) \\(A_{m,}\\) proportion area mapped class \\(\\) \\(W_i = {A_{m,}}/{A_{tot}}\\). Adjusting area size allows producing unbiased estimation total area class \\(j\\), defined stratified estimator\n\\[\n\\hat{A_j} = A_{tot}\\sum_{=1}^KW_i\\frac{n_{,j}}{n_i}.\n\\]unbiased area estimator includes effect false negatives (omission error) considering effect false positives (commission error). area estimates also allow unbiased estimate user’s producer’s accuracy class. Following Olofsson et al. [83], provide 95% confidence interval \\(\\hat{A_j}\\).produce adjusted area estimates, sits_accuracy() must get classified image together csv file containing set well-selected labeled points. csv file format one used obtain samples, discussed earlier.labeled points based random stratified sample. areas associated class contribute test data used accuracy assessment.biases inherent cross-validation training data, independent validation data set used measure classification accuracy. case study, Simoes et al. systematic sampling Cerrado biome using \\(20 \\times 20\\) km grid total 5,402 points [60]. samples independent training set used classification. interpreted five specialists using high-resolution images period classification. resulted 5,286 evaluation samples thus distributed: Annual Crop (553), Cerrado (3,155), Natural Non Vegetated (44), Pasture (1,246), Perennial Crop (38), Silviculture (94), Sugarcane (77), Water (79). data set available package sitsdata, described . validation file, samples belonging classes Cerrado, Open Cerrado, Cerradao (Woody Savanna) grouped together single class.first step obtain classification map. code full classification Cerrado biome, using TempCNN algorithm, shown . large data size, code executed.Since code included information , use labeled cube available sitsdata package perform accuracy assessment. First, retrieve metadata cube.\nFigure 79: Classification tile 044048 Landsat data cube Brazilian Cerrado 2017/2018 (Source: Authors).\nnext step provide csv file validation points, described .example shows important correct area estimates land classification reduce bias effect misclassification consider different producer’s accuracies associated class. also shows actual overall accuracy generally lower result cross-validation.","code":"\n# This code shows the classification of the Cerrado biome\n# It is included for information purposes\n# It takes a long time to run\ntcnn_model <- sits_train(\n  samples = samples_cerrado_lc8,\n  ml_method = sits_tempcnn()\n)\n\n# Using the tempCNN model to classify the Cerrado\n# This example should be run on a large virtual machine\ncerrado_probs_cube <- sits_classify(\n  cube = cerrado_cube,\n  ml_model = tcnn_model,\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./tempdir/chp11\"\n)\n\ncerrado_bayes_cube <- sits_smooth(\n  cube = cerrado_probs_cube,\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./tempdir/chp11\"\n)\n\ncerrado_classif <- sits_label_classification(\n  cube = cerrado_bayes_cube,\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./tempdir/chp11\"\n)\n# Retrieve the metadata for the classified cube\n# The files are stored in the sitsdata package\ndata_dir <- system.file(\"extdata/Cerrado\", package = \"sitsdata\")\n# labels for the classification\nlabels <- c(\n  \"1\" = \"Annual_Crop\", \"2\" = \"Cerrado\", \"3\" = \"Cerrado\", \"4\" = \"Nat_NonVeg\",\n  \"5\" = \"Cerrado\", \"6\" = \"Pasture\", \"7\" = \"Perennial_Crop\",\n  \"8\" = \"Silviculture\", \"9\" = \"Sugarcane\", \"10\" = \"Water\"\n)\n# Read the cube metadata\ncerrado_classif <- sits_cube(\n  source = \"USGS\",\n  collection = \"LANDSAT-C2L2-SR\",\n  bands = \"class\",\n  labels = labels,\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"start_date\", \"end_date\", \"version\")\n)\n# Plot one tile of the classification\nplot(cerrado_classif, tiles = \"044048\")\n# Get ground truth points\nvalid_csv <- system.file(\"extdata/csv/cerrado_lc8_validation.csv\",\n  package = \"sitsdata\"\n)\n# Calculate accuracy according to Olofsson's method\narea_acc <- sits_accuracy(cerrado_classif,\n  validation_csv = valid_csv\n)\n# Print the area estimated accuracy\narea_acc#> $error_matrix\n#>                 \n#>                  Annual_Crop Cerrado Nat_NonVeg Pasture Perennial_Crop\n#>   Annual_Crop            469      13          0      47              0\n#>   Cerrado                  4    2813          0     191              3\n#>   Nat_NonVeg               0       2         43       0              0\n#>   Pasture                 67     287          0     999              5\n#>   Perennial_Crop           0      23          0       2             26\n#>   Silviculture             0      16          0       2              4\n#>   Sugarcane               13       0          0       5              0\n#>   Water                    0       1          1       0              0\n#>                 \n#>                  Silviculture Sugarcane Water\n#>   Annual_Crop               0         2     0\n#>   Cerrado                  12         2     4\n#>   Nat_NonVeg                0         0     2\n#>   Pasture                   3         2     4\n#>   Perennial_Crop            2         0     0\n#>   Silviculture             77         0     0\n#>   Sugarcane                 0        71     0\n#>   Water                     0         0    69\n#> \n#> $area_pixels\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>       3.12e+07       2.02e+08       9.97e+05       1.09e+08       1.62e+06 \n#>   Silviculture      Sugarcane          Water \n#>       6.96e+06       1.06e+07       1.42e+07 \n#> \n#> $error_ajusted_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>       3.47e+07       2.14e+08       1.11e+06       9.58e+07       1.67e+06 \n#>   Silviculture      Sugarcane          Water \n#>       6.51e+06       8.84e+06       1.44e+07 \n#> \n#> $stderr_prop\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>       0.002328       0.004194       0.000542       0.004386       0.000735 \n#>   Silviculture      Sugarcane          Water \n#>       0.001060       0.001282       0.000931 \n#> \n#> $stderr_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>         876650        1579665         204161        1651840         276851 \n#>   Silviculture      Sugarcane          Water \n#>         399372         483007         350471 \n#> \n#> $conf_interval\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>        1718233        3096142         400156        3237606         542628 \n#>   Silviculture      Sugarcane          Water \n#>         782769         946693         686924 \n#> \n#> $accuracy\n#> $accuracy$user\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>          0.883          0.929          0.915          0.731          0.491 \n#>   Silviculture      Sugarcane          Water \n#>          0.778          0.798          0.972 \n#> \n#> $accuracy$producer\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop \n#>          0.794          0.880          0.820          0.830          0.474 \n#>   Silviculture      Sugarcane          Water \n#>          0.831          0.954          0.956 \n#> \n#> $accuracy$overall\n#> [1] 0.861\n#> \n#> \n#> attr(,\"class\")\n#> [1] \"sits_area_assessment\" \"list\""},{"path":"uncertainty-and-active-learning.html","id":"uncertainty-and-active-learning","chapter":"Uncertainty and active learning","heading":"Uncertainty and active learning","text":"Land classification tasks unique characteristics differ machine learning domains, image recognition natural language processing. main challenge land classification describe diversity planet’s landscapes handful labels. However, diversity world’s ecosystem makes classification systems biased approximations reality. stated Murphy: “gradation properties world means smallish number categories never map perfectly onto objects” [84]. reason, sits provides tools improve classifications using process called active learning.Active learning iterative process sample selection, labeling, model retraining. following steps provide general overview use active learning:Collect initial training samples: Start collecting small set representative training samples cover range land classes interest.Train machine learning model: Use initial training samples train machine learning model classify remote sensing data.Classify data cube using model.Identify areas uncertainty.Select samples re-labelling: Select set unlabelled samples model uncertain , .e., model least confident classifying.Label selected samples: user labels selected samples, adding training set.Retrain model: model retrained using newly labeled samples, process repeats , starting step 2.Stop classification accuracy satisfactory: iterative process continues classification accuracy reaches satisfactory level.traditional classification methods, experts provide set training samples use machine learning algorithm produce map. contrast, active learning approach puts human loop [85]. iteration, unlabelled set samples presented user, assigns classes includes training set [86]. process repeated expert satisfied result, shown Figure 80.\nFigure 80: Active learning approach (Source: Crawford et al. (2013). Reproduction fair use doctrine).\nActive learning aims reduce bias errors sample selection , , improve accuracy result. interaction, experts asked review pixels machine learning classifier indicates high uncertainty value. Sources classification uncertainty include missing classes mislabeled samples. sits, active learning supported functions sits_uncertainty() sits_uncertainty_sampling().","code":""},{"path":"uncertainty-and-active-learning.html","id":"measuring-uncertainty","chapter":"Uncertainty and active learning","heading":"Measuring uncertainty","text":"Uncertainty refers degree doubt ambiguity accuracy classification results. Several sources uncertainty can arise land classification using satellite data, including:Classification errors: can occur classification algorithm misinterprets spectral, spatial temporal characteristics input data, leading misclassification land classes.Ambiguity classification schema: definition land classes can ambiguous subjective, leading inconsistencies classification results.Variability landscape: Natural human-induced variations landscape can make difficult accurately classify land areas.Limitations data: quality quantity input data can influence accuracy classification results.Quantifying uncertainty land classification important ensuring results reliable valid decision-making. Various methods, confusion error matrices, can used estimate visualize level uncertainty classification results. Additionally, incorporating uncertainty estimates decision-making processes can help identify regions investigation data collection needed.function sits_uncertainty() calculates uncertainty cube based probabilities produced classifier. takes probability cube input. uncertainty measure relevant context active learning. helps increase quantity quality training samples providing information model’s confidence. supported types uncertainty ‘entropy’, ‘least’, ‘margin’, ‘ratio’.Least confidence sampling difference uncertainty (100% confidence) probability likely class, normalized number classes. Let \\(P_1()\\) higher class probability pixel \\(\\). least confidence sampling expressed \\[\n\\theta_{LC} = (1 - P_1()) * \\frac{n}{n-1}.\n\\]margin confidence sampling difference two confident predictions, expressed 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , margin confidence expressed \\[\n\\theta_{MC} = 1 - P_1() - P_2().\n\\]ratio confidence measure ratio two confident predictions, expressed range 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , ratio confidence expressed \n\\[\n\\theta_{RC} = \\frac{P_2()}{P_1()}.\n\\]Entropy measure uncertainty used Claude Shannon classic work “Mathematical Theory Communication”. related amount variability probabilities associated pixel. lower variability, lower entropy. Let \\(P_k()\\) probability class \\(k\\) pixel \\(\\). entropy calculated \n\\[\n\\theta_{E} = \\frac{-\\sum_{k=1}^K P_k() * log_2(P_k())}{log_2{n}}.\n\\]parameters sits_uncertainty() : cube, probability data cube; type, uncertainty measure (default least). processing functions, multicores number cores run function memsize maximum overall memory (GB) run function, output_dir output directory image files, version result version.","code":""},{"path":"uncertainty-and-active-learning.html","id":"using-uncertainty-measures-for-active-learning","chapter":"Uncertainty and active learning","heading":"Using uncertainty measures for active learning","text":"following case study shows uncertainty measures can used context active learning. study area subset one Sentinel-2 tile state Rondonia, Brazil. work aims detect deforestation Brazilian Amazonia.study area close Samuel Hydroelectric Dam, located Madeira River Brazilian state Rondônia. Building dam led loss 56,000 ha native forest. dam’s construction caused displacement several indigenous communities traditional populations, leading social cultural disruption. Additionally, flooding large forest areas resulted losing habitats biodiversity, including several endangered species. dam altered natural flow Madeira River, leading changes water quality temperature affecting aquatic life depends river. changes river flow also impacted navigation transportation activities local communities [87].first step produce regular data cube chosen area 2020-06-01 2021-09-01. reduce processing time storage, use three bands (B02, B8A, B11) plus cloud band, take small area inside tile. obtaining regular cube, plot study area two dates temporal interval data cube. first image taken beginning dry season 2020-07-04, inundation area dam covered shallow water.\nFigure 81: Area Rondonia near Samuel dam (Source: Authors).\nsecond image 2020-11-09 shows inundation area dries dry season. early November 2020, end dry season, inundation area dry response similar bare soil burned areas. Madeira River can seen running dried inundation area.\nFigure 82: Area Rondonia near Samuel dam November 2021 (Source: Authors).\nthird image 2021-08-08. early August 2021, wet season, inundation area covered shallow water layer. Several burned clear-cut areas can also seen August 2021 image compared July 2020 one. Given contrast wet dry seasons, correct land classification area hard.\nFigure 83: Area Rondonia near Samuel dam August 2021 (Source: Authors).\nnext step classify study area using training set 480 times series collected state Rondonia (Brazil) detecting deforestation. training set uses 4 classes (Burned_Area, Forest, Highly_Degraded, Cleared_Area). cube classified using LightTAE model, post-processed Bayesian smoothing, labeled.\nFigure 84: Classified map area Rondonia near Samuel dam (Source: Authors).\nresulting map correctly identifies forest area deforestation. However, wrongly classifies area covered Samuel hydroelectric dam. reason lack samples classes related surface water wetlands. improve classification, need improve samples. , first step calculate uncertainty classification.\nFigure 85: Uncertainty map classification Rondonia near Samuel dam (Source: Authors).\nexpected, places highest uncertainty covered surface water associated wetlands. places likely misclassified. reason, sits provides sits_uncertainty_sampling(), takes uncertainty cube input produces tibble locations WGS84 high uncertainty. function three parameters: n, number uncertain points included; min_uncert, minimum value uncertainty pixels included list; sampling_window, defines window one sample selected. aim sampling_window improve spatial distribution new samples avoiding points neighborhood included. running function, can use sits_view() visualize location samples.\nFigure 86: Location uncertain pixel classification Rondonia near Samuel dam (Source: Authors).\nvisualization shows samples located areas covered Samuel data. Thus, designate samples Wetlands. detailed evaluation, recommended practice, requires analysing samples exploration software QGIS individually labelling sample. case, take direct approach illustration purposes.\nFigure 87: New land classification Rondonia near Samuel dam (Source: Authors).\nresults show significant quality gain earlier classification. still areas confusion exposed soils inside inundation area, classified burned areas. also useful show uncertainty map associated second model.\nFigure 88: Uncertainty map classification Rondonia near Samuel dam - improved model (Source: Authors).\nnew uncertainty map shows, significant improvement quality classification. remaining areas high uncertainty affected contrast wet dry seasons close inundation area. areas low-laying places sometimes covered water sometimes bare soil areas throughout year, depending intensity rainy season. improve classification quality, obtain new samples uncertain areas, label , add samples. general, Chapter shows, combining uncertainty measurements active learning recommended practice improving classification results.","code":"\n# Select a S2 tile\ns2_cube_ro <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LMR\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"SCL\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2021-09-01\")\n)\n\n# Select a small area inside the tile\nroi <- c(\n  lon_max = -63.25790, lon_min = -63.6078,\n  lat_max = -8.72290, lat_min = -8.95630\n)\n# Regularize the small area cube\ns2_reg_cube_ro <- sits_regularize(\n  cube = s2_cube_ro,\n  output_dir = \"./tempdir/chp12/\",\n  res = 20,\n  roi = roi,\n  period = \"P16D\",\n  multicores = 4\n)\n\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-07-04\"\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-11-09\"\n)\nplot(s2_reg_cube_ro, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2021-08-08\")\nlibrary(sitsdata)\n# Load the training set\ndata(\"samples_prodes_4classes\")\n# Select the same three bands used in the data cube\nsamples_4classes_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\n\n# Train a random forest model\nrfor_model <- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_rfor()\n)\n\n# Classify the small area cube\ns2_cube_probs <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 15,\n  multicores = 5\n)\n\n# Post-process the probability cube\ns2_cube_bayes <- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label <- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_label)\n# Calculate the uncertainty cube\ns2_cube_uncert <- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"margin\",\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert)\n# Find samples with high uncertainty\nnew_samples <- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n)\n\n# View the location of the samples\nsits_view(new_samples)\n# Label the new samples\nnew_samples$label <- \"Wetland\"\n# Obtain the time series from the regularized cube\nnew_samples_ts <- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n)\n\n# Join the new samples with the original ones with 4 classes\nsamples_round_2 <- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n)\n\n# Train a RF model with the new sample set\nrfor_model_v2 <- sits_train(\n  samples = samples_round_2,\n  ml_method = sits_rfor()\n)\n\n# Classify the small area cube\ns2_cube_probs_v2 <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Post-process the probability cube\ns2_cube_bayes_v2 <- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label_v2 <- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(s2_cube_label_v2)\n# Calculate the uncertainty cube\ns2_cube_uncert_v2 <- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"entropy\",\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert_v2)"},{"path":"ensemble-prediction-from-multiple-models.html","id":"ensemble-prediction-from-multiple-models","chapter":"Ensemble prediction from multiple models","heading":"Ensemble prediction from multiple models","text":"Ensemble prediction powerful technique combining predictions multiple models produce accurate robust predictions. general, ensemble predictions produce better predictions using single model. errors individual models can cancel reduced combined predictions models. result, ensemble predictions can lead better overall accuracy reduce risk overfitting. can especially useful working complex uncertain data. combining predictions multiple models, users can identify features factors important making accurate predictions. using ensemble methods, choosing diverse models different sources error important ensure ensemble predictions accurate robust.sits package provides sits_combine_predictions() estimate ensemble predictions using probability cubes produced sits_classify() optionally post-processed sits_smooth(). two ways make ensemble predictions multiple models:Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.follows, use data set used Chapter Image classification data cubes illustrate produce ensemble prediction. train two models: Random Forest (RF) Support Vector Machines (SVM), classify cube , combine results. first make RF classification\nFigure 89: Land classification Rondonia using random forest algorithm (Source: Authors).\nnext step classify area using SVM algorithm, shown .\nFigure 90: Land classification Rondonia using support vector machine (Source: Authors).\ngood agreement two results, land areas classified similarly. main differences “Clear_Cut_Burned_Area” “Clear_Cut_Vegetation”. RF algorithm tends conservative finds less areas SVM. reason RF decision-making uses values single attributes (values single band given time instance). Since Random Forest model sensitive response images end period, tends focus values indicate presence forests dry season. SVM model balanced overall separation classes entire attribute space. Also note study area presents many challenges land classification, given presence wetlands, riparian forests seasonally-flooded areas. challenge, methods make mistakes including flooded areas “Clear_Cut_Vegetation” center-left part image.Given differences complementaries two predicted outcomes, combining using sits_combine_predictions() useful. function takes following arguments: () cubes, list cubes combined. cubes probability cubes generated optionally may smoothened; (b) type, indicates combine probability maps. options average, performs weighted mean probabilities, uncertainty, uses uncertainty cubes combine predictions; (c) weights, vector weights used combine predictions average selected; (d) uncertainty_cubes, list uncertainty cubes associated predictions; (e) multicores, number cores used; (f) memsize, RAM used classification; (g) output_dir, directory classified raster files written.\nFigure 91: Land classification Rondonia using average probabilities produced Random Forest SVM algorithms (Source: Authors).\nCompared initial map, result similar original SVM map RF result, especially regards “Clear_Cut_Burned_Area” class. outcome indicates SVM confident predictions RF detecting deforestation areas associated fires. contrast, misclassified areas center-left part map reduced. reason areas indicated one classifier . case, confidence deforestation results matched methods. Thus, principle, resulting combined map accurate individual model outcomes.second way combine prediction use uncertainty information associated probability pixel. case, confidence prediction inversely proportional uncertainty. information compute uncertainty prediction, please refer Chapter Uncertainty active learning.\nFigure 92: Land classification Rondonia using uncertainty probabilities produced Random Forest SVM algorithms (Source: Authors).\nresult prediction combination using uncertainty quite similar one produced average method. shows SVM method higher confidence predictions. Overall, ensemble predictions powerful tool improving accuracy robustness machine learning models. combining predictions multiple models, can reduce errors uncertainty gain new insights underlying patterns data.","code":"\n# Files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LMR/\", package = \"sitsdata\")\n# Read data cube\nro_cube_20LMR <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n# train a random forest model\nrfor_model <- sits_train(samples_deforestation, sits_rfor())\n\nro_cube_20LMR_rfor_probs <- sits_classify(\n  ro_cube_20LMR,\n  rfor_model,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor-raster\"\n)\n\nro_cube_20LMR_rfor_bayes <- sits_smooth(\n  ro_cube_20LMR_rfor_probs,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor-raster\"\n)\nro_cube_20LMR_rfor_class <- sits_label_classification(\n  ro_cube_20LMR_rfor_bayes,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor-raster\"\n)\nplot(ro_cube_20LMR_rfor_class)\n# train an SVM model\nsvm_model <- sits_train(samples_deforestation, sits_svm())\n# classify the data cube\nro_cube_20LMR_svm_probs <- sits_classify(\n  ro_cube_20LMR,\n  rfor_model,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"svm-raster\"\n)\n\nro_cube_20LMR_svm_bayes <- sits_smooth(\n  ro_cube_20LMR_svm_probs,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"svm-raster\"\n)\nro_cube_20LMR_svm_class <- sits_label_classification(\n  ro_cube_20LMR_svm_bayes,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"svm-raster\"\n)\nplot(ro_cube_20LMR_svm_class)\n# Combine the two predictions by taking the average of the probabilities for each class\nro_cube_20LMR_average_probs <- sits_combine_predictions(\n  cubes = list(ro_cube_20LMR_svm_bayes, ro_cube_20LMR_rfor_bayes),\n  type = \"average\",\n  output_dir = \"./tempdir/chp13/\",\n  weights = c(0.50, 0.50),\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the average probability cube\nro_cube_20LMR_average_class <- sits_label_classification(\n  cube = ro_cube_20LMR_average_probs,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"average\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(ro_cube_20LMR_average_class,\n  tmap_options = list(\"scale\" = 0.6)\n)\n# Calculate the uncertainty of SVM prediction\nro_cube_20LMR_svm_uncert <- sits_uncertainty(\n  ro_cube_20LMR_svm_bayes,\n  type = \"margin\",\n  output_dir = \"./tempdir/chp13/\",\n  version = \"svm\",\n  memsize = 16,\n  multicores = 4\n)\n# Calculate the uncertainty of RF prediction\nro_cube_20LMR_rfor_uncert <- sits_uncertainty(\n  ro_cube_20LMR_rfor_bayes,\n  type = \"margin\",\n  output_dir = \"./tempdir/chp13/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Combine the two predictions by taking the average of the probabilities for each class\nro_cube_20LMR_uncert_probs <- sits_combine_predictions(\n  cubes = list(ro_cube_20LMR_svm_bayes, ro_cube_20LMR_rfor_bayes),\n  uncert_cubes = list(ro_cube_20LMR_svm_uncert, ro_cube_20LMR_rfor_uncert),\n  type = \"uncertainty\",\n  output_dir = \"./tempdir/chp13/\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the average probability cube\nro_cube_20LMR_uncert_class <- sits_label_classification(\n  cube = ro_cube_20LMR_uncert_probs,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"uncertainty\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(ro_cube_20LMR_uncert_class,\n  tmap_options = list(\"scale\" = 0.6)\n)"},{"path":"object-based-time-series-image-analysis.html","id":"object-based-time-series-image-analysis","chapter":"Object-based time series image analysis","heading":"Object-based time series image analysis","text":"Object-Based Image Analysis (OBIA) approach remote sensing image analysis partitions image closed segments classified analyzed. high-resolution images (1 meter smaller) aim OBIA create objects represent meaningful features real world, like buildings, roads, fields, forests, water bodies. case medium resolution images (Sentinel-2 Landsat) segments represent groups image similar spectral responses general correspond directly individual objects ground. groups pixels called super-pixels. situations, aim OBIA obtain spatial partition image can assigned single class. applicable, OBIA reduces processing time produces labelled maps greater spatial consistency.general sequence processes involved OBIA sits :Segmentation: first step group together pixels similar based distance metric consider values bands time instances. build multitemporal attribute space time/band combination taken independent dimension. Thus, distance metrics segmentation data cube 10 bands 24 time steps use 240-dimension space.Segmentation: first step group together pixels similar based distance metric consider values bands time instances. build multitemporal attribute space time/band combination taken independent dimension. Thus, distance metrics segmentation data cube 10 bands 24 time steps use 240-dimension space.Probability Estimation: image partitioned distinct objects, next step classify segment. satellite image time series, subset time series inside segment classified.Probability Estimation: image partitioned distinct objects, next step classify segment. satellite image time series, subset time series inside segment classified.Labelling: set probabilities obtain time series inside segment, can used labelling. done considering median value probabilities time series inside segment classified. class, take median probability values. , median values classes normalised, likely value assigned class segment.Labelling: set probabilities obtain time series inside segment, can used labelling. done considering median value probabilities time series inside segment classified. class, take median probability values. , median values classes normalised, likely value assigned class segment.","code":""},{"path":"object-based-time-series-image-analysis.html","id":"image-segmentation-in-sits","chapter":"Object-based time series image analysis","heading":"Image segmentation in SITS","text":"first step OBIA procedure sits select data cube segmented function performs segmentation. purpose, sits provides generic sits_segment() function, allows users select different segmentation algorithms. sits_segment() function following parameters:cube: regular data cube.seg_fn: function apply segmentationroi: spatial region interest cubestart_date: starting date space-time segmentationend_date: final date space-time segmentationmemsize: memory available processingmulticores: number cores available processingoutput_dir: output directory resulting cubeversion: version resultprogress: show progress bar?sits version 1.4.2, one segmentation function available (sits_slic) implements extended version Simple Linear Iterative Clustering (SLIC) described . future versions sits, expect include additional functions support spatio-temporal segmentation.","code":""},{"path":"object-based-time-series-image-analysis.html","id":"simple-linear-iterative-clustering-slic-algorithm","chapter":"Object-based time series image analysis","heading":"Simple Linear Iterative Clustering (SLIC) algorithm","text":"building multidimensional space, use SLIC algorithm [Achanta2012] clusters pixels efficiently generate compact, nearly uniform superpixels. algorithm adapted Nowosad Stepinski [Nowosad2022] work multispectral images. SLIC uses spectral similarity proximity image space segment image superpixels. Superpixels clusters pixels similar spectral responses close together, correspond coherent object parts image. ’s high-level view extended SLIC algorithm:algorithm starts dividing image grid, cell grid become superpixel.algorithm starts dividing image grid, cell grid become superpixel.cell, pixel center becomes initial “cluster center” superpixel.cell, pixel center becomes initial “cluster center” superpixel.pixel, algorithm calculates distance nearby cluster centers. distance includes spatial component (far pixel center superpixel terms x y coordinates) spectral component (different pixel’s spectral values average values superpixel). spectral distance calculated using temporal instances bands.pixel, algorithm calculates distance nearby cluster centers. distance includes spatial component (far pixel center superpixel terms x y coordinates) spectral component (different pixel’s spectral values average values superpixel). spectral distance calculated using temporal instances bands.pixel assigned closest cluster. pixels assigned clusters, algorithm recalculates cluster centers averaging spatial coordinates spectral values pixels within cluster.pixel assigned closest cluster. pixels assigned clusters, algorithm recalculates cluster centers averaging spatial coordinates spectral values pixels within cluster.Steps 3-4 repeated set number iterations, cluster assignments stop changing.Steps 3-4 repeated set number iterations, cluster assignments stop changing.outcome SLIC algorithm set superpixels try capture boundaries objects within image. SLIC implementation sits 1.4.1 uses supercells R package [88]. parameters sits_slic() function :dist_fn: metric used calculate distance values. default, “euclidean” metric used. Alternatives include “jsd” (Jensen-Shannon distance), “dtw” (dynamic time warping) one 46 distance similarity measures implemented R package philentropy [89].avg_fn: function calculate value superpixel. two internal functions implemented C++ - “mean” “median”. also possible provide user-defined R function returns one value based R vector.step: distance, measured number cells, initial superpixels’ centers.compactness: value controls superpixels’ density. Larger values cause clusters compact.minarea: minimal size output superpixels (measured number cells).","code":""},{"path":"object-based-time-series-image-analysis.html","id":"example-of-slic-based-segmentation-and-classification","chapter":"Object-based time series image analysis","heading":"Example of SLIC-based segmentation and classification","text":"show example SLIC-based segmentation, first build data cube, using images available sitsdata package.\nFigure 93: Sentinel-2 image area Rondonia Brazil\nfollowing example produces segmented image. SLIC algorithm, take initial separation cluster centres (step) 20 pixels, compactness 1, minimum area superpixel (min_area) 20 pixels.useful visualize segments leaflet together RGB image using sits_view().obtaining segments, next step classify . done first training classification model. case study, use SVM model.segment classification procedure applies model number user-defined samples inside segment. samples assigned set probability values, one class. obtain median value probabilities class normalize . output procedure vector data cube containing set classified segments. parameters sits_classify()view classified segments together original image, use plot() sits_view(), following example.conclude OBIA analysis applied image time series worthy efficient technique land classification, combining desirable sharp object boundary properties required land use cover maps analytical power image time series.","code":"\n# directory where files are located\ndata_dir <- system.file(\"extdata/Rondonia-20LMR\", package = \"sitsdata\")\n# Builds a cube based on existing files\ncube_20LMR <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\nplot(cube_20LMR, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2022-07-16\")\n# segment a cube using SLIC\n# Files are available in a local directory\nsegments_20LMR <- sits_segment(\n  cube = cube_20LMR,\n  output_dir = \"./tempdir/chp14\",\n  seg_fn = sits_slic(\n    step = 20,\n    compactness = 1,\n    dist_fun = \"euclidean\",\n    iter = 20,\n    minarea = 20\n  )\n)\nplot(segments_20LMR,\n  red = \"B11\", green = \"B8A\", blue = \"B02\",\n  date = \"2022-07-16\"\n)\nsits_view(segments_20LMR,\n  red = \"B11\", green = \"B8A\", blue = \"B02\",\n  dates = \"2022-07-16\"\n)\nsvm_model <- sits_train(samples_deforestation, sits_svm())\nsegments_20LMR_probs_svm <- sits_classify(\n  data = segments_20LMR,\n  ml_model = svm_model,\n  output_dir = \"./tempdir/chp14\",\n  n_sam_pol = 40,\n  gpu_memory = 16,\n  memsize = 24,\n  multicores = 6,\n  version = \"svm-segments\"\n)\n\nsegments_20LMR_class_svm <- sits_label_classification(\n  segments_20LMR_probs_svm,\n  output_dir = \"./tempdir/chp14\",\n  memsize = 24,\n  multicores = 6,\n  version = \"svm-segments\"\n)\nsits_view(\n  segments_20LMR_class_svm,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  dates = \"2022-07-16\",\n)"},{"path":"technical-annex.html","id":"technical-annex","chapter":"Technical Annex","heading":"Technical Annex","text":"Chapter contains technical details algorithms available sits. intended support want understand package works also want contribute development.","code":""},{"path":"technical-annex.html","id":"how-parallel-processing-works-in-virtual-machines-with-cpus","chapter":"Technical Annex","heading":"How parallel processing works in virtual machines with CPUs","text":"section provides overview sits_classify(), sits_smooth(), sits_label_classification() process images parallel. achieve efficiency, sits implements fault-tolerant multitasking procedure big Earth observation data classification. learning curve shortened need learn multiprocessing. Image classification sits done cluster independent workers linked virtual machine. avoid communication overhead, large payloads read stored independently; direct interaction main process workers kept minimum.classification procedure benefits fact images available cloud collections stored COGs (cloud-optimized GeoTIFF). COGs regular GeoTIFF files organized regular square blocks improve visualization access large data sets. Thus, data requests can optimized access portions images. cloud services supported sits use COG files. classification algorithm sits uses COGs ensure optimal data access, reducing /O demand much possible.approach parallel processing sits, depicted Figure 94, following steps:Based block size individual COG files, calculate size chunk must loaded memory, considering number bands timeline’s length. Chunk access optimized efficient transfer data blocks.Divide total memory available chunk size determine many processes can run parallel.core processes chunk produces subset result.Repeat process chunks cube processed.Check subimages produced correctly. problem one subimages, run failure recovery procedure ensure data processed.generating subimages, join obtain result.\nFigure 94: Parallel processing sits (Source: Simoes et al. (2021). Reproduction fair use doctrine).\napproach many advantages. dependencies proprietary software runs virtual machine supports R. Processing done concurrent independent way, communication workers. Failure one worker cause failure big data processing. software prepared resume classification processing last processed chunk, preventing failures memory exhaustion, power supply interruption, network breakdown.reduce processing time, necessary adjust sits_classify(), sits_smooth(), sits_label_classification() according capabilities host environment. memsize parameter controls size main memory (GBytes) used classification. practical approach set memsize maximum memory available virtual machine classification choose multicores largest number cores available. Based memory available size blocks COG files, sits access images optimized way. way, sits tries ensure best possible use available resources.","code":""},{"path":"technical-annex.html","id":"including-new-methods-for-machine-learning","chapter":"Technical Annex","heading":"Including new methods for machine learning","text":"section provides guidance experts want include new methods machine learning work connection sits. discussion assumes familiarity R language. Developers consult Hadley Wickham’s excellent book Advanced R, especially Chapter 10 “Function Factories”.machine learning deep learning algorithm sits follow logic; models created sits_train(). function two parameters: () samples, set time series training samples; (b) ml_method, function fits model input data. result function passed sits_classify() classify time series data cubes. structure sits_train() simple, shown .R terms, sits_train() function factory, function makes functions. behavior possible functions first-class objects R. words, can bound name way variables . second propriety R functions capture (enclose) environment created. words, function returned result another function, internal variables used create available inside environment. programming language, technique called “closure”.following definition Wikipedia captures purpose clousures: “Operationally, closure record storing function together environment. environment mapping associating free variable function value reference name bound closure created. closure allows function access captured variables closure’s copies values references, even function invoked outside scope.”sits, properties closures used basis making training classification independent. return sits_train() model contains information classify input values, well information samples used train model.ensure models work fashion, machine learning functions sits also share data structure prediction. data structure created sits_predictors(), transforms time series tibble set values suitable using training data, shown following example.predictors tibble organized combination “X” “Y” values used machine learning algorithms. first two columns sample_id label. columns contain data values, organized band time. machine learning methods time-sensitive, random forest, organization sufficient training. case time-sensitive methods tempCNN, arrangements necessary ensure tensors right dimensions. Please refer sits_tempcnn() source code example adapt prediction table appropriate torch tensor.algorithms require data normalization. Therefore, sits_predictors() code usually combined methods extract statistical information normalize data, example .following example shows implementation LightGBM algorithm, designed efficiently handle large-scale datasets perform fast training inference [90]. Gradient boosting machine learning technique builds ensemble weak prediction models, typically decision trees, create stronger model. LightGBM specifically focuses optimizing training prediction speed, making particularly suitable large datasets. example builds model using lightgbm package. model applied later obtain classification.Since LightGBM gradient boosting model, uses part data testing data improve model’s performance. split training test samples controlled parameter, shown following code extract.parameters lightgbm algorithm, defined documentation, : () boosting_type, boosting algorithm; (b) objective, classification objective (c) num_iterations, number runs; (d) max_depth, maximum tree depth; (d) min_samples_leaf, minimum size data one leaf (avoid overfitting); (f) learning_rate, learning rate algorithm; (g) n_iter_no_change, number successive iterations stop training validation metrics improve; (h) validation_split, fraction training data used validation data.training part lightgbm algorithm uses two functions: () lgb.Dataset(), transforms training test samples internal structures; (b) lgb.train(), trains model.code two nested functions: results_fun() predict_fun(). lgb_method() called, transforms input samples predictors normalizes . , uses predictors train algorithm, creating model (result_mlr). model included part function’s closure becomes available classification time. code creates prediction_fun(), applies result_mlr model input values classified. function returned results_fun() contains necessary information classification. classification time, model called directly.last lines code also include convenience function sits_factory_function(), shown . function allows model called either part sits_train() called independently, result.one additional requirement algorithm compatible sits. Data cube processing algorithms sits run parallel. reason, classification model trained, serialized, shown following line. serialized version model exported function closure, can used classification time.classification, predict_fun() called parallel CPU. moment, serialized string transformed back model, run obtain classification, shown code.Therefore, using function factories produce closures, sits keeps classification function independent machine learning deep learning algorithm. policy allows independent proposal, testing, development new classification methods. also enables improvements parallel processing methods without affecting existing classification methods.illustrate separation training classification, new algorithm developed chapter using lightgbm used classify data cube. code one Chapter Introduction example data cube classification, except use lgb_method().\nFigure 95: Classification map Sinop using LightGBM.\nexample shows possible extend sits new machine learning algorithms.","code":"\nsits_train <- function(samples, ml_method) {\n  # train a ml classifier with the given data\n  result <- ml_method(samples)\n  # return a valid machine learning method\n  return(result)\n}\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\npred <- sits_predictors(samples_matogrosso_mod13q1)\npred#> # A tibble: 1,837 × 94\n#>    sample_id label   NDVI1 NDVI2 NDVI3 NDVI4 NDVI5 NDVI6 NDVI7 NDVI8 NDVI9 NDVI10\n#>        <int> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n#>  1         1 Pasture 0.500 0.485 0.716 0.654 0.591 0.662 0.734 0.739 0.768  0.797\n#>  2         2 Pasture 0.364 0.484 0.605 0.726 0.778 0.829 0.762 0.762 0.643  0.610\n#>  3         3 Pasture 0.577 0.674 0.639 0.569 0.596 0.623 0.650 0.650 0.637  0.646\n#>  4         4 Pasture 0.597 0.699 0.789 0.792 0.794 0.72  0.646 0.705 0.757  0.810\n#>  5         5 Pasture 0.388 0.491 0.527 0.660 0.677 0.746 0.816 0.816 0.825  0.835\n#>  6         6 Pasture 0.350 0.345 0.364 0.429 0.506 0.583 0.660 0.616 0.580  0.651\n#>  7         7 Pasture 0.490 0.527 0.543 0.583 0.594 0.605 0.616 0.627 0.622  0.644\n#>  8         8 Pasture 0.435 0.574 0.395 0.392 0.518 0.597 0.648 0.774 0.786  0.798\n#>  9         9 Pasture 0.396 0.473 0.542 0.587 0.649 0.697 0.696 0.695 0.699  0.703\n#> 10        10 Pasture 0.354 0.387 0.527 0.577 0.626 0.723 0.655 0.655 0.646  0.536\n#> # ℹ 1,827 more rows\n#> # ℹ 82 more variables: NDVI11 <dbl>, NDVI12 <dbl>, NDVI13 <dbl>, NDVI14 <dbl>,\n#> #   NDVI15 <dbl>, NDVI16 <dbl>, NDVI17 <dbl>, NDVI18 <dbl>, NDVI19 <dbl>,\n#> #   NDVI20 <dbl>, NDVI21 <dbl>, NDVI22 <dbl>, NDVI23 <dbl>, EVI1 <dbl>,\n#> #   EVI2 <dbl>, EVI3 <dbl>, EVI4 <dbl>, EVI5 <dbl>, EVI6 <dbl>, EVI7 <dbl>,\n#> #   EVI8 <dbl>, EVI9 <dbl>, EVI10 <dbl>, EVI11 <dbl>, EVI12 <dbl>, EVI13 <dbl>,\n#> #   EVI14 <dbl>, EVI15 <dbl>, EVI16 <dbl>, EVI17 <dbl>, EVI18 <dbl>, …\n# Data normalization\nml_stats <- sits_stats(samples)\n# extract the training samples\ntrain_samples <- sits_predictors(samples)\n# normalize the training samples\ntrain_samples <- sits_pred_normalize(pred = train_samples, stats = ml_stats)\n# split the data into training and validation data sets\n# create partitions different splits of the input data\ntest_samples <- sits_pred_sample(train_samples,\n  frac = validation_split\n)\n# Remove the lines used for validation\nsel <- !(train_samples$sample_id %in% test_samples$sample_id)\ntrain_samples <- train_samples[sel, ]\n# install \"lightgbm\" package if not available\nif (!require(\"lightgbm\")) install.packages(\"lightgbm\")\n# create a function in sits style for LightGBM algorithm\nlgb_method <- function(samples = NULL,\n                       boosting_type = \"gbdt\",\n                       objective = \"multiclass\",\n                       min_samples_leaf = 10,\n                       max_depth = 6,\n                       learning_rate = 0.1,\n                       num_iterations = 100,\n                       n_iter_no_change = 10,\n                       validation_split = 0.2, ...) {\n  # function that returns MASS::lda model based on a sits sample tibble\n  result_fun <- function(samples) {\n    # Data normalization\n    ml_stats <- sits_stats(samples)\n    train_samples <- sits_predictors(samples)\n    train_samples <- sits_pred_normalize(pred = train_samples, stats = ml_stats)\n\n    # find number of labels\n    labels <- sits_labels(samples)\n    n_labels <- length(labels)\n    # lightGBM uses numerical labels starting from 0\n    int_labels <- c(1:n_labels) - 1\n    # create a named vector with integers match the class labels\n    names(int_labels) <- labels\n\n    # add number of classes to lightGBM params\n    # split the data into training and validation data sets\n    # create partitions different splits of the input data\n    test_samples <- sits_pred_sample(train_samples,\n      frac = validation_split\n    )\n\n    # Remove the lines used for validation\n    sel <- !(train_samples$sample_id %in% test_samples$sample_id)\n    train_samples <- train_samples[sel, ]\n\n    # transform the training data to LGBM dataset\n    lgbm_train_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(train_samples[, -2:0]),\n      label = unname(int_labels[train_samples[[2]]])\n    )\n    # transform the test data to LGBM dataset\n    lgbm_test_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(test_samples[, -2:0]),\n      label = unname(int_labels[test_samples[[2]]])\n    )\n    # set the parameters for the lightGBM training\n    lgb_params <- list(\n      boosting_type = boosting_type,\n      objective = objective,\n      min_samples_leaf = min_samples_leaf,\n      max_depth = max_depth,\n      learning_rate = learning_rate,\n      num_iterations = num_iterations,\n      n_iter_no_change = n_iter_no_change,\n      num_class = n_labels\n    )\n    # call method and return the trained model\n    lgbm_model <- lightgbm::lgb.train(\n      data    = lgbm_train_samples,\n      valids  = list(test_data = lgbm_test_samples),\n      params  = lgb_params,\n      verbose = -1,\n      ...\n    )\n    # serialize the model for parallel processing\n    lgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n    # construct model predict closure function and returns\n    predict_fun <- function(values) {\n      # reload the model (unserialize)\n      lgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\n      # Performs data normalization - returns only values\n      # in the prediction only values are available\n      values <- sits_pred_normalize(pred = values, stats = ml_stats)\n      # predict probabilities\n      prediction <- stats::predict(lgbm_model,\n        data = as.matrix(values),\n        rawscore = FALSE,\n        reshape = TRUE\n      )\n      # adjust the names of the columns of the probs\n      colnames(prediction) <- labels\n      # retrieve the prediction results\n      return(prediction)\n    }\n    # Set model class\n    class(predict_fun) <- c(\"sits_model\", class(predict_fun))\n    return(predict_fun)\n  }\n  result <- sits_factory_function(samples, result_fun)\n  return(result)\n}\nsits_factory_function <- function(samples, fun) {\n  # if no data is given, we prepare a\n  # function to be called as a parameter of other functions\n  if (purrr::is_null(data)) {\n    result <- fun\n  } else {\n    # ...otherwise compute the result on the input data\n    result <- fun(data)\n  }\n  return(result)\n}\n# serialize the model for parallel processing\nlgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n# unserialize the model\nlgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\n# Create a data cube using local files\nsinop <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# The data cube has only \"NDVI\" and \"EVI\" bands\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# train lightGBM model\nlgb_model <- sits_train(samples_2bands, lgb_method())\n\n# Classify the data cube\nsinop_probs <- sits_classify(\n  data = sinop,\n  ml_model = lgb_model,\n  multicores = 1,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Label the smoothed file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp3\"\n)\n# plot the result\nplot(sinop_map, title = \"Sinop Classification Map\")"},{"path":"technical-annex.html","id":"how-colors-work-in-sits","chapter":"Technical Annex","heading":"How colors work in sits","text":"examples provided book, color legend taken predefined color pallete provided sits. color definition file used sits 210 class names, can shown using sits_colors()colors grouped typical legends used Earth observation community, include “IGBP”, “UMD”, “ESA_CCI_LC”, “WORLDCOVER”, “PRODES”, “PRODES_VISUAL”, “TERRA_CLASS”, “TERRA_CLASS_PT”. following commands shows colors associated IGBP legend[91].\nFigure 96: Default colors used sits package (Source: Authors).\ndefault color table can redefined using sits_colors_set(). example user-defined color table, consider definition covers level 1 Anderson Classification System used US National Land Cover Data, obtained defining new color table, shown . colors can defined HEX values names accepted R color codes.original default sits color table can restored using sits_colors_reset().alternative, legend can used directly parameter plot(). Please see example provided Section “Map Reclassification” Chapter Image classification data cubes.","code":"#> [1] \"Returning all available colors\"#> # A tibble: 220 × 2\n#>    name                             color  \n#>    <chr>                            <chr>  \n#>  1 Evergreen_Broadleaf_Forest       #518940\n#>  2 Evergreen_Broadleaf_Forests      #518940\n#>  3 Tree_Cover_Broadleaved_Evergreen #518940\n#>  4 Forest                           #518940\n#>  5 Forests                          #518940\n#>  6 Closed_Forest                    #518940\n#>  7 Closed_Forests                   #518940\n#>  8 Mountainside_Forest              #229C59\n#>  9 Mountainside_Forests             #229C59\n#> 10 Open_Forest                      #53A145\n#> # ℹ 210 more rows\n# Define a color table based on the Anderson Land Classification System\nus_nlcd <- tibble::tibble(name = character(), color = character())\nus_nlcd <- us_nlcd %>%\n  tibble::add_row(name = \"Urban Built Up\", color = \"#85929E\") |>\n  tibble::add_row(name = \"Agricultural Land\", color = \"#F0B27A\") |>\n  tibble::add_row(name = \"Rangeland\", color = \"#F1C40F\") |>\n  tibble::add_row(name = \"Forest Land\", color = \"#27AE60\") |>\n  tibble::add_row(name = \"Water\", color = \"#2980B9\") |>\n  tibble::add_row(name = \"Wetland\", color = \"#D4E6F1\") |>\n  tibble::add_row(name = \"Barren Land\", color = \"#FDEBD0\") |>\n  tibble::add_row(name = \"Tundra\", color = \"#EBDEF0\") |>\n  tibble::add_row(name = \"Snow and Ice\", color = \"#F7F9F9\")\n# Load the color table into `sits`\nsits_colors_set(us_nlcd)"},{"path":"technical-annex.html","id":"exporting-data-to-json","chapter":"Technical Annex","heading":"Exporting data to JSON","text":"data cube time series tibble can exported exchange formats JSON.","code":"\nlibrary(jsonlite)\n# Export the data cube to JSON\njsonlite::write_json(\n  x = sinop,\n  path = \"./data_cube.json\",\n  pretty = TRUE\n)\n\n# Export the time series to JSON\njsonlite::write_json(\n  x = samples_prodes_4classes,\n  path = \"./time_series.json\",\n  pretty = TRUE\n)"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
